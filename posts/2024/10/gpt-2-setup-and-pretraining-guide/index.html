<!DOCTYPE html>
<html lang="en">
  <head><head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    
    <link rel="icon" href="/img/favicon.ico">
    

    <meta property="og:url" content="https://seehiong.github.io/posts/2024/10/gpt-2-setup-and-pretraining-guide/">
  <meta property="og:site_name" content="See Hiong&#39;s Blog">
  <meta property="og:title" content="GPT-2 Setup and Pretraining Guide">
  <meta property="og:description" content="This guide explores reproducing GPT-2 (124M) using Andrej Karpathy’s video walkthrough. It begins with an overview of the GPT-2 architecture, a decoder-only transformer model inspired by “Attention Is All You Need.” Using pretrained GPT-2 weights, we analyze and initialize a custom GPT class, with detailed steps to handle token embeddings, causal attention, and layer normalization. The guide includes code for generating text from pretrained weights. In the next segment, we’ll continue with a deeper dive into dataset preparation and training from scratch, moving from small samples to large-scale training.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-10-28T20:00:00+08:00">
    <meta property="article:modified_time" content="2024-10-28T20:00:00+08:00">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="GPT">
    <meta property="article:tag" content="PyTorch">
    <meta property="article:tag" content="LLM">
    <meta property="article:tag" content="NanoGPT">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="GPT-2 Setup and Pretraining Guide">
  <meta name="twitter:description" content="This guide explores reproducing GPT-2 (124M) using Andrej Karpathy’s video walkthrough. It begins with an overview of the GPT-2 architecture, a decoder-only transformer model inspired by “Attention Is All You Need.” Using pretrained GPT-2 weights, we analyze and initialize a custom GPT class, with detailed steps to handle token embeddings, causal attention, and layer normalization. The guide includes code for generating text from pretrained weights. In the next segment, we’ll continue with a deeper dive into dataset preparation and training from scratch, moving from small samples to large-scale training.">

  <meta itemprop="name" content="GPT-2 Setup and Pretraining Guide">
  <meta itemprop="description" content="This guide explores reproducing GPT-2 (124M) using Andrej Karpathy’s video walkthrough. It begins with an overview of the GPT-2 architecture, a decoder-only transformer model inspired by “Attention Is All You Need.” Using pretrained GPT-2 weights, we analyze and initialize a custom GPT class, with detailed steps to handle token embeddings, causal attention, and layer normalization. The guide includes code for generating text from pretrained weights. In the next segment, we’ll continue with a deeper dive into dataset preparation and training from scratch, moving from small samples to large-scale training.">
  <meta itemprop="datePublished" content="2024-10-28T20:00:00+08:00">
  <meta itemprop="dateModified" content="2024-10-28T20:00:00+08:00">
  <meta itemprop="wordCount" content="2463">
  <meta itemprop="keywords" content="AI,GPT,PyTorch,LLM,NanoGPT"><title>GPT-2 Setup and Pretraining Guide | See Hiong&#39;s Blog</title>

    <link rel="canonical" href="https://seehiong.github.io/posts/2024/10/gpt-2-setup-and-pretraining-guide/">

    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    
    
    <link rel="stylesheet" href="/css/variables.css">
    
    <link rel="stylesheet" href="/css/base.css">
    
    <link rel="stylesheet" href="/css/layout.css">
    
    <link rel="stylesheet" href="/css/header.css">
    
    <link rel="stylesheet" href="/css/header.css">
    
    <link rel="stylesheet" href="/css/cards.css">
    
    <link rel="stylesheet" href="/css/content_elements.css">
    
    <link rel="stylesheet" href="/css/codeblocks.css">
    
    <link rel="stylesheet" href="/css/page_specific.css">
    
    <link rel="stylesheet" href="/css/shortcodes.css">
    
    <link rel="stylesheet" href="/css/components.css">
    
    <link rel="stylesheet" href="/css/animations.css">
    
    <link rel="stylesheet" href="/css/media_queries.css">
    
    <link rel="stylesheet" href="/css/quantum-theme.css">
    

    
    <script>
      (function() {
        var theme = localStorage.getItem('theme');
        var H = document.documentElement;
        if (theme === 'dark-mode') {
          H.classList.add('dark-mode');
        } else if (theme === 'light-mode') {
          H.classList.remove('dark-mode');
        } else if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
          H.classList.add('dark-mode');
        }
      })();
    </script>
</head></head>
  <body class="page-article"><nav class="nav">
  <div class="nav-wrapper">
    <div class="nav-content-wrapper">
      <div class="nav-content">
        <a href="/" class="nav-logo-link" title="See Hiong&#39;s Blog - Home">
          
          
          <img src="/images/blog_logo.png" alt="See Hiong&#39;s Blog Logo" class="nav-logo-image">
        </a>
        <div class="nav-menu">
          <div class="nav-item-wrapper">
            
            
            <a href="/posts/" class="nav-item-content active">Archives</a>
            
          </div>
          
          
          <div class="nav-item-wrapper">
            <a href="/tags/" class="nav-item-content ">Tags</a>
          </div>
          <div class="nav-item-wrapper">
            <a href="/about/" class="nav-item-content ">About</a>
          </div>
          <div class="nav-item-wrapper nav-search-toggle-wrapper">
            <button id="nav-search-toggle" class="nav-item-button" aria-label="Toggle search" title="Search">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="18" height="18" fill="currentColor" class="nav-item-icon">
                <path d="M15.5 14h-.79l-.28-.27A6.471 6.471 0 0 0 16 9.5A6.5 6.5 0 1 0 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
              </svg>
            </button>
          </div>
          
          
          <button id="theme-toggle" class="nav-item-button" aria-label="Toggle theme"></button> 
        </div>
      </div>
    </div>
  </div>
</nav>


<script>
  document.addEventListener('DOMContentLoaded', function () {
    const themeToggle = document.getElementById('theme-toggle');
    const H = document.documentElement; 

    if (H.classList.contains('dark-mode')) {
      themeToggle.textContent = 'Light Mode';
    } else {
      themeToggle.textContent = 'Dark Mode';
    }

    themeToggle.addEventListener('click', function() {
      H.classList.toggle('dark-mode');
      if (H.classList.contains('dark-mode')) {
        localStorage.setItem('theme', 'dark-mode');
        themeToggle.textContent = 'Light Mode';
      } else {
        localStorage.setItem('theme', 'light-mode');
        themeToggle.textContent = 'Dark Mode';
      }
    });
  });
</script><div id="content-wrapper">
        <main class="container" id="main-content">
<div class="main-content-area">
  <article class="post-layout container">

    <header class="post-header">
      <h1 class="post-title">GPT-2 Setup and Pretraining Guide</h1>

      <div class="post-meta">
        <span class="post-meta__date">
          <time datetime="2024-10-28T20:00:00&#43;08:00">October 28, 2024</time>
        </span>

        
          <span class="post-meta__author">Written by See Hiong</span>
        

        
          <span class="post-meta__tags">
            In:
            
              <a href="/tags/ai">AI</a>
            
              , <a href="/tags/gpt">GPT</a>
            
              , <a href="/tags/pytorch">PyTorch</a>
            
              , <a href="/tags/llm">LLM</a>
            
              , <a href="/tags/nanogpt">nanoGPT</a>
            
          </span>
        

        
      </div>
    </header>

    
      
      
      <div class="post-cover-container post-cover--artistic-blur-wrapper">
        
          <div class="post-cover-blur-background" style="--bg-image: url('/images/train-llm/gpt-2-setup-and-pretraining-guide.png');"></div>
          <img src="/images/train-llm/gpt-2-setup-and-pretraining-guide.png" alt="GPT-2 Setup and Pretraining Guide cover image" class="post-cover-image post-cover-image--artistic-blur">
        
      </div>
    

    <section class="post-content">
      <p>In this post, I’ll document my journey in learning how to reproduce GPT-2 from scratch using my 6GB NVIDIA RTX A2000 GPU. This is my first attempt at training a model from scratch, and I’m excited to learn from the experts and share my experiences here.</p>
<h2 id="the-basics">The Basics</h2>
<p>I began my journey with the video 






  <a href="https://www.youtube.com/watch?v=UU1WVnMk4E8" target="_blank" rel="noopener noreferrer" >Create a Large Language Model from Scratch with Python</a>
 by 






  <a href="https://github.com/Infatoshi" target="_blank" rel="noopener noreferrer" >Elliot Arledge</a>
. This video covers the fundamentals of large language models (LLMs) and demonstrates how to build one from the ground up. Here, I’ve documented the foundational concepts I extracted from the initial stages of this video.</p>
<h3 id="pytorch-basic-examples">PyTorch Basic Examples</h3>
<p>As part of this journey, I’m learning 






  <a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer" >PyTorch</a>
, an optimized tensor library for deep learning on GPUs and CPUs. In PyTorch, <strong>tensors</strong> are specialized data structures similar to arrays and matrices, with additional capabilities that make them suitable for deep learning.</p>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#cf222e">import</span> <span style="color:#24292e">torch</span>
</span></span><span style="display:flex;"><span>device <span style="color:#0550ae">=</span> <span style="color:#1f2328">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#0a3069">&#34;cuda&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">if</span> torch<span style="color:#0550ae">.</span>cuda<span style="color:#0550ae">.</span>is_available<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">else</span> <span style="color:#0a3069">&#34;mps&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">if</span> torch<span style="color:#0550ae">.</span>backends<span style="color:#0550ae">.</span>mps<span style="color:#0550ae">.</span>is_available<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">else</span> <span style="color:#0a3069">&#34;cpu&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span><span style="color:#0a3069">f</span><span style="color:#0a3069">&#34;Using </span><span style="color:#0a3069">{</span>device<span style="color:#0a3069">}</span><span style="color:#0a3069"> device&#34;</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Output: Using cuda device</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><p>The shape of a tensor in PyTorch refers to its dimensions — the number of elements along each axis. For example, a tensor with shape (2, 3, 4) means:</p>
<ul>
<li>2 elements along the first axis (depth)</li>
<li>3 elements along the second axis (height)</li>
<li>4 elements along the third axis (width)</li>
</ul>
<p>Here are some of the torch functions:</p>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>randint <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>randint<span style="color:#1f2328">(</span><span style="color:#0550ae">-</span><span style="color:#0550ae">100</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">100</span><span style="color:#1f2328">,</span> <span style="color:#1f2328">(</span><span style="color:#0550ae">6</span><span style="color:#1f2328">,))</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>randint<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Output: tensor([-21,   0, -39, -71, -64, -60])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tensor <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>tensor<span style="color:#1f2328">([[</span><span style="color:#0550ae">0.1</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">1.2</span><span style="color:#1f2328">],</span> <span style="color:#1f2328">[</span><span style="color:#0550ae">2.2</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">3.1</span><span style="color:#1f2328">],</span> <span style="color:#1f2328">[</span><span style="color:#0550ae">4.9</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">5.2</span><span style="color:#1f2328">]])</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>tensor<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([[0.1000, 1.2000],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [2.2000, 3.1000],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [4.9000, 5.2000]])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>zeros <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>zeros<span style="color:#1f2328">(</span><span style="color:#0550ae">2</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">3</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>zeros<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([[0., 0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [0., 0., 0.]])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ones <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>ones<span style="color:#1f2328">(</span><span style="color:#0550ae">2</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">3</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>ones<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([[1., 1., 1.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#        [1., 1., 1.]])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">input</span> <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>empty<span style="color:#1f2328">(</span><span style="color:#0550ae">2</span><span style="color:#1f2328">,</span><span style="color:#0550ae">3</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span><span style="color:#6639ba">input</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([[-1.1287e+28,  6.1223e-41, -1.1247e+28],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [ 6.1223e-41,  1.6678e+19,  7.0976e+22]])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>arange <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>arange<span style="color:#1f2328">(</span><span style="color:#0550ae">5</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>arange<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([0, 1, 2, 3, 4])</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div>

































 
  
  





  <img src="/images/train-llm/train-llm-torch-basics.png"   alt="train-llm-torch-basics" class="sc-image sc-image-default"
       >


<h3 id="measuring-time-taken">Measuring Time Taken</h3>
<p>By using the <strong>%%time</strong> magic command at the beginning of a cell, I can measure how long the entire cell takes to run, which helps track and optimize execution time.</p>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#0550ae">%%</span>time
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#cf222e">import</span> <span style="color:#24292e">time</span>
</span></span><span style="display:flex;"><span>start_time <span style="color:#0550ae">=</span> time<span style="color:#0550ae">.</span>time<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>zeros <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>zeros<span style="color:#1f2328">(</span><span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">1</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>end_time <span style="color:#0550ae">=</span> time<span style="color:#0550ae">.</span>time<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>elapsed_time <span style="color:#0550ae">=</span> end_time <span style="color:#0550ae">-</span> start_time
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span><span style="color:#0a3069">f</span><span style="color:#0a3069">&#34;</span><span style="color:#0a3069">{</span>elapsed_time<span style="color:#0a3069">:</span><span style="color:#0a3069">.8f</span><span style="color:#0a3069">}</span><span style="color:#0a3069">&#34;</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Output: 0.00000000 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># CPU times: total: 0 ns</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Wall time: 0 ns</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><h3 id="additional-pytorch-features">Additional PyTorch Features</h3>
<p>Here are some additional PyTorch functions I explored, which I’ll use later in the model-building process. I also explored <em>tril</em>, <em>triu</em>, and <em>masked_fill</em> for manipulating tensor data, and transpose for altering tensor dimensions. These will be helpful for matrix operations and attention mechanisms.</p>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#57606a"># Returns a tensor where each row contains num_samples indices sampled from the multinomial distribution located in the corresponding row of tensor input</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">input</span> <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>tensor<span style="color:#1f2328">([</span><span style="color:#0550ae">0.1</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">0.9</span><span style="color:#1f2328">])</span>
</span></span><span style="display:flex;"><span>samples <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>multinomial<span style="color:#1f2328">(</span><span style="color:#6639ba">input</span><span style="color:#1f2328">,</span> num_samples<span style="color:#0550ae">=</span><span style="color:#0550ae">10</span><span style="color:#1f2328">,</span> replacement<span style="color:#0550ae">=</span><span style="color:#cf222e">True</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>samples<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Output: tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 1])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Concatenates the given sequence of tensors in tensors in the given dimension</span>
</span></span><span style="display:flex;"><span>tensor <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>tensor<span style="color:#1f2328">([</span><span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">2</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">3</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">4</span><span style="color:#1f2328">])</span>
</span></span><span style="display:flex;"><span>out <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>cat<span style="color:#1f2328">((</span>tensor<span style="color:#1f2328">,</span> torch<span style="color:#0550ae">.</span>tensor<span style="color:#1f2328">([</span><span style="color:#0550ae">5</span><span style="color:#1f2328">])),</span> dim<span style="color:#0550ae">=</span><span style="color:#0550ae">0</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>out<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([1, 2, 3, 4, 5])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Returns the lower triangular part of the matrix (2-D tensor), the other elements of the result tensor out are set to 0</span>
</span></span><span style="display:flex;"><span>out <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>tril<span style="color:#1f2328">(</span>torch<span style="color:#0550ae">.</span>ones<span style="color:#1f2328">(</span><span style="color:#0550ae">5</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">5</span><span style="color:#1f2328">))</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>out<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([[1., 0., 0., 0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [1., 1., 0., 0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [1., 1., 1., 0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [1., 1., 1., 1., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [1., 1., 1., 1., 1.]])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Returns the upper triangular part of a matrix (2-D tensor), the other elements of the result tensor out are set to 0</span>
</span></span><span style="display:flex;"><span>out <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>triu<span style="color:#1f2328">(</span>torch<span style="color:#0550ae">.</span>ones<span style="color:#1f2328">(</span><span style="color:#0550ae">5</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">5</span><span style="color:#1f2328">))</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>out<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([[1., 1., 1., 1., 1.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [0., 1., 1., 1., 1.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [0., 0., 1., 1., 1.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [0., 0., 0., 1., 1.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [0., 0., 0., 0., 1.]])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Fills elements of self tensor with value, -inf where mask is True</span>
</span></span><span style="display:flex;"><span>out <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>zeros<span style="color:#1f2328">(</span><span style="color:#0550ae">5</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">5</span><span style="color:#1f2328">)</span><span style="color:#0550ae">.</span>masked_fill<span style="color:#1f2328">(</span>torch<span style="color:#0550ae">.</span>tril<span style="color:#1f2328">(</span>torch<span style="color:#0550ae">.</span>ones<span style="color:#1f2328">(</span><span style="color:#0550ae">5</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">5</span><span style="color:#1f2328">))</span> <span style="color:#0550ae">==</span> <span style="color:#0550ae">0</span><span style="color:#1f2328">,</span> <span style="color:#6639ba">float</span><span style="color:#1f2328">(</span><span style="color:#0a3069">&#39;-inf&#39;</span><span style="color:#1f2328">))</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>out<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([[0., -inf, -inf, -inf, -inf],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [0., 0., -inf, -inf, -inf],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [0., 0., 0., -inf, -inf],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [0., 0., 0., 0., -inf],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [0., 0., 0., 0., 0.]])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Returns a tensor that is a transposed version of input wheret the given dimensions dim0 and dim1 are swapped</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">input</span> <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>zeros<span style="color:#1f2328">(</span><span style="color:#0550ae">2</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">3</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">4</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>out <span style="color:#0550ae">=</span> <span style="color:#6639ba">input</span><span style="color:#0550ae">.</span>transpose<span style="color:#1f2328">(</span><span style="color:#0550ae">0</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">2</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>out<span style="color:#0550ae">.</span>shape<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>out<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># torch.Size([4, 3, 2])</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([[[0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#          [0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#          [0., 0.]],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [[0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#          [0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#          [0., 0.]],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [[0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#          [0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#          [0., 0.]],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [[0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#          [0., 0.],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#          [0., 0.]]])</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><h3 id="linear-transformations">Linear Transformations</h3>
<p>The linear layer in PyTorch applies an affine transformation, represented as \( y = xA^T + b \), where \( y \) is the output, \( x \) is the input, \( A \) is the weight matrix and \( b \) is the bias vector.</p>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#cf222e">import</span> <span style="color:#24292e">torch.nn</span> <span style="color:#cf222e">as</span> <span style="color:#24292e">nn</span>
</span></span><span style="display:flex;"><span>sample <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>tensor<span style="color:#1f2328">([</span><span style="color:#0550ae">10.</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">10.</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">10.</span><span style="color:#1f2328">])</span>
</span></span><span style="display:flex;"><span>linear <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>Linear<span style="color:#1f2328">(</span><span style="color:#0550ae">3</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">3</span><span style="color:#1f2328">,</span> bias<span style="color:#0550ae">=</span><span style="color:#cf222e">False</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>linear<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>linear<span style="color:#1f2328">(</span>sample<span style="color:#1f2328">))</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Output: tensor([10., 10., 10.])</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([-0.8503, -5.8184,  1.0190], grad_fn=&lt;SqueezeBackward4&gt;)</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><h3 id="softmax">Softmax</h3>
<p>The softmax function rescales an input tensor so its elements lie between 0 and 1 and sum to 1. Softmax is defined as:</p>
$$
\text{softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}
$$<p>and \( e \) is a mathematical constant, where \( e \approx 2.71828 \).</p>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#cf222e">import</span> <span style="color:#24292e">torch.nn.functional</span> <span style="color:#cf222e">as</span> <span style="color:#24292e">F</span>
</span></span><span style="display:flex;"><span>tensor1 <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>tensor<span style="color:#1f2328">([</span><span style="color:#0550ae">1.0</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">2.0</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">3.0</span><span style="color:#1f2328">])</span>
</span></span><span style="display:flex;"><span>softmax_output <span style="color:#0550ae">=</span> F<span style="color:#0550ae">.</span>softmax<span style="color:#1f2328">(</span>tensor1<span style="color:#1f2328">,</span> dim<span style="color:#0550ae">=</span><span style="color:#0550ae">0</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>softmax_output<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Output: tensor([0.0900, 0.2447, 0.6652])</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><h3 id="embedding">Embedding</h3>
<p>An embedding layer stores dense representations of a fixed dictionary of words or indices.</p>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#57606a"># Initialize an embedding layer</span>
</span></span><span style="display:flex;"><span>vocab_size <span style="color:#0550ae">=</span> <span style="color:#0550ae">80</span>
</span></span><span style="display:flex;"><span>embedding_dim <span style="color:#0550ae">=</span> <span style="color:#0550ae">6</span>
</span></span><span style="display:flex;"><span>embedding <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>Embedding<span style="color:#1f2328">(</span>vocab_size<span style="color:#1f2328">,</span> embedding_dim<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Create some input indices</span>
</span></span><span style="display:flex;"><span>input_indices <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>LongTensor<span style="color:#1f2328">([</span><span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">5</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">3</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">2</span><span style="color:#1f2328">])</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>input_indices<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Apply the embedding layer</span>
</span></span><span style="display:flex;"><span>embedded_output <span style="color:#0550ae">=</span> embedding<span style="color:#1f2328">(</span>input_indices<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># The output will be a tensor of shape (4, 6), where 4 is the number of inputs</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># and 6 is the dimensionality of the embedding vectors</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>embedded_output<span style="color:#0550ae">.</span>shape<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#0550ae">.</span>Size<span style="color:#1f2328">([</span><span style="color:#0550ae">4</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">6</span><span style="color:#1f2328">])</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([[ 1.1766,  1.3491, -0.2536,  0.5023,  0.4930,  0.3043],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [ 0.3194,  1.2871,  0.5535,  0.7847, -0.1497,  0.6422],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [-1.0683,  1.6570,  0.3645, -1.2519,  2.5594, -1.0523],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#         [ 1.4452, -0.2749,  0.7373,  0.4051, -0.4702, -1.2839]],</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a">#        grad_fn=&lt;EmbeddingBackward0&gt;)</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><h3 id="activation-functions-sigmoid-and-gelu">Activation Functions: Sigmoid and GELU</h3>
<h4 id="sigmoid">Sigmoid</h4>
<p>Sigmoid squashes the input into a range between 0 and 1. It is defined as:</p>
$$ \sigma(x) = \frac{1}{1 + e^x} $$





<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>m <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>Sigmoid<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">input</span> <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>randn<span style="color:#1f2328">(</span><span style="color:#0550ae">2</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>output <span style="color:#0550ae">=</span> m<span style="color:#1f2328">(</span><span style="color:#6639ba">input</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span><span style="color:#6639ba">input</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>output<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([ 0.8731, -0.2994])</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([0.7054, 0.4257])</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><h4 id="gelu">GELU</h4>
<p>GELU (Gaussian Error Linear Units) provides smoother activation, which can enhance model performance. It is defined as:</p>
$$
\text{GELU}(x) = x \cdot \Phi(x)
$$





<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>m <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>GELU<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">input</span> <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>randn<span style="color:#1f2328">(</span><span style="color:#0550ae">2</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>output <span style="color:#0550ae">=</span> m<span style="color:#1f2328">(</span><span style="color:#6639ba">input</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span><span style="color:#6639ba">input</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>output<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([-0.4450, -0.4593])</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># tensor([-0.1460, -0.1484])</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><h3 id="broadcasting-semantics">Broadcasting semantics</h3>
<p>PyTorch operations often support NumPy-style broadcasting, where tensor arguments expand to equal sizes automatically without copying data.</p>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>x <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>tensor<span style="color:#1f2328">([</span><span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">2</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">3</span><span style="color:#1f2328">])</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>x<span style="color:#0550ae">.</span>shape<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>y <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>tensor<span style="color:#1f2328">([[</span><span style="color:#0550ae">1</span><span style="color:#1f2328">],</span> <span style="color:#1f2328">[</span><span style="color:#0550ae">2</span><span style="color:#1f2328">],</span> <span style="color:#1f2328">[</span><span style="color:#0550ae">3</span><span style="color:#1f2328">]])</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>y<span style="color:#0550ae">.</span>shape<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#1f2328">(</span>x<span style="color:#0550ae">+</span>y<span style="color:#1f2328">)</span><span style="color:#0550ae">.</span>size<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># torch.Size([3])</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># torch.Size([3, 1])</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># torch.Size([3, 3])</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><h3 id="standard-deviation">Standard Deviation</h3>
<p>The standard deviation \( (\sigma) \) of a dataset \( X = \{x_1, x_2, \ldots, x_n\} \) is calculated as:</p>
$$ \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2} $$<p>This value indicates the average deviation of the data points from the mean, providing insight into the dataset’s spread.</p>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#cf222e">import</span> <span style="color:#24292e">numpy</span> <span style="color:#cf222e">as</span> <span style="color:#24292e">np</span>
</span></span><span style="display:flex;"><span>data <span style="color:#0550ae">=</span> np<span style="color:#0550ae">.</span>array<span style="color:#1f2328">([</span><span style="color:#0550ae">2</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">4</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">4</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">4</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">5</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">5</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">7</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">9</span><span style="color:#1f2328">])</span>
</span></span><span style="display:flex;"><span>mean <span style="color:#0550ae">=</span> np<span style="color:#0550ae">.</span>mean<span style="color:#1f2328">(</span>data<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>mean<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>squared_diff <span style="color:#0550ae">=</span> <span style="color:#1f2328">(</span>data <span style="color:#0550ae">-</span> mean<span style="color:#1f2328">)</span> <span style="color:#0550ae">**</span> <span style="color:#0550ae">2</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>squared_diff<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>sum_squared_diff <span style="color:#0550ae">=</span> np<span style="color:#0550ae">.</span>sum<span style="color:#1f2328">(</span>squared_diff<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>sum_squared_diff<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>n <span style="color:#0550ae">=</span> <span style="color:#6639ba">len</span><span style="color:#1f2328">(</span>data<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>variance <span style="color:#0550ae">=</span> sum_squared_diff <span style="color:#0550ae">/</span> n
</span></span><span style="display:flex;"><span>std_dev <span style="color:#0550ae">=</span> np<span style="color:#0550ae">.</span>sqrt<span style="color:#1f2328">(</span>variance<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>std_dev<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Output:</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Mean: 5.0</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Square Differences: [ 9.  1.  1.  1.  0.  0.  4. 16.]</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Sum of Squared Differences: 32.0</span>
</span></span><span style="display:flex;"><span><span style="color:#57606a"># Standard Deviation: 2.0</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><hr>
<h2 id="reproducing-gpt-2-from-scratch">Reproducing GPT-2 from Scratch</h2>
<p>After successfully navigating the transformer fundamentals, I took on another challenge with 






  <a href="https://github.com/karpathy" target="_blank" rel="noopener noreferrer" >Andrej Karpathy</a>
’s four-hour tutorial 






  <a href="https://www.youtube.com/watch?v=l8pRSuU81PU" target="_blank" rel="noopener noreferrer" >Let&rsquo;s reproduce GPT-2(124M)</a>
. This section guides you through the model-building and weights-initialization process, and contrasts with the original architecture presented in the landmark paper 






  <a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener noreferrer" >Attention Is All You Need</a>
, which combines encoder and decoder components. GPT-2, however, only utilizes the decoder segment, making it unique in structure and application.</p>


































 
  
  





  <img src="/images/train-llm/The-Transformer-model-architecture.png"   alt="The-Transformer-model-architecture" class="sc-image sc-image-default"
       >


<h3 id="loading-pretrained-gpt-2-weights">Loading Pretrained GPT-2 Weights</h3>
<p>The initial part of the tutorial goes over setting up a pretrained GPT-2 model using the <em>transformers</em> library, allowing us to see how the model behaves with the pretrained weights. Here’s the example provided by Andrej Karpathy, to initiate GPT-2 and generate text based on an input prompt:</p>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#cf222e">from</span> <span style="color:#24292e">transformers</span> <span style="color:#cf222e">import</span> GPT2LMHeadModel
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model_hf <span style="color:#0550ae">=</span> GPT2LMHeadModel<span style="color:#0550ae">.</span>from_pretrained<span style="color:#1f2328">(</span><span style="color:#0a3069">&#34;gpt2&#34;</span><span style="color:#1f2328">)</span> <span style="color:#57606a">#124M</span>
</span></span><span style="display:flex;"><span>sd_hf <span style="color:#0550ae">=</span> model_hf<span style="color:#0550ae">.</span>state_dict<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#cf222e">for</span> k<span style="color:#1f2328">,</span> v <span style="color:#0550ae">in</span> sd_hf<span style="color:#0550ae">.</span>items<span style="color:#1f2328">():</span>
</span></span><span style="display:flex;"><span>    <span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>k<span style="color:#1f2328">,</span> v<span style="color:#0550ae">.</span>shape<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>wpe_weight <span style="color:#0550ae">=</span> sd_hf<span style="color:#1f2328">[</span><span style="color:#0a3069">&#34;transformer.wpe.weight&#34;</span><span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>view<span style="color:#1f2328">(</span><span style="color:#0550ae">-</span><span style="color:#0550ae">1</span><span style="color:#1f2328">)[:</span><span style="color:#0550ae">20</span><span style="color:#1f2328">]</span>
</span></span><span style="display:flex;"><span><span style="color:#6639ba">print</span><span style="color:#1f2328">(</span>wpe_weight<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#cf222e">from</span> <span style="color:#24292e">transformers</span> <span style="color:#cf222e">import</span> pipeline<span style="color:#1f2328">,</span> set_seed
</span></span><span style="display:flex;"><span>generator <span style="color:#0550ae">=</span> pipeline<span style="color:#1f2328">(</span><span style="color:#0a3069">&#39;text-generation&#39;</span><span style="color:#1f2328">,</span> model<span style="color:#0550ae">=</span><span style="color:#0a3069">&#39;gpt2&#39;</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>set_seed<span style="color:#1f2328">(</span><span style="color:#0550ae">42</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>generator<span style="color:#1f2328">(</span><span style="color:#0a3069">&#34;Hello, I&#39;m a language model,&#34;</span><span style="color:#1f2328">,</span> max_length<span style="color:#0550ae">=</span><span style="color:#0550ae">30</span><span style="color:#1f2328">,</span> num_return_sequences<span style="color:#0550ae">=</span><span style="color:#0550ae">5</span><span style="color:#1f2328">)</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><p>This helped in understanding how the weights are structured and provides a baseline for further model modifications.</p>


































 
  
  





  <img src="/images/train-llm/train-llm-pretrained-gpt-2.png"   alt="train-llm-pretrained-gpt-2" class="sc-image sc-image-default"
       >


<h3 id="building-gpt-2-from-scratch">Building GPT-2 from Scratch</h3>
<p>Following the analysis of pretrained weights, Andrej Karpathy started constructing the model from the ground up. The main class includes components like CausalSelfAttention, which handles the attention mechanism, and a simple MLP layer to process the embeddings.</p>
<p>Here’s a snippet of the core setup, where each block layer is defined, and the pretrained weights are loaded into the model for text generation:</p>
<ol>
<li>The initialization:</li>
</ol>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#cf222e">from</span> <span style="color:#24292e">dataclasses</span> <span style="color:#cf222e">import</span> dataclass
</span></span><span style="display:flex;"><span><span style="color:#cf222e">import</span> <span style="color:#24292e">torch</span>
</span></span><span style="display:flex;"><span><span style="color:#cf222e">import</span> <span style="color:#24292e">torch.nn</span> <span style="color:#cf222e">as</span> <span style="color:#24292e">nn</span>
</span></span><span style="display:flex;"><span><span style="color:#cf222e">from</span> <span style="color:#24292e">torch.nn</span> <span style="color:#cf222e">import</span> functional <span style="color:#cf222e">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#cf222e">import</span> <span style="color:#24292e">math</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><ol start="2">
<li>The main GPT class, using the pretrained gpt2 (124M) weights:</li>
</ol>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#cf222e">class</span> <span style="color:#1f2328">CausalSelfAttention</span><span style="color:#1f2328">(</span>nn<span style="color:#0550ae">.</span>Module<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">def</span> <span style="color:#6639ba">__init__</span><span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#1f2328">,</span> config<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6639ba">super</span><span style="color:#1f2328">()</span><span style="color:#0550ae">.</span><span style="color:#6639ba">__init__</span><span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">assert</span> config<span style="color:#0550ae">.</span>n_embd <span style="color:#0550ae">%</span> config<span style="color:#0550ae">.</span>n_head <span style="color:#0550ae">==</span> <span style="color:#0550ae">0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#57606a"># key, query, value projections for all heads, but in a batch</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>c_attn <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>Linear<span style="color:#1f2328">(</span>config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">,</span> <span style="color:#0550ae">3</span> <span style="color:#0550ae">*</span> config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#57606a"># output projection</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>c_proj <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>Linear<span style="color:#1f2328">(</span>config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">,</span> config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#57606a"># regularization</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>n_head <span style="color:#0550ae">=</span> config<span style="color:#0550ae">.</span>n_head
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>n_embd <span style="color:#0550ae">=</span> config<span style="color:#0550ae">.</span>n_embd
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>register_buffer<span style="color:#1f2328">(</span><span style="color:#0a3069">&#34;bias&#34;</span><span style="color:#1f2328">,</span> torch<span style="color:#0550ae">.</span>tril<span style="color:#1f2328">(</span>torch<span style="color:#0550ae">.</span>ones<span style="color:#1f2328">(</span>config<span style="color:#0550ae">.</span>block_size<span style="color:#1f2328">,</span> config<span style="color:#0550ae">.</span>block_size<span style="color:#1f2328">))</span>
</span></span><span style="display:flex;"><span>                                    <span style="color:#0550ae">.</span>view<span style="color:#1f2328">(</span><span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> config<span style="color:#0550ae">.</span>block_size<span style="color:#1f2328">,</span> config<span style="color:#0550ae">.</span>block_size<span style="color:#1f2328">))</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">def</span> <span style="color:#6639ba">forward</span><span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#1f2328">,</span> x<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>        B<span style="color:#1f2328">,</span> T<span style="color:#1f2328">,</span> C <span style="color:#0550ae">=</span> x<span style="color:#0550ae">.</span>size<span style="color:#1f2328">()</span> <span style="color:#57606a"># batch size, sequence length, embedding dimensionality (n_embd)</span>
</span></span><span style="display:flex;"><span>        qkv  <span style="color:#0550ae">=</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>c_attn<span style="color:#1f2328">(</span>x<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        q<span style="color:#1f2328">,</span> k<span style="color:#1f2328">,</span> v <span style="color:#0550ae">=</span> qkv<span style="color:#0550ae">.</span>split<span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">,</span> dim<span style="color:#0550ae">=</span><span style="color:#0550ae">2</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        k <span style="color:#0550ae">=</span> k<span style="color:#0550ae">.</span>view<span style="color:#1f2328">(</span>B<span style="color:#1f2328">,</span> T<span style="color:#1f2328">,</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>n_head<span style="color:#1f2328">,</span> C <span style="color:#0550ae">//</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>n_head<span style="color:#1f2328">)</span><span style="color:#0550ae">.</span>transpose<span style="color:#1f2328">(</span><span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">2</span><span style="color:#1f2328">)</span> <span style="color:#57606a"># (B, nh, T, hs)</span>
</span></span><span style="display:flex;"><span>        q <span style="color:#0550ae">=</span> q<span style="color:#0550ae">.</span>view<span style="color:#1f2328">(</span>B<span style="color:#1f2328">,</span> T<span style="color:#1f2328">,</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>n_head<span style="color:#1f2328">,</span> C <span style="color:#0550ae">//</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>n_head<span style="color:#1f2328">)</span><span style="color:#0550ae">.</span>transpose<span style="color:#1f2328">(</span><span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">2</span><span style="color:#1f2328">)</span> <span style="color:#57606a"># (B, nh, T, hs)</span>
</span></span><span style="display:flex;"><span>        v <span style="color:#0550ae">=</span> v<span style="color:#0550ae">.</span>view<span style="color:#1f2328">(</span>B<span style="color:#1f2328">,</span> T<span style="color:#1f2328">,</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>n_head<span style="color:#1f2328">,</span> C <span style="color:#0550ae">//</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>n_head<span style="color:#1f2328">)</span><span style="color:#0550ae">.</span>transpose<span style="color:#1f2328">(</span><span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">2</span><span style="color:#1f2328">)</span> <span style="color:#57606a"># (B, nh, T, hs)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        att <span style="color:#0550ae">=</span> <span style="color:#1f2328">(</span>q <span style="color:#0550ae">@</span> k<span style="color:#0550ae">.</span>transpose<span style="color:#1f2328">(</span><span style="color:#0550ae">-</span><span style="color:#0550ae">2</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">-</span><span style="color:#0550ae">1</span><span style="color:#1f2328">))</span> <span style="color:#0550ae">*</span> <span style="color:#1f2328">(</span><span style="color:#0550ae">1.0</span> <span style="color:#0550ae">/</span> math<span style="color:#0550ae">.</span>sqrt<span style="color:#1f2328">(</span>k<span style="color:#0550ae">.</span>size<span style="color:#1f2328">(</span><span style="color:#0550ae">-</span><span style="color:#0550ae">1</span><span style="color:#1f2328">)))</span>
</span></span><span style="display:flex;"><span>        att <span style="color:#0550ae">=</span> att<span style="color:#0550ae">.</span>masked_fill<span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>bias<span style="color:#1f2328">[:,:,:</span>T<span style="color:#1f2328">,:</span>T<span style="color:#1f2328">]</span> <span style="color:#0550ae">==</span> <span style="color:#0550ae">0</span><span style="color:#1f2328">,</span> <span style="color:#6639ba">float</span><span style="color:#1f2328">(</span><span style="color:#0a3069">&#39;-inf&#39;</span><span style="color:#1f2328">))</span>
</span></span><span style="display:flex;"><span>        att <span style="color:#0550ae">=</span> F<span style="color:#0550ae">.</span>softmax<span style="color:#1f2328">(</span>att<span style="color:#1f2328">,</span> dim<span style="color:#0550ae">=-</span><span style="color:#0550ae">1</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        y <span style="color:#0550ae">=</span> att <span style="color:#0550ae">@</span> v <span style="color:#57606a"># (B, nh, T, T) x (B, nh, T, hs) -&gt; (B, nh, T, hs)</span>
</span></span><span style="display:flex;"><span>        y <span style="color:#0550ae">=</span> y<span style="color:#0550ae">.</span>transpose<span style="color:#1f2328">(</span><span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> <span style="color:#0550ae">2</span><span style="color:#1f2328">)</span><span style="color:#0550ae">.</span>contiguous<span style="color:#1f2328">()</span><span style="color:#0550ae">.</span>view<span style="color:#1f2328">(</span>B<span style="color:#1f2328">,</span> T<span style="color:#1f2328">,</span> C<span style="color:#1f2328">)</span> <span style="color:#57606a"># re-assemble all head outputs side by side</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#57606a"># output projection</span>
</span></span><span style="display:flex;"><span>        y <span style="color:#0550ae">=</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>c_proj<span style="color:#1f2328">(</span>y<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">return</span> y
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span><span style="color:#cf222e">class</span> <span style="color:#1f2328">MLP</span><span style="color:#1f2328">(</span>nn<span style="color:#0550ae">.</span>Module<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">def</span> <span style="color:#6639ba">__init__</span><span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#1f2328">,</span> config<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6639ba">super</span><span style="color:#1f2328">()</span><span style="color:#0550ae">.</span><span style="color:#6639ba">__init__</span><span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>c_fc    <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>Linear<span style="color:#1f2328">(</span>config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">,</span> <span style="color:#0550ae">4</span> <span style="color:#0550ae">*</span> config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>gelu    <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>GELU<span style="color:#1f2328">(</span>approximate<span style="color:#0550ae">=</span><span style="color:#0a3069">&#39;tanh&#39;</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>c_proj  <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>Linear<span style="color:#1f2328">(</span><span style="color:#0550ae">4</span> <span style="color:#0550ae">*</span> config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">,</span> config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">def</span> <span style="color:#6639ba">forward</span><span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#1f2328">,</span> x<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#0550ae">=</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>c_fc<span style="color:#1f2328">(</span>x<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#0550ae">=</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>gelu<span style="color:#1f2328">(</span>x<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#0550ae">=</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>c_proj<span style="color:#1f2328">(</span>x<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">return</span> x
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span><span style="color:#cf222e">class</span> <span style="color:#1f2328">Block</span><span style="color:#1f2328">(</span>nn<span style="color:#0550ae">.</span>Module<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">def</span> <span style="color:#6639ba">__init__</span><span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#1f2328">,</span> config<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6639ba">super</span><span style="color:#1f2328">()</span><span style="color:#0550ae">.</span><span style="color:#6639ba">__init__</span><span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>ln_1 <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>LayerNorm<span style="color:#1f2328">(</span>config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>attn <span style="color:#0550ae">=</span> CausalSelfAttention<span style="color:#1f2328">(</span>config<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>ln_2 <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>LayerNorm<span style="color:#1f2328">(</span>config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>mlp <span style="color:#0550ae">=</span> MLP<span style="color:#1f2328">(</span>config<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">def</span> <span style="color:#6639ba">forward</span><span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#1f2328">,</span> x<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#0550ae">=</span> x <span style="color:#0550ae">+</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>attn<span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>ln_1<span style="color:#1f2328">(</span>x<span style="color:#1f2328">))</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#0550ae">=</span> x <span style="color:#0550ae">+</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>mlp<span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>ln_2<span style="color:#1f2328">(</span>x<span style="color:#1f2328">))</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">return</span> x
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span><span style="color:#0550ae">@dataclass</span>
</span></span><span style="display:flex;"><span><span style="color:#cf222e">class</span> <span style="color:#1f2328">GPTConfig</span><span style="color:#1f2328">:</span>
</span></span><span style="display:flex;"><span>    block_size<span style="color:#1f2328">:</span> <span style="color:#6639ba">int</span> <span style="color:#0550ae">=</span> <span style="color:#0550ae">1024</span>
</span></span><span style="display:flex;"><span>    vocab_size<span style="color:#1f2328">:</span> <span style="color:#6639ba">int</span> <span style="color:#0550ae">=</span> <span style="color:#0550ae">50257</span>
</span></span><span style="display:flex;"><span>    n_layer<span style="color:#1f2328">:</span> <span style="color:#6639ba">int</span> <span style="color:#0550ae">=</span> <span style="color:#0550ae">12</span>
</span></span><span style="display:flex;"><span>    n_head<span style="color:#1f2328">:</span> <span style="color:#6639ba">int</span> <span style="color:#0550ae">=</span> <span style="color:#0550ae">12</span>
</span></span><span style="display:flex;"><span>    n_embd<span style="color:#1f2328">:</span> <span style="color:#6639ba">int</span> <span style="color:#0550ae">=</span> <span style="color:#0550ae">768</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#cf222e">class</span> <span style="color:#1f2328">GPT</span><span style="color:#1f2328">(</span>nn<span style="color:#0550ae">.</span>Module<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">def</span> <span style="color:#6639ba">__init__</span><span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#1f2328">,</span> config<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6639ba">super</span><span style="color:#1f2328">()</span><span style="color:#0550ae">.</span><span style="color:#6639ba">__init__</span><span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>config <span style="color:#0550ae">=</span> config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>transformer <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>ModuleDict<span style="color:#1f2328">(</span><span style="color:#6639ba">dict</span><span style="color:#1f2328">(</span>
</span></span><span style="display:flex;"><span>            wte <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>Embedding<span style="color:#1f2328">(</span>config<span style="color:#0550ae">.</span>vocab_size<span style="color:#1f2328">,</span> config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">),</span>
</span></span><span style="display:flex;"><span>            wpe <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>Embedding<span style="color:#1f2328">(</span>config<span style="color:#0550ae">.</span>block_size<span style="color:#1f2328">,</span> config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">),</span>
</span></span><span style="display:flex;"><span>            h <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>ModuleList<span style="color:#1f2328">([</span>Block<span style="color:#1f2328">(</span>config<span style="color:#1f2328">)</span> <span style="color:#cf222e">for</span> _ <span style="color:#0550ae">in</span> <span style="color:#6639ba">range</span><span style="color:#1f2328">(</span>config<span style="color:#0550ae">.</span>n_layer<span style="color:#1f2328">)]),</span>
</span></span><span style="display:flex;"><span>            ln_f <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>LayerNorm<span style="color:#1f2328">(</span>config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">),</span>
</span></span><span style="display:flex;"><span>        <span style="color:#1f2328">))</span>
</span></span><span style="display:flex;"><span>        <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>lm_head <span style="color:#0550ae">=</span> nn<span style="color:#0550ae">.</span>Linear<span style="color:#1f2328">(</span>config<span style="color:#0550ae">.</span>n_embd<span style="color:#1f2328">,</span> config<span style="color:#0550ae">.</span>vocab_size<span style="color:#1f2328">,</span> bias<span style="color:#0550ae">=</span><span style="color:#cf222e">False</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">def</span> <span style="color:#6639ba">forward</span><span style="color:#1f2328">(</span><span style="color:#6a737d">self</span><span style="color:#1f2328">,</span> idx<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>        B<span style="color:#1f2328">,</span> T <span style="color:#0550ae">=</span> idx<span style="color:#0550ae">.</span>size<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">assert</span> T <span style="color:#0550ae">&lt;=</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>config<span style="color:#0550ae">.</span>block_size<span style="color:#1f2328">,</span> <span style="color:#0a3069">f</span><span style="color:#0a3069">&#34;Cannot forward sequence of length </span><span style="color:#0a3069">{</span>t<span style="color:#0a3069">}</span><span style="color:#0a3069">, block size is only </span><span style="color:#0a3069">{</span><span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>config<span style="color:#0550ae">.</span>block_size<span style="color:#0a3069">}</span><span style="color:#0a3069">&#34;</span>
</span></span><span style="display:flex;"><span>        pos <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>arange<span style="color:#1f2328">(</span><span style="color:#0550ae">0</span><span style="color:#1f2328">,</span> T<span style="color:#1f2328">,</span> dtype<span style="color:#0550ae">=</span>torch<span style="color:#0550ae">.</span>long<span style="color:#1f2328">,</span> device<span style="color:#0550ae">=</span>idx<span style="color:#0550ae">.</span>device<span style="color:#1f2328">)</span> <span style="color:#57606a"># shape (t)</span>
</span></span><span style="display:flex;"><span>        pos_emb <span style="color:#0550ae">=</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>transformer<span style="color:#0550ae">.</span>wpe<span style="color:#1f2328">(</span>pos<span style="color:#1f2328">)</span> <span style="color:#57606a"># position embeddings of shape (t, n_embd)</span>
</span></span><span style="display:flex;"><span>        tok_emb <span style="color:#0550ae">=</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>transformer<span style="color:#0550ae">.</span>wte<span style="color:#1f2328">(</span>idx<span style="color:#1f2328">)</span> <span style="color:#57606a"># token embeddings of shape (b, t, n_embd)</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#0550ae">=</span> tok_emb <span style="color:#0550ae">+</span> pos_emb
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">for</span> block <span style="color:#0550ae">in</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>transformer<span style="color:#0550ae">.</span>h<span style="color:#1f2328">:</span>
</span></span><span style="display:flex;"><span>            x <span style="color:#0550ae">=</span> block<span style="color:#1f2328">(</span>x<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#0550ae">=</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>transformer<span style="color:#0550ae">.</span>ln_f<span style="color:#1f2328">(</span>x<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        logits <span style="color:#0550ae">=</span> <span style="color:#6a737d">self</span><span style="color:#0550ae">.</span>lm_head<span style="color:#1f2328">(</span>x<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">return</span> logits
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#0550ae">@classmethod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">def</span> <span style="color:#6639ba">from_pretrained</span><span style="color:#1f2328">(</span><span style="color:#6a737d">cls</span><span style="color:#1f2328">,</span> model_type<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">assert</span> model_type <span style="color:#0550ae">in</span> <span style="color:#1f2328">{</span><span style="color:#0a3069">&#39;gpt2&#39;</span><span style="color:#1f2328">,</span> <span style="color:#0a3069">&#39;gpt2-medium&#39;</span><span style="color:#1f2328">,</span> <span style="color:#0a3069">&#39;gpt2-large&#39;</span><span style="color:#1f2328">,</span> <span style="color:#0a3069">&#39;gpt2-xl&#39;</span><span style="color:#1f2328">}</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">from</span> <span style="color:#24292e">transformers</span> <span style="color:#cf222e">import</span> GPT2LMHeadModel
</span></span><span style="display:flex;"><span>        <span style="color:#6639ba">print</span><span style="color:#1f2328">(</span><span style="color:#0a3069">&#34;loading weights from pretrained gpt: </span><span style="color:#0a3069">%s</span><span style="color:#0a3069">&#34;</span> <span style="color:#0550ae">%</span> model_type<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#57606a"># n_layer, n_head and n_embd are determined from model_type</span>
</span></span><span style="display:flex;"><span>        config_args <span style="color:#0550ae">=</span> <span style="color:#1f2328">{</span>
</span></span><span style="display:flex;"><span>            <span style="color:#0a3069">&#39;gpt2&#39;</span><span style="color:#1f2328">:</span>         <span style="color:#6639ba">dict</span><span style="color:#1f2328">(</span>n_layer<span style="color:#0550ae">=</span><span style="color:#0550ae">12</span><span style="color:#1f2328">,</span> n_head<span style="color:#0550ae">=</span><span style="color:#0550ae">12</span><span style="color:#1f2328">,</span> n_embd<span style="color:#0550ae">=</span><span style="color:#0550ae">768</span><span style="color:#1f2328">),</span>  <span style="color:#57606a"># 124M params</span>
</span></span><span style="display:flex;"><span>            <span style="color:#0a3069">&#39;gpt2-medium&#39;</span><span style="color:#1f2328">:</span>  <span style="color:#6639ba">dict</span><span style="color:#1f2328">(</span>n_layer<span style="color:#0550ae">=</span><span style="color:#0550ae">24</span><span style="color:#1f2328">,</span> n_head<span style="color:#0550ae">=</span><span style="color:#0550ae">16</span><span style="color:#1f2328">,</span> n_embd<span style="color:#0550ae">=</span><span style="color:#0550ae">1024</span><span style="color:#1f2328">),</span> <span style="color:#57606a"># 350M params</span>
</span></span><span style="display:flex;"><span>            <span style="color:#0a3069">&#39;gpt2-large&#39;</span><span style="color:#1f2328">:</span>   <span style="color:#6639ba">dict</span><span style="color:#1f2328">(</span>n_layer<span style="color:#0550ae">=</span><span style="color:#0550ae">36</span><span style="color:#1f2328">,</span> n_head<span style="color:#0550ae">=</span><span style="color:#0550ae">20</span><span style="color:#1f2328">,</span> n_embd<span style="color:#0550ae">=</span><span style="color:#0550ae">1280</span><span style="color:#1f2328">),</span> <span style="color:#57606a"># 774M params</span>
</span></span><span style="display:flex;"><span>            <span style="color:#0a3069">&#39;gpt2-xl&#39;</span><span style="color:#1f2328">:</span>      <span style="color:#6639ba">dict</span><span style="color:#1f2328">(</span>n_layer<span style="color:#0550ae">=</span><span style="color:#0550ae">48</span><span style="color:#1f2328">,</span> n_head<span style="color:#0550ae">=</span><span style="color:#0550ae">25</span><span style="color:#1f2328">,</span> n_embd<span style="color:#0550ae">=</span><span style="color:#0550ae">1600</span><span style="color:#1f2328">),</span> <span style="color:#57606a"># 1558M params</span>
</span></span><span style="display:flex;"><span>        <span style="color:#1f2328">}[</span>model_type<span style="color:#1f2328">]</span>
</span></span><span style="display:flex;"><span>        config_args<span style="color:#1f2328">[</span><span style="color:#0a3069">&#39;vocab_size&#39;</span><span style="color:#1f2328">]</span> <span style="color:#0550ae">=</span> <span style="color:#0550ae">50257</span> <span style="color:#57606a"># always 50257 for GPT model checkpoints</span>
</span></span><span style="display:flex;"><span>        config_args<span style="color:#1f2328">[</span><span style="color:#0a3069">&#39;block_size&#39;</span><span style="color:#1f2328">]</span> <span style="color:#0550ae">=</span> <span style="color:#0550ae">1024</span> <span style="color:#57606a"># always 1024 for GPT model checkpoints      </span>
</span></span><span style="display:flex;"><span>        <span style="color:#57606a"># create a from-scratch initialized minGPT model</span>
</span></span><span style="display:flex;"><span>        config <span style="color:#0550ae">=</span> GPTConfig<span style="color:#1f2328">(</span><span style="color:#0550ae">**</span>config_args<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        model <span style="color:#0550ae">=</span> GPT<span style="color:#1f2328">(</span>config<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        sd <span style="color:#0550ae">=</span> model<span style="color:#0550ae">.</span>state_dict<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>        sd_keys <span style="color:#0550ae">=</span> sd<span style="color:#0550ae">.</span>keys<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>        sd_keys <span style="color:#0550ae">=</span> <span style="color:#1f2328">[</span>k <span style="color:#cf222e">for</span> k <span style="color:#0550ae">in</span> sd_keys <span style="color:#cf222e">if</span> <span style="color:#0550ae">not</span> k<span style="color:#0550ae">.</span>endswith<span style="color:#1f2328">(</span><span style="color:#0a3069">&#39;.attn.bias&#39;</span><span style="color:#1f2328">)]</span> <span style="color:#57606a"># discard this mask / buffer, not a param</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#57606a"># init a huggingface/transformers model</span>
</span></span><span style="display:flex;"><span>        model_hf <span style="color:#0550ae">=</span> GPT2LMHeadModel<span style="color:#0550ae">.</span>from_pretrained<span style="color:#1f2328">(</span>model_type<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        sd_hf <span style="color:#0550ae">=</span> model_hf<span style="color:#0550ae">.</span>state_dict<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#57606a"># copy while ensuring all of the parameters are aligned and match in names and shapes</span>
</span></span><span style="display:flex;"><span>        sd_keys_hf <span style="color:#0550ae">=</span> sd_hf<span style="color:#0550ae">.</span>keys<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>        sd_keys_hf <span style="color:#0550ae">=</span> <span style="color:#1f2328">[</span>k <span style="color:#cf222e">for</span> k <span style="color:#0550ae">in</span> sd_keys_hf <span style="color:#cf222e">if</span> <span style="color:#0550ae">not</span> k<span style="color:#0550ae">.</span>endswith<span style="color:#1f2328">(</span><span style="color:#0a3069">&#39;.attn.masked_bias&#39;</span><span style="color:#1f2328">)]</span> <span style="color:#57606a"># ignore these, just a buffer</span>
</span></span><span style="display:flex;"><span>        sd_keys_hf <span style="color:#0550ae">=</span> <span style="color:#1f2328">[</span>k <span style="color:#cf222e">for</span> k <span style="color:#0550ae">in</span> sd_keys_hf <span style="color:#cf222e">if</span> <span style="color:#0550ae">not</span> k<span style="color:#0550ae">.</span>endswith<span style="color:#1f2328">(</span><span style="color:#0a3069">&#39;.attn.bias&#39;</span><span style="color:#1f2328">)]</span> <span style="color:#57606a"># same, just the mask (buffer)</span>
</span></span><span style="display:flex;"><span>        transposed <span style="color:#0550ae">=</span> <span style="color:#1f2328">[</span><span style="color:#0a3069">&#39;attn.c_attn.weight&#39;</span><span style="color:#1f2328">,</span> <span style="color:#0a3069">&#39;attn.c_proj.weight&#39;</span><span style="color:#1f2328">,</span> <span style="color:#0a3069">&#39;mlp.c_fc.weight&#39;</span><span style="color:#1f2328">,</span> <span style="color:#0a3069">&#39;mlp.c_proj.weight&#39;</span><span style="color:#1f2328">]</span>
</span></span><span style="display:flex;"><span>        <span style="color:#57606a"># basically the openai checkpoints use a &#34;Conv1D&#34; module, but we only want to use a vanilla Linear</span>
</span></span><span style="display:flex;"><span>        <span style="color:#57606a"># this means that we have to transpose these weights when we import them</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">assert</span> <span style="color:#6639ba">len</span><span style="color:#1f2328">(</span>sd_keys_hf<span style="color:#1f2328">)</span> <span style="color:#0550ae">==</span> <span style="color:#6639ba">len</span><span style="color:#1f2328">(</span>sd_keys<span style="color:#1f2328">),</span> <span style="color:#0a3069">f</span><span style="color:#0a3069">&#34;mismatched keys: </span><span style="color:#0a3069">{</span><span style="color:#6639ba">len</span><span style="color:#1f2328">(</span>sd_keys_hf<span style="color:#1f2328">)</span><span style="color:#0a3069">}</span><span style="color:#0a3069"> != </span><span style="color:#0a3069">{</span><span style="color:#6639ba">len</span><span style="color:#1f2328">(</span>sd_keys<span style="color:#1f2328">)</span><span style="color:#0a3069">}</span><span style="color:#0a3069">&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">for</span> k <span style="color:#0550ae">in</span> sd_keys_hf<span style="color:#1f2328">:</span>
</span></span><span style="display:flex;"><span>            <span style="color:#cf222e">if</span> <span style="color:#6639ba">any</span><span style="color:#1f2328">(</span>k<span style="color:#0550ae">.</span>endswith<span style="color:#1f2328">(</span>w<span style="color:#1f2328">)</span> <span style="color:#cf222e">for</span> w <span style="color:#0550ae">in</span> transposed<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>                <span style="color:#57606a"># special treatment for the Conv1D weights we need to transpose</span>
</span></span><span style="display:flex;"><span>                <span style="color:#cf222e">assert</span> sd_hf<span style="color:#1f2328">[</span>k<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>shape<span style="color:#1f2328">[::</span><span style="color:#0550ae">-</span><span style="color:#0550ae">1</span><span style="color:#1f2328">]</span> <span style="color:#0550ae">==</span> sd<span style="color:#1f2328">[</span>k<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>shape<span style="color:#1f2328">,</span> <span style="color:#0a3069">f</span><span style="color:#0a3069">&#34;Shape mismatch for </span><span style="color:#0a3069">{</span>k<span style="color:#0a3069">}</span><span style="color:#0a3069">: </span><span style="color:#0a3069">{</span>sd_hf<span style="color:#1f2328">[</span>k<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>shape<span style="color:#1f2328">[::</span><span style="color:#0550ae">-</span><span style="color:#0550ae">1</span><span style="color:#1f2328">]</span><span style="color:#0a3069">}</span><span style="color:#0a3069"> vs </span><span style="color:#0a3069">{</span>sd<span style="color:#1f2328">[</span>k<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>shape<span style="color:#0a3069">}</span><span style="color:#0a3069">&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#cf222e">with</span> torch<span style="color:#0550ae">.</span>no_grad<span style="color:#1f2328">():</span>
</span></span><span style="display:flex;"><span>                    sd<span style="color:#1f2328">[</span>k<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>copy_<span style="color:#1f2328">(</span>sd_hf<span style="color:#1f2328">[</span>k<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>t<span style="color:#1f2328">())</span>
</span></span><span style="display:flex;"><span>            <span style="color:#cf222e">else</span><span style="color:#1f2328">:</span>
</span></span><span style="display:flex;"><span>                <span style="color:#57606a"># vanilla copy over the other parameters</span>
</span></span><span style="display:flex;"><span>                <span style="color:#cf222e">assert</span> sd_hf<span style="color:#1f2328">[</span>k<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>shape <span style="color:#0550ae">==</span> sd<span style="color:#1f2328">[</span>k<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>shape<span style="color:#1f2328">,</span> <span style="color:#0a3069">f</span><span style="color:#0a3069">&#34;Shape mismatch for </span><span style="color:#0a3069">{</span>k<span style="color:#0a3069">}</span><span style="color:#0a3069">: </span><span style="color:#0a3069">{</span>sd_hf<span style="color:#1f2328">[</span>k<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>shape<span style="color:#0a3069">}</span><span style="color:#0a3069"> vs </span><span style="color:#0a3069">{</span>sd<span style="color:#1f2328">[</span>k<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>shape<span style="color:#0a3069">}</span><span style="color:#0a3069">&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#cf222e">with</span> torch<span style="color:#0550ae">.</span>no_grad<span style="color:#1f2328">():</span>
</span></span><span style="display:flex;"><span>                    sd<span style="color:#1f2328">[</span>k<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>copy_<span style="color:#1f2328">(</span>sd_hf<span style="color:#1f2328">[</span>k<span style="color:#1f2328">])</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#cf222e">return</span> model</span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><ol start="3">
<li>Text generation for the main GPT class using the pretrained weights:</li>
</ol>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>num_return_sequences <span style="color:#0550ae">=</span> <span style="color:#0550ae">5</span>
</span></span><span style="display:flex;"><span>max_length <span style="color:#0550ae">=</span> <span style="color:#0550ae">30</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#0550ae">=</span> GPT<span style="color:#0550ae">.</span>from_pretrained<span style="color:#1f2328">(</span><span style="color:#0a3069">&#39;gpt2&#39;</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>model<span style="color:#0550ae">.</span>eval<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>model<span style="color:#0550ae">.</span>to<span style="color:#1f2328">(</span><span style="color:#0a3069">&#39;cuda&#39;</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#cf222e">import</span> <span style="color:#24292e">tiktoken</span>
</span></span><span style="display:flex;"><span>enc <span style="color:#0550ae">=</span> tiktoken<span style="color:#0550ae">.</span>get_encoding<span style="color:#1f2328">(</span><span style="color:#0a3069">&#39;gpt2&#39;</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>tokens <span style="color:#0550ae">=</span> enc<span style="color:#0550ae">.</span>encode<span style="color:#1f2328">(</span><span style="color:#0a3069">&#34;Hello, I&#39;m a language model,&#34;</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>tokens <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>tensor<span style="color:#1f2328">(</span>tokens<span style="color:#1f2328">,</span> dtype<span style="color:#0550ae">=</span>torch<span style="color:#0550ae">.</span>long<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>tokens <span style="color:#0550ae">=</span> tokens<span style="color:#0550ae">.</span>unsqueeze<span style="color:#1f2328">(</span><span style="color:#0550ae">0</span><span style="color:#1f2328">)</span><span style="color:#0550ae">.</span>repeat<span style="color:#1f2328">(</span>num_return_sequences<span style="color:#1f2328">,</span> <span style="color:#0550ae">1</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>x <span style="color:#0550ae">=</span> tokens<span style="color:#0550ae">.</span>to<span style="color:#1f2328">(</span><span style="color:#0a3069">&#39;cuda&#39;</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch<span style="color:#0550ae">.</span>manual_seed<span style="color:#1f2328">(</span><span style="color:#0550ae">42</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#0550ae">.</span>cuda<span style="color:#0550ae">.</span>manual_seed<span style="color:#1f2328">(</span><span style="color:#0550ae">42</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span><span style="color:#cf222e">while</span> x<span style="color:#0550ae">.</span>size<span style="color:#1f2328">(</span><span style="color:#0550ae">1</span><span style="color:#1f2328">)</span> <span style="color:#0550ae">&lt;</span> max_length<span style="color:#1f2328">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#cf222e">with</span> torch<span style="color:#0550ae">.</span>no_grad<span style="color:#1f2328">():</span>
</span></span><span style="display:flex;"><span>        logits <span style="color:#0550ae">=</span> model<span style="color:#1f2328">(</span>x<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        logits <span style="color:#0550ae">=</span> logits<span style="color:#1f2328">[:,</span> <span style="color:#0550ae">-</span><span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> <span style="color:#1f2328">:]</span>
</span></span><span style="display:flex;"><span>        probs <span style="color:#0550ae">=</span> F<span style="color:#0550ae">.</span>softmax<span style="color:#1f2328">(</span>logits<span style="color:#1f2328">,</span> dim<span style="color:#0550ae">=-</span><span style="color:#0550ae">1</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        topk_probs<span style="color:#1f2328">,</span> topk_indices <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>topk<span style="color:#1f2328">(</span>probs<span style="color:#1f2328">,</span> <span style="color:#0550ae">50</span><span style="color:#1f2328">,</span> dim<span style="color:#0550ae">=-</span><span style="color:#0550ae">1</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        ix <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>multinomial<span style="color:#1f2328">(</span>topk_probs<span style="color:#1f2328">,</span> <span style="color:#0550ae">1</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        xcol <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>gather<span style="color:#1f2328">(</span>topk_indices<span style="color:#1f2328">,</span> <span style="color:#0550ae">-</span><span style="color:#0550ae">1</span><span style="color:#1f2328">,</span> ix<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#0550ae">=</span> torch<span style="color:#0550ae">.</span>cat<span style="color:#1f2328">((</span>x<span style="color:#1f2328">,</span> xcol<span style="color:#1f2328">),</span> dim<span style="color:#0550ae">=</span><span style="color:#0550ae">1</span><span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#cf222e">for</span> i <span style="color:#0550ae">in</span> <span style="color:#6639ba">range</span><span style="color:#1f2328">(</span>num_return_sequences<span style="color:#1f2328">):</span>
</span></span><span style="display:flex;"><span>    tokens <span style="color:#0550ae">=</span> x<span style="color:#1f2328">[</span>i<span style="color:#1f2328">,</span> <span style="color:#1f2328">:</span>max_length<span style="color:#1f2328">]</span><span style="color:#0550ae">.</span>tolist<span style="color:#1f2328">()</span>
</span></span><span style="display:flex;"><span>    decoded <span style="color:#0550ae">=</span> enc<span style="color:#0550ae">.</span>decode<span style="color:#1f2328">(</span>tokens<span style="color:#1f2328">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#6639ba">print</span><span style="color:#1f2328">(</span><span style="color:#0a3069">&#34;&gt;&#34;</span><span style="color:#1f2328">,</span> decoded<span style="color:#1f2328">)</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div>

































 
  
  





  <img src="/images/train-llm/train-llm-loading-weights-from-pretrained-gpt-2.png"   alt="train-llm-loading-weights-from-pretrained-gpt-2" class="sc-image sc-image-default"
       >


<h2 id="wrapping-up-the-pretrained-model-setup">Wrapping Up the Pretrained Model Setup</h2>
<p>In this post, we&rsquo;ve explored the foundational setup for loading pretrained GPT-2 weights and performing basic text generation. From analyzing the pretrained model structure to initializing and modifying key parameters, this approach sets the stage for a deeper dive into the intricacies of GPT-2. We&rsquo;ve also covered the essentials for leveraging existing weights to understand and test the model&rsquo;s capabilities.</p>
<p>In the next part, we&rsquo;ll continue following Andrej Karpathy&rsquo;s video as he takes the GPT-2 model through hands-on training with actual datasets. We&rsquo;ll start with a small sample text to see the practical aspects of text generation training, followed by scaling to larger datasets.</p>
<h2 id="optional---generate-model-from-scratch">Optional - Generate Model from Scratch</h2>
<p>To create a model entirely from scratch, we can leverage PyTorch’s default random initialization rather than loading GPT-2’s pretrained weights.</p>
<p>The only modification needed in the configuration is as follows:</p>






<div class="code-block-wrapper">
  <div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#57606a"># model = GPT.from_pretrained(&#39;gpt2&#39;)</span>
</span></span><span style="display:flex;"><span>model <span style="color:#0550ae">=</span> GPT<span style="color:#1f2328">(</span>GPTConfig<span style="color:#1f2328">())</span></span></span></code></pre></div>
  <button class="copy-code-button" aria-label="Copy code to clipboard" title="Copy code">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="copy-icon">
      <path d="M16 1H4c-1.1 0-2 .9-2 2v14h2V3h12V1zm3 4H8c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h11c1.1 0 2-.9 2-2V7c0-1.1-.9-2-2-2zm0 16H8V7h11v14z"/>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16" fill="currentColor" class="check-icon" style="display:none;">
      <path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/>
    </svg>
    <span class="copy-text">Copy</span>
  </button>
</div><p>This setup will allow us to train a randomly initialized GPT model, shown below.</p>


































 
  
  





  <img src="/images/train-llm/train-llm-random-model.png"   alt="train-llm-random-model" class="sc-image sc-image-default"
       >



    </section>

    <nav class="post-navigation">
      <div class="nav-links">
        
          <div class="nav-previous">
            <a href="/posts/2024/10/integrating-mlflow-and-kubeflow-on-talos/" rel="prev">
              <span class="meta-nav">← Previous</span>
              <span class="post-title">Integrating MLflow and Kubeflow on Talos</span>
            </a>
          </div>
        
        
          <div class="nav-next">
            <a href="/posts/2024/10/gpt-2-training-guide/" rel="next">
              <span class="meta-nav">Next →</span>
              <span class="post-title">GPT-2 Training Guide</span>
            </a>
          </div>
        
      </div>
    </nav>

    
<div class="giscus-comments-container">
</div>

<script>
  (function() {
    'use strict';

    const getGiscusTheme = () => {
      const storedTheme = localStorage.getItem('theme'); 
      if (storedTheme) {
        return storedTheme === 'dark-mode' ? 'dark' : 'light';
      }
      return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
    };

    const setGiscusFrameTheme = (theme) => {
      const iframe = document.querySelector('iframe.giscus-frame');
      if (iframe && iframe.contentWindow) {
        iframe.contentWindow.postMessage({ giscus: { setConfig: { theme: theme } } }, 'https://giscus.app');
      }
    };

    const loadGiscus = () => {
      const giscusContainer = document.querySelector('.giscus-comments-container');
      if (!giscusContainer) {
        console.warn('Giscus container not found.');
        return;
      }

      while (giscusContainer.firstChild) {
        giscusContainer.removeChild(giscusContainer.firstChild);
      }

      const giscusScript = document.createElement('script');
      const giscusAttributes = {
        "src": "https://giscus.app/client.js",
        "data-repo":             "seehiong\/seehiong.github.io",
        "data-repo-id":          "R_kgDOJg7Puw",
        "data-category":         "General",
        "data-category-id":      "DIC_kwDOJg7Pu84Cbyhc",
        "data-mapping":          "url", 
        "data-strict":           "0",
        "data-reactions-enabled":"1",
        "data-emit-metadata":    "0",
        "data-input-position":   "top", 
        "data-theme":            getGiscusTheme(), 
        "data-lang":             "en",
        "data-loading":          "lazy",
        "crossorigin":           "anonymous",
        "async":                 "true", 
      };

      if (!giscusAttributes["data-repo"] || !giscusAttributes["data-repo-id"] || !giscusAttributes["data-category-id"]) {
          console.error("Giscus parameters (giscusRepo, giscusRepoId, giscusCategoryId) are not configured in hugo.toml.");
          giscusContainer.innerHTML = "<p style='color: var(--text-secondary);'>Giscus comments are not configured correctly. Please check site parameters.</p>";
          return;
      }

      Object.entries(giscusAttributes).forEach(
        ([key, value]) => giscusScript.setAttribute(key, value)
      );
      giscusContainer.appendChild(giscusScript);
    };

    if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', loadGiscus);
    } else {
        loadGiscus();
    }

    const htmlElement = document.documentElement;
    const observer = new MutationObserver((mutationsList) => {
      for (const mutation of mutationsList) {
        if (mutation.type === 'attributes' && mutation.attributeName === 'class') {
          setGiscusFrameTheme(getGiscusTheme());
        }
      }
    });
    observer.observe(htmlElement, { attributes: true });

  })();
</script>


  </article>
</div>
</main>
    </div>

    
    <div id="search-modal-overlay" class="search-modal-overlay" style="display: none;">
      <div id="search-modal-content" class="search-modal-content">
        <button id="search-modal-close" class="search-modal-close" aria-label="Close search" title="Close search">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="20" height="20" fill="currentColor">
            <path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/>
          </svg>
        </button>
        <input type="search" id="modal-search-input" class="modal-search-input" placeholder="Search content..." aria-label="Search input">
        <div id="modal-search-results" class="modal-search-results">
        </div>
      </div>
    </div>
    

  <script src="https://cdn.jsdelivr.net/npm/fuse.js/dist/fuse.min.js" defer></script>
  <script>
    (function() {
      'use strict';

      window.addEventListener('DOMContentLoaded', () => {
        const searchModalOverlay = document.getElementById('search-modal-overlay');
        const searchModalContent = document.getElementById('search-modal-content');
        const searchModalCloseButton = document.getElementById('search-modal-close');
        const searchToggleButton = document.getElementById('nav-search-toggle');
        const searchInputTarget = document.getElementById('modal-search-input');
        const searchResultsTarget = document.getElementById('modal-search-results');

        let fuseInstance = null;
        let searchData = [];

        const loadSearchData = async () => {
          if (searchData.length === 0 && !fuseInstance) {
            try {
              const response = await fetch('\/index.json');
              if (!response.ok) {
                throw new Error(`HTTP error loading index.json! status: ${response.status}`);
              }
              searchData = await response.json();
              initializeFuse();
            } catch (e) {
              console.error("[SearchSetup] Error loading search data:", e);
              if (searchResultsTarget) searchResultsTarget.innerHTML = "<p>Error loading search index.</p>";
            }
          } else if (searchData.length > 0 && !fuseInstance){
            initializeFuse();
          }
        };

        const initializeFuse = () => {
          if (searchData.length > 0 && !fuseInstance) {
            const options = {
              keys: [
                { name: 'title', weight: 0.7 }, { name: 'summary', weight: 0.5 },
                { name: 'content', weight: 0.3 }, { name: 'tags', weight: 0.4 }
              ],
              includeScore: true, threshold: 0.4, minMatchCharLength: 2,
            };
            fuseInstance = new Fuse(searchData, options);
          }
        };

        const performSearch = () => {
          if (!fuseInstance || !searchInputTarget || !searchResultsTarget) return;
          const query = searchInputTarget.value.trim();
          searchResultsTarget.innerHTML = '';
          if (query.length < 2) return;

          const results = fuseInstance.search(query);
          if (results.length > 0) {
            const ul = document.createElement('ul');
            ul.className = 'search-results-list';
            results.slice(0, 10).forEach(result => {
              const item = result.item;
              const li = document.createElement('li');
              li.className = 'search-result-item';
              const a = document.createElement('a');
              a.href = item.permalink;
              a.textContent = item.title;
              li.appendChild(a);
              ul.appendChild(li);
            });
            searchResultsTarget.appendChild(ul);
          } else {
            searchResultsTarget.innerHTML = '<p>No results found.</p>';
          }
        };

        const openSearchModal = async () => {
          await loadSearchData();
          if (searchInputTarget) searchInputTarget.value = '';
          if (searchResultsTarget) searchResultsTarget.innerHTML = '';

          if (searchModalOverlay) {
            searchModalOverlay.style.display = 'flex';
            setTimeout(() => searchModalOverlay.classList.add('active'), 10);
          } else { return; }

          if (searchInputTarget) setTimeout(() => searchInputTarget.focus(), 50);
          if (searchToggleButton) searchToggleButton.classList.add('active');
        };

        const closeSearchModal = () => {
          if (searchModalOverlay) {
            searchModalOverlay.classList.remove('active');
            setTimeout(() => searchModalOverlay.style.display = 'none', 300);
          }
          if (searchToggleButton) searchToggleButton.classList.remove('active');
        };

        if (searchToggleButton) {
          searchToggleButton.addEventListener('click', (e) => {
            e.stopPropagation();
            if (searchModalOverlay && searchModalOverlay.classList.contains('active')) {
              closeSearchModal();
            } else {
              openSearchModal();
            }
          });
        } else { console.error("[SearchSetup] #nav-search-toggle button not found."); }

        if (searchModalCloseButton) { searchModalCloseButton.addEventListener('click', closeSearchModal); }
        if (searchModalOverlay && searchModalContent) {
          searchModalOverlay.addEventListener('click', (event) => {
            if (event.target === searchModalOverlay) closeSearchModal();
          });
        }
        document.addEventListener('keydown', (event) => {
          if (event.key === 'Escape' && searchModalOverlay && searchModalOverlay.classList.contains('active')) {
            closeSearchModal();
          }
        });
        if (searchInputTarget) {
          let debounceTimer;
          searchInputTarget.addEventListener('input', () => {
            clearTimeout(debounceTimer);
            debounceTimer = setTimeout(performSearch, 300);
          });
        }
      });
    })();
  </script>

    

    

  <script>
    MathJax = {
      tex: {
        displayMath: [['\\[', '\\]'], ['$$', '$$']], 
        inlineMath: [['\\(', '\\)']], 
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams' 
      },
      svg: {
        fontCache: 'global' 
      },
      chtml: {
        fontURL: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2'
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], 
        ignoreHtmlClass: 'tex2jax_ignore', 
        processHtmlClass: 'tex2jax_process'
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<footer class="footer-main simplified-footer">
  <div class="content-body footer-wraper">
    <div class="footer-box">
      <div class="footer-content">
        <div class="copyright-line">
          Powered by <a href="https://gohugo.io/" target="_blank">Hugo</a> © 2025 See Hiong. All rights reserved.
        </div>
        <div class="social-links">
          
            <a href="https://github.com/seehiong" target="_blank" title="GitHub" class="social-link" aria-label="GitHub">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
            </a>
          
          
            <a href="https://www.linkedin.com/in/seehiong/" target="_blank" title="LinkedIn" class="social-link" aria-label="LinkedIn">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/></svg>
            </a>
          
          
            <a href="/index.xml" target="_blank" title="RSS" class="social-link" aria-label="RSS Feed">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.503 20.752c0 1.794-1.456 3.248-3.251 3.248-1.796 0-3.252-1.454-3.252-3.248 0-1.794 1.456-3.248 3.252-3.248 1.795.001 3.251 1.454 3.251 3.248zm-6.503-12.572v4.811c6.05.062 10.96 4.966 11.022 11.009h4.817c-.062-8.71-7.118-15.758-15.839-15.82zm0-3.368c10.58.046 19.152 8.594 19.183 19.188h4.817c-.03-13.231-10.755-23.954-24-24v4.812z"/></svg>
            </a>
          
        </div>
      </div>
    </div>
  </div>
</footer>
        <script src="/js/animation.js" defer></script>
    
        <script src="/js/code-copy.js" defer></script>
    
        <script src="/js/scroll-header.js" defer></script>
       
  </body>
</html>