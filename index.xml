<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/</link>
    <description>Recent content on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 20 Jul 2025 20:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Transfer Learning with MobileNetV2</title>
      <link>https://seehiong.github.io/posts/2025/07/transfer-learning-with-mobilenetv2/</link>
      <pubDate>Sun, 20 Jul 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/07/transfer-learning-with-mobilenetv2/</guid>
      <description>In this post, I explore transfer learning using MobileNetV2 to build a binary image classifier for cats and dogs. Running on a tensorflow-full Kubeflow Notebook in my homelab, the workflow covers dataset preprocessing, model architecture, training, evaluation, and visualization. By freezing the base model and training only the top layers, I achieved efficient results with minimal resources. This hands-on project reinforces core CNN concepts learned in the Deep Learning Specialization.</description>
    </item>
    <item>
      <title>Automating Workflows with n8n</title>
      <link>https://seehiong.github.io/posts/2025/07/automating-workflows-with-n8n/</link>
      <pubDate>Sun, 13 Jul 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/07/automating-workflows-with-n8n/</guid>
      <description>Explore how to set up and run n8n, a powerful open-source workflow automation tool, locally using Docker and WSL on Windows. This post also walks through deploying n8n on a Kubernetes homelab using Kompose-generated manifests. Learn the basics of workflow building with hands-on examples and real-world usage tips.</description>
    </item>
    <item>
      <title>Running Bolt.diy with OpenRouter</title>
      <link>https://seehiong.github.io/posts/2025/07/running-bolt.diy-with-openrouter/</link>
      <pubDate>Sun, 06 Jul 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/07/running-bolt.diy-with-openrouter/</guid>
      <description>This post explores running the open-source bolt.diy locally and integrating it with OpenRouter to experiment with various LLMs. I document the development of TextForge—a multi-tool text manipulation app—using one-shot prompts and compare outputs from models like Claude 3 and DeepSeek Chat. The post shares setup steps, performance benchmarks, cost breakdowns, and lessons learned from building a locally hosted, LLM-driven developer tool.</description>
    </item>
    <item>
      <title>Deploying KServe on OKE</title>
      <link>https://seehiong.github.io/posts/2025/05/deploying-kserve-on-oke/</link>
      <pubDate>Mon, 12 May 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/05/deploying-kserve-on-oke/</guid>
      <description>This post demonstrated how to deploy an XGBoost model using KServe on Oracle Kubernetes Engine (OKE). Starting from model upload to Object Storage, we served the model via KServe and exposed it through Istio Gateway. Instead of deploying the frontend in-cluster, we built a Streamlit app hosted on Streamlit Community Cloud, which sends requests to the public inference endpoint. This end-to-end setup showcases a scalable and cloud-native ML deployment pipeline on OCI, separating model serving and user interface layers for flexibility and ease of maintenance.</description>
    </item>
    <item>
      <title>Building a Recommender System</title>
      <link>https://seehiong.github.io/posts/2025/05/building-a-recommender-system/</link>
      <pubDate>Fri, 02 May 2025 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/05/building-a-recommender-system/</guid>
      <description>In this post, we walk through the process of building a movie recommender system using deep learning embeddings and PostgreSQL with pgvector. You&amp;rsquo;ll learn how to extract and normalize item features, generate vector embeddings with TensorFlow, store them in a Postgres database, and perform similarity searches to recommend relevant content. The system leverages cosine distance for finding similar items and user preferences, enabling efficient, scalable recommendations.</description>
    </item>
    <item>
      <title>From Model to HDB App</title>
      <link>https://seehiong.github.io/posts/2025/04/from-model-to-hdb-app/</link>
      <pubDate>Mon, 21 Apr 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/04/from-model-to-hdb-app/</guid>
      <description>In this post, I demonstrated how to deploy a Jupyter notebook using the jupyter-tensorflow-full image in Kubeflow, develop an HDB resale price predictor app with Streamlit, and access it via port forwarding. The setup runs locally and showcases how to bring together machine learning, visualization, and interactivity in a seamless development workflow within Kubeflow.</description>
    </item>
    <item>
      <title>Feature Impact on HDB predictions</title>
      <link>https://seehiong.github.io/posts/2025/04/feature-impact-on-hdb-predictions/</link>
      <pubDate>Sun, 13 Apr 2025 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/04/feature-impact-on-hdb-predictions/</guid>
      <description>In this post, I explore the impact of different feature sets on XGBoost model performance for HDB resale price prediction. By combining numerical, categorical, and engineered features, I conducted a series of experiments and tracked their performance using MLflow. The results reveal how thoughtful feature engineering and selection can significantly influence metrics like RMSE, MAE, and R²—offering valuable insights into building more accurate predictive models.</description>
    </item>
    <item>
      <title>MNIST Digit Classifier in TensorFlow</title>
      <link>https://seehiong.github.io/posts/2025/04/mnist-digit-classifier-in-tensorflow/</link>
      <pubDate>Sun, 06 Apr 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/04/mnist-digit-classifier-in-tensorflow/</guid>
      <description>In this post, I walk through building a simple feedforward neural network using TensorFlow to classify handwritten digits from the MNIST dataset. From data preprocessing to training, evaluation, and visualizing predictions, this hands-on project reinforces key deep learning concepts covered in Andrew Ng’s course. The model achieved over 97% accuracy on the test set, and I also explored prediction confidence and misclassified samples. A solid foundation for experimenting with more advanced architectures ahead.</description>
    </item>
    <item>
      <title>Chat-Driven Insights with Chart.js</title>
      <link>https://seehiong.github.io/posts/2025/02/chat-driven-insights-with-chart.js/</link>
      <pubDate>Sun, 09 Feb 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/02/chat-driven-insights-with-chart.js/</guid>
      <description>Enhance your Vue.js application by integrating chat capabilities with Chart.js and LLMs like OpenAI and Deepseek-R1. This post walks through adding a chat node to the Micronaut-Optimizer workflow, enabling dynamic interactions with optimization results. Learn how to configure environment variables, connect workflow nodes, and send Chart.js data to LLMs. See it in action with sample inputs and responses, and explore running Deepseek-R1 locally with Ollama.</description>
    </item>
    <item>
      <title>JMC: Java Performance Profiling Simplified</title>
      <link>https://seehiong.github.io/posts/2025/02/jmc-java-performance-profiling-simplified/</link>
      <pubDate>Sun, 02 Feb 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/02/jmc-java-performance-profiling-simplified/</guid>
      <description>JDK Mission Control (JMC) is a powerful tool for low-overhead Java application profiling and performance analysis. In this post, I explore JMC’s capabilities while optimizing inference performance for Micronaut-Llama3 with DeepSeek-R1. I walk through setup, profiling with Flight Recorder, and identifying bottlenecks using flame graphs. Key optimizations, such as refining ByteVector operations, significantly enhance performance. A comparison with VisualVM highlights JMC’s advantages, making it the go-to tool for in-depth Java profiling. If you&amp;rsquo;re looking to fine-tune your Java applications, JMC provides essential insights for optimization.</description>
    </item>
    <item>
      <title>Building a Vue.js Frontend for Combinatorial Optimization Problems</title>
      <link>https://seehiong.github.io/posts/2025/01/building-a-vue.js-frontend-for-combinatorial-optimization-problems/</link>
      <pubDate>Sun, 26 Jan 2025 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/01/building-a-vue.js-frontend-for-combinatorial-optimization-problems/</guid>
      <description>In this post, I’ll walk you through the development of a Vue.js frontend application designed to complement my previous work on a flexible optimizer framework built with Micronaut. This frontend provides a visual interface for designing, managing, and optimizing workflows, with a focus on solving combinatorial optimization problems like the Traveling Salesman Problem (TSP). The app features a drag-and-drop UI, enabling users to define optimization problems graphically without relying on tools like Postman. By connecting inputs, transformations, and outputs through Workflow Nodes, users can visualize and compare the performance of backend optimization algorithms across different datasets.</description>
    </item>
    <item>
      <title>Building a Flexible Optimizer Framework with Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/12/building-a-flexible-optimizer-framework-with-micronaut/</link>
      <pubDate>Sun, 29 Dec 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/12/building-a-flexible-optimizer-framework-with-micronaut/</guid>
      <description>This post outlines the design and implementation of the Micronaut Optimizer framework, which solves combinatorial optimization problems like TSP and FLP. It details the architecture, key components, and the use of Flux and PublishSubject for real-time updates. The post also highlights planned enhancements, including additional solver integration, performance optimizations, visualization improvements, and architecture extensions. The complete implementation is available on GitHub, and contributions are welcome.</description>
    </item>
    <item>
      <title>Porting Llama3.java to Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/12/porting-llama3.java-to-micronaut/</link>
      <pubDate>Sun, 15 Dec 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/12/porting-llama3.java-to-micronaut/</guid>
      <description>This project ports the original single-file llama3.java by Alfonso² Peterssen into a modular Micronaut application, transforming it from a console app to a stream-based, production-ready API. The internals and performance of the original GGUF-format LLM remain unchanged. Updates focus on restructuring the codebase into logical packages and adapting it to Micronaut’s ecosystem, enabling easier integration with Java microservices. This streamlined design retains the original’s simplicity while enhancing scalability and usability for modern AI applications.</description>
    </item>
    <item>
      <title>Porting Llama2.java to Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/12/porting-llama2.java-to-micronaut/</link>
      <pubDate>Sat, 07 Dec 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/12/porting-llama2.java-to-micronaut/</guid>
      <description>This post explores porting the single-file llama2.java into a robust Micronaut application, demonstrating both JDK and GraalVM native mode performance. While GraalVM offers faster startup (56ms), its serving throughput is slower (210 tokens/sec). For high-performance inference, JDK mode is preferred, but GraalVM shines for lightweight, startup-critical scenarios. The journey highlights Micronaut&amp;rsquo;s ease of integration for AI applications.</description>
    </item>
    <item>
      <title>Building an AI Knowledge Assistant</title>
      <link>https://seehiong.github.io/posts/2024/11/building-an-ai-knowledge-assistant/</link>
      <pubDate>Sun, 24 Nov 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/11/building-an-ai-knowledge-assistant/</guid>
      <description>Learn how to build an AI-powered knowledge assistant using Python. This guide covers data ingestion from sources like PDFs, deploying a FastAPI-based API, and querying the assistant for detailed answers. Using advanced retrieval mechanisms, the assistant provides contextually relevant responses. You&amp;rsquo;ll also explore a working example with the CQRS design pattern. The complete project code is available on &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://github.com/seehiong/ai-knowledge-assistant&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;GitHub&lt;/a&gt;&#xD;&#xA;.</description>
    </item>
    <item>
      <title>Exploring AI with Raspberry Pi 5</title>
      <link>https://seehiong.github.io/posts/2024/11/exploring-ai-with-raspberry-pi-5/</link>
      <pubDate>Sat, 09 Nov 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/11/exploring-ai-with-raspberry-pi-5/</guid>
      <description>In this post, I dive into the powerful capabilities of the Raspberry Pi 5 paired with the Hailo-8L AI Kit, a neural network accelerator offering 13 TOPS. After setting up the system and camera, I explore object detection, pose estimation, and instance segmentation, showcasing the Pi’s impressive AI potential. Whether using pre-trained models or custom configurations, this compact setup proves to be a versatile tool for AI enthusiasts and developers alike. It&amp;rsquo;s a fun, hands-on introduction to the world of edge AI on a budget-friendly platform.</description>
    </item>
    <item>
      <title>GPT-2 Training Guide</title>
      <link>https://seehiong.github.io/posts/2024/10/gpt-2-training-guide/</link>
      <pubDate>Thu, 31 Oct 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/10/gpt-2-training-guide/</guid>
      <description>This post documents my journey training GPT-2 on the Tiny Shakespeare dataset, inspired by Andrej Karpathy&amp;rsquo;s instructional video and nanoGPT repository. Following each step, I detail the setup process, from encoding data and optimizing the model with AdamW, to improving training stability with mixed precision and flash attention. The post includes practical insights on using pretrained weights, weight sharing, and efficient data handling, concluding with sample outputs from training and sampling a “baby” GPT model.</description>
    </item>
    <item>
      <title>GPT-2 Setup and Pretraining Guide</title>
      <link>https://seehiong.github.io/posts/2024/10/gpt-2-setup-and-pretraining-guide/</link>
      <pubDate>Mon, 28 Oct 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/10/gpt-2-setup-and-pretraining-guide/</guid>
      <description>This guide explores reproducing GPT-2 (124M) using Andrej Karpathy’s video walkthrough. It begins with an overview of the GPT-2 architecture, a decoder-only transformer model inspired by &amp;ldquo;Attention Is All You Need.&amp;rdquo; Using pretrained GPT-2 weights, we analyze and initialize a custom GPT class, with detailed steps to handle token embeddings, causal attention, and layer normalization. The guide includes code for generating text from pretrained weights. In the next segment, we’ll continue with a deeper dive into dataset preparation and training from scratch, moving from small samples to large-scale training.</description>
    </item>
    <item>
      <title>Integrating MLflow and Kubeflow on Talos</title>
      <link>https://seehiong.github.io/posts/2024/10/integrating-mlflow-and-kubeflow-on-talos/</link>
      <pubDate>Sun, 20 Oct 2024 08:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/10/integrating-mlflow-and-kubeflow-on-talos/</guid>
      <description>This post details the installation of MLflow and Kubeflow on a Talos HomeLab cluster. It covers the setup process, including Talos configuration, local-path and NFS provisioning, and Metallb installation. Step-by-step instructions are provided for deploying Kubeflow, followed by the installation of MLflow for managing the machine learning lifecycle. Finally, the post illustrates how to log experiments and models in MLflow and perform inference, demonstrating a seamless integration of these tools for enhanced machine learning operations.</description>
    </item>
    <item>
      <title>Deploy Microservices with Talos Locally</title>
      <link>https://seehiong.github.io/posts/2024/10/deploy-microservices-with-talos-locally/</link>
      <pubDate>Sun, 13 Oct 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/10/deploy-microservices-with-talos-locally/</guid>
      <description>In this guide, we walk through deploying the Google Cloud Microservices Demo locally using Talos Linux in a VirtualBox VM. This step-by-step tutorial replicates a GKE environment, enabling seamless integration of microservices in a local Kubernetes cluster. We cover Talos installation, setting up the microservices demo, integrating MetalLB for load balancing, and optional Istio service mesh and Kiali observability for advanced monitoring. This approach is perfect for developers looking to simulate cloud environments locally and ensure their microservices run smoothly before deploying to production.</description>
    </item>
    <item>
      <title>Controlling RoArm-M2-S with ROS2</title>
      <link>https://seehiong.github.io/posts/2024/10/controlling-roarm-m2-s-with-ros2/</link>
      <pubDate>Sun, 06 Oct 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/10/controlling-roarm-m2-s-with-ros2/</guid>
      <description>Learn how to set up and control the RoArm-M2-S robotic arm using ROS2 in a virtual environment. This guide walks you through installing VirtualBox, creating a custom Ubuntu VM, setting up ROS2 with MoveIt2, and running driver nodes to control the arm through RViz, MoveIt, keyboard, and a web interface.</description>
    </item>
    <item>
      <title>Wave Rover with Raspberry Pi 4</title>
      <link>https://seehiong.github.io/posts/2024/09/wave-rover-with-raspberry-pi-4/</link>
      <pubDate>Sat, 28 Sep 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/09/wave-rover-with-raspberry-pi-4/</guid>
      <description>This post documents using a Raspberry Pi 4 as the main controller for the Wave Rover project. It covers installing Raspberry Pi OS, setting up the UGV_RPI package, enabling VNC, and configuring the Pi camera. Additionally, it details how to control the rover&amp;rsquo;s movement with Python and stream camera feeds via Flask. A sample HTML interface is provided for controlling the rover with arrow keys or buttons. Troubleshooting steps are included for resolving issues related to Picamera2 and V4L2 errors during the setup.</description>
    </item>
    <item>
      <title>Wave Rover: Setup Guide and Troubleshooting Tips</title>
      <link>https://seehiong.github.io/posts/2024/09/wave-rover-setup-guide-and-troubleshooting-tips/</link>
      <pubDate>Sat, 21 Sep 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/09/wave-rover-setup-guide-and-troubleshooting-tips/</guid>
      <description>This guide walks you through setting up the Wave Rover, including hardware connections and software configuration. It covers common issues like missing drivers and file errors, providing step-by-step solutions for problems such as the CP2102N USB to UART Bridge Controller and missing libraries like ArduinoJson or Adafruit_GFX. Whether you&amp;rsquo;re troubleshooting hardware connections or resolving compilation errors, this guide ensures a smooth setup process.</description>
    </item>
    <item>
      <title>Talos Linux: Setting Up a Secure, Immutable Kubernetes Cluster</title>
      <link>https://seehiong.github.io/posts/2024/09/talos-linux-setting-up-a-secure-immutable-kubernetes-cluster/</link>
      <pubDate>Sun, 01 Sep 2024 08:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/09/talos-linux-setting-up-a-secure-immutable-kubernetes-cluster/</guid>
      <description>This post guides you through setting up a secure, immutable Kubernetes cluster using Talos Linux. It covers installing Talos on control and worker nodes, configuring local storage with hostPath and Local Path Provisioner, and setting up the Kubernetes Dashboard with an admin user for cluster management. With Talos Linux, you achieve a minimal, API-managed Kubernetes environment without SSH or systemd, making it ideal for a secure and reliable homelab or production setup.</description>
    </item>
    <item>
      <title>Audio Generation with NVIDIA Jetson Orin NX</title>
      <link>https://seehiong.github.io/posts/2024/08/audio-generation-with-nvidia-jetson-orin-nx/</link>
      <pubDate>Sun, 25 Aug 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/08/audio-generation-with-nvidia-jetson-orin-nx/</guid>
      <description>This post explores the audio generation capabilities of the NVIDIA Jetson Orin NX. It covers transcribing audio using Whisper, setting up text-to-speech (TTS) and automatic speech recognition (ASR) with Llamaspeak, and preparing the RIVA server for advanced speech AI applications. Detailed instructions and command examples are provided, making it easy for developers to experiment with these tools on the Jetson platform.</description>
    </item>
    <item>
      <title>Unleashing Text Generation with NVIDIA Jetson Orin NX</title>
      <link>https://seehiong.github.io/posts/2024/08/unleashing-text-generation-with-nvidia-jetson-orin-nx/</link>
      <pubDate>Sat, 17 Aug 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/08/unleashing-text-generation-with-nvidia-jetson-orin-nx/</guid>
      <description>This post explores the powerful capabilities of NVIDIA Jetson Orin NX for text generation tasks. It covers the setup and use of models like Llama 2 and Llama 3, including installation steps, performance benchmarks, and examples of interactive AI sessions. Additionally, it provides insights into using the Jetson platform for deploying AI models efficiently, with practical tips on getting started and maximizing performance. Whether you&amp;rsquo;re a developer or AI enthusiast, this guide offers a hands-on look at harnessing NVIDIA Jetson&amp;rsquo;s potential for advanced AI applications.</description>
    </item>
    <item>
      <title>Scaling Kafka Workloads with KEDA in Kubernetes</title>
      <link>https://seehiong.github.io/posts/2024/08/scaling-kafka-workloads-with-keda-in-kubernetes/</link>
      <pubDate>Sat, 10 Aug 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/08/scaling-kafka-workloads-with-keda-in-kubernetes/</guid>
      <description>This post demonstrates how to use KEDA, a Kubernetes-based Event Driven Autoscaler, to dynamically scale Kafka consumer workloads. Building on a previous setup with Kafka on MicroK8s, the guide walks through the installation of KEDA, configuring Kafka consumers, setting up secrets for authentication, and creating a ScaledObject to manage scaling based on message load. The post also includes practical examples of scaling under different loads, showcasing how KEDA automates horizontal scaling without requiring changes to the microservices code, making it easier to manage workloads in a Kubernetes environment.</description>
    </item>
    <item>
      <title>Exploring NVIDIA Jetson Orin NX: Flashing and Setup Guide</title>
      <link>https://seehiong.github.io/posts/2024/08/exploring-nvidia-jetson-orin-nx-flashing-and-setup-guide/</link>
      <pubDate>Fri, 09 Aug 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/08/exploring-nvidia-jetson-orin-nx-flashing-and-setup-guide/</guid>
      <description>In this guide, I document the process of setting up and flashing the NVIDIA Jetson Orin NX, a powerful embedded AI computer ideal for advanced robotics and generative AI applications. The post covers preparation steps, including selecting the right SSD and downloading the necessary Ubuntu image. I provide a detailed walkthrough of the installation using NVIDIA&amp;rsquo;s SDK Manager, along with troubleshooting tips based on my experience. Whether you&amp;rsquo;re new to the Jetson Orin NX or looking to optimize your setup, this guide offers practical insights and step-by-step instructions to get you started.</description>
    </item>
    <item>
      <title>Setting Up Kafka with MicroK8s and Multipass</title>
      <link>https://seehiong.github.io/posts/2024/08/setting-up-kafka-with-microk8s-and-multipass/</link>
      <pubDate>Sat, 03 Aug 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/08/setting-up-kafka-with-microk8s-and-multipass/</guid>
      <description>My homelab is a playground for experimenting with various tools and setups. However, for Proof of Concept (POC) environments, a lightweight and portable setup is often more suitable. In this post, I will guide you through setting up a MicroK8s environment in a virtual machine using Multipass. This POC demonstrates how Kafka can be set up in this environment.</description>
    </item>
    <item>
      <title>Building Your First Kubeflow Pipeline: A Step-by-Step Guide</title>
      <link>https://seehiong.github.io/posts/2024/07/building-your-first-kubeflow-pipeline-a-step-by-step-guide/</link>
      <pubDate>Sat, 20 Jul 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/07/building-your-first-kubeflow-pipeline-a-step-by-step-guide/</guid>
      <description>In this blog post, I guide you through creating and running your first Kubeflow pipeline. We&amp;rsquo;ll start with the &amp;ldquo;Hello World&amp;rdquo; example, demonstrate how to manage sequential and shared pipelines, and explore artifact storage with MinIO. Additionally, I&amp;rsquo;ll introduce K9s, a powerful terminal-based UI for managing your Kubernetes clusters efficiently. By the end, you&amp;rsquo;ll have a solid understanding of setting up and managing Kubeflow pipelines in your machine learning workflows.</description>
    </item>
    <item>
      <title>Integrating Draw.io and PlantUML with GitLab</title>
      <link>https://seehiong.github.io/posts/2024/07/integrating-draw.io-and-plantuml-with-gitlab/</link>
      <pubDate>Sat, 06 Jul 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/07/integrating-draw.io-and-plantuml-with-gitlab/</guid>
      <description>As we transition from Lucidchart to draw.io for team diagramming, this guide outlines the steps to integrate draw.io and PlantUML with GitLab. I&amp;rsquo;ll configure the Diagrams.net server, enable integration, and demonstrate creating and editing diagrams within GitLab. Additionally, I&amp;rsquo;ll cover the setup and integration of PlantUML for creating detailed design diagrams. Follow along to seamlessly incorporate these powerful diagramming tools into your GitLab workflow.</description>
    </item>
    <item>
      <title>Setting Up and Using KServe with Kubeflow</title>
      <link>https://seehiong.github.io/posts/2024/06/setting-up-and-using-kserve-with-kubeflow/</link>
      <pubDate>Sun, 30 Jun 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/06/setting-up-and-using-kserve-with-kubeflow/</guid>
      <description>In this post, we explore KServe, a model inference platform on Kubernetes designed for scalability. Building on our previous Kubeflow guide, we detail how to set up your first KServe endpoint, make predictions, and troubleshoot common issues. Follow our step-by-step instructions to seamlessly integrate KServe with your Kubeflow environment and enhance your machine learning deployment process.</description>
    </item>
    <item>
      <title>Setting Up Kubeflow on Kubernetes: A Step-by-Step Guide</title>
      <link>https://seehiong.github.io/posts/2024/06/setting-up-kubeflow-on-kubernetes-a-step-by-step-guide/</link>
      <pubDate>Mon, 24 Jun 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/06/setting-up-kubeflow-on-kubernetes-a-step-by-step-guide/</guid>
      <description>In this post, I provide a comprehensive guide to setting up Kubeflow, a machine learning toolkit for Kubernetes. From initial preparation and downloading necessary binaries to installing all Kubeflow components and troubleshooting common issues, this step-by-step tutorial ensures a smooth installation process. You&amp;rsquo;ll also learn how to create your first notebook and resolve potential errors, making it easier to leverage Kubeflow&amp;rsquo;s powerful features for your machine learning projects.</description>
    </item>
    <item>
      <title>Building Advanced RAG Applications with MyScaleDB and LlamaIndex</title>
      <link>https://seehiong.github.io/posts/2024/06/building-advanced-rag-applications-with-myscaledb-and-llamaindex/</link>
      <pubDate>Sat, 15 Jun 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/06/building-advanced-rag-applications-with-myscaledb-and-llamaindex/</guid>
      <description>Explore how to build advanced Retrieval-Augmented Generation (RAG) applications using MyScaleDB and LlamaIndex. This guide covers the installation of necessary tools, setting up a virtual environment, and creating an index for document categorization. Learn how to execute simple and filtered queries, and troubleshoot common issues. Enhance your understanding of integrating high-performance SQL vector databases with cutting-edge data frameworks for efficient LLM applications.</description>
    </item>
    <item>
      <title>Planning Gift Deliveries With QGIS</title>
      <link>https://seehiong.github.io/posts/2024/06/planning-gift-deliveries-with-qgis/</link>
      <pubDate>Sat, 08 Jun 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/06/planning-gift-deliveries-with-qgis/</guid>
      <description>In this post, I document my journey of using QGIS, a free and open-source geographic information system, to plan gift deliveries. I outline the steps to install QGIS, add essential plugins, create a shapefile layer for mapping locations, and use ORS Tools for route planning. After configuring the map, I determined that my delivery route would take 3 hours. This process, while tailored to my use case, is versatile and applicable to various fields such as logistics, urban planning, and environmental management. QGIS provides robust tools for efficient spatial analysis and mapping tasks.</description>
    </item>
    <item>
      <title>From Routing Models to MIP: Solving Capacitated Vehicle Routing Problem</title>
      <link>https://seehiong.github.io/posts/2024/06/from-routing-models-to-mip-solving-capacitated-vehicle-routing-problem/</link>
      <pubDate>Sat, 01 Jun 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/06/from-routing-models-to-mip-solving-capacitated-vehicle-routing-problem/</guid>
      <description>In this post, we delve into solving the Capacitated Vehicle Routing Problem (CVRP) by transitioning from traditional routing models to the advanced Mixed Integer Programming (MIP) approach. We&amp;rsquo;ll start with the basics of creating a routing model using Google OR-Tools and then explore how to formulate and solve the CVRP using MIP for more optimized solutions. Whether you&amp;rsquo;re new to vehicle routing or looking to enhance your optimization techniques, this comprehensive guide provides the insights and code examples you need.</description>
    </item>
    <item>
      <title>Solving Facility Location Problem with OR-Tools and Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/05/solving-facility-location-problem-with-or-tools-and-micronaut/</link>
      <pubDate>Mon, 27 May 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/05/solving-facility-location-problem-with-or-tools-and-micronaut/</guid>
      <description>This post demonstrates solving the Facility Location Problem (FLP) using OR-Tools and Micronaut. It covers defining the solver, variables, constraints, and objective function in Java. The implementation includes creating a Micronaut service and controller to handle file uploads, process the data, and compute the optimal solution. The example input file format and expected outputs are also illustrated, providing a complete guide to implementing and testing the FLP solution.</description>
    </item>
    <item>
      <title>Optimizing TSP with Genetic Algorithms in Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/05/optimizing-tsp-with-genetic-algorithms-in-micronaut/</link>
      <pubDate>Thu, 23 May 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/05/optimizing-tsp-with-genetic-algorithms-in-micronaut/</guid>
      <description>In this post, I explore solving a Traveling Salesman Problem (TSP) involving 200 cities using genetic algorithms within a Micronaut framework. Leveraging techniques like inversion, insertion, and swap mutations, I illustrate how to maintain genetic diversity and improve solution quality over generations. The implementation showcases significant performance improvements compared to previous solvers. This approach combines simulated annealing, genetic algorithms, and local search to tackle complex optimization challenges effectively.</description>
    </item>
    <item>
      <title>Efficient TSP Solver API with Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/04/efficient-tsp-solver-api-with-micronaut/</link>
      <pubDate>Sat, 27 Apr 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/04/efficient-tsp-solver-api-with-micronaut/</guid>
      <description>Solve the Travelling Salesman Problem using Choco-solver and convert it into a powerful API with Micronaut. Explore the efficient solution and its integration for optimal city tours.</description>
    </item>
    <item>
      <title>Log Management with Graylog</title>
      <link>https://seehiong.github.io/posts/2024/04/log-management-with-graylog/</link>
      <pubDate>Fri, 19 Apr 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/04/log-management-with-graylog/</guid>
      <description>Explore setting up Graylog in your HomeLab for comprehensive log management. Configure MongoDB and OpenSearch, deploy Fluent Bit for log forwarding, and implement advanced features like Grok patterns and pipelines. Troubleshoot efficiently with tools like netshoot and tcpdump. Enhance your HomeLab environment with a scalable and efficient log management solution.</description>
    </item>
    <item>
      <title>Coding with CrewAI: AI Orchestration Simplified</title>
      <link>https://seehiong.github.io/posts/2024/03/coding-with-crewai-ai-orchestration-simplified/</link>
      <pubDate>Fri, 29 Mar 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/03/coding-with-crewai-ai-orchestration-simplified/</guid>
      <description>Explore CrewAI, a pioneering framework streamlining AI agent orchestration. Discover practical applications, from Jan and LM Studio integration to Serper API utilization. Follow along as we delve into coding with CrewAI, showcasing its versatility in crafting resumes and more. Experience the seamless synergy of autonomous AI agents, revolutionizing workflows with efficiency and innovation. Unlock the power of CrewAI, propelling your projects to new heights in artificial intelligence.</description>
    </item>
    <item>
      <title>AutoPilot Setup for VS Code</title>
      <link>https://seehiong.github.io/posts/2024/03/autopilot-setup-for-vs-code/</link>
      <pubDate>Sat, 16 Mar 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/03/autopilot-setup-for-vs-code/</guid>
      <description>Discover the quick setup of AutoPilot for VS Code, enabling seamless code completion with LM Studio and OpenAI-compatible models. Learn the configuration steps and see them in action, empowering your coding experience.</description>
    </item>
    <item>
      <title>Configuring Appwrite Functions with K3s</title>
      <link>https://seehiong.github.io/posts/2024/03/configuring-appwrite-functions-with-k3s/</link>
      <pubDate>Sun, 10 Mar 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/03/configuring-appwrite-functions-with-k3s/</guid>
      <description>This guide outlines configuring Appwrite Functions within a K3s environment. It covers essential steps, including installing ngrok for external network access, registering a GitHub App, and setting up Appwrite with required configurations. The process involves updating YAML files for deployment, ensuring proper routing with Traefik, and creating functions through the Appwrite interface. Once set up, the functions are deployed successfully, enabling seamless integration and execution within the K3s infrastructure.</description>
    </item>
    <item>
      <title>Deploying Budibase in HomeLab</title>
      <link>https://seehiong.github.io/posts/2024/02/deploying-budibase-in-homelab/</link>
      <pubDate>Sun, 25 Feb 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/02/deploying-budibase-in-homelab/</guid>
      <description>This post outlines the process of installing Budibase in a HomeLab environment, starting with testing it on Docker Desktop and then deploying it using Helm in Kubernetes. It guides through setting up an admin user, building the first app by creating a database, designing an application form, and configuring submission actions. The summary encapsulates the steps involved in testing, deploying, and building an application with Budibase, highlighting key actions such as Docker Compose setup, Helm installation, app creation, and deployment in a concise manner.</description>
    </item>
    <item>
      <title>Deploying Appwrite in HomeLab with K3s</title>
      <link>https://seehiong.github.io/posts/2024/02/deploying-appwrite-in-homelab-with-k3s/</link>
      <pubDate>Fri, 16 Feb 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/02/deploying-appwrite-in-homelab-with-k3s/</guid>
      <description>Learn how to seamlessly integrate Appwrite, an open-source platform, into your HomeLab setup using K3s. Follow step-by-step instructions to deploy K3s with Portainer, prepare Appwrite volumes, and configure miscellaneous services like MariaDB and InfluxDB. Utilize Kompose to convert Docker Compose files to Kubernetes for efficient deployment. Ensure smooth installation by mapping necessary environment variables and applying all required deployments and services. Finally, witness the successful deployment of Appwrite services and access the login page to start building scalable applications. Master the art of HomeLab application deployment with Appwrite and K3s.</description>
    </item>
    <item>
      <title>Text-to-Image with StableDiffusionPipeline</title>
      <link>https://seehiong.github.io/posts/2024/02/text-to-image-with-stablediffusionpipeline/</link>
      <pubDate>Sat, 10 Feb 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/02/text-to-image-with-stablediffusionpipeline/</guid>
      <description>In this post, we explore the capabilities of StableDiffusionPipeline for generating photorealistic images from textual inputs. We start with setting up the environment and installing necessary libraries. Then, we dive into Textual Inversion, demonstrating how the model learns new concepts from images. Image-to-Image transformations are also explored, showcasing the pipeline&amp;rsquo;s versatility. Additionally, we introduce Animagine XL 2.0, a model for high-resolution anime image creation, and provide sample code for its implementation. Lastly, we highlight Stable Diffusion XL, a powerful text-to-image model, and share a festive image generated using it.</description>
    </item>
    <item>
      <title>Stable Diffusion: Text-to-Image Modeling Journey</title>
      <link>https://seehiong.github.io/posts/2024/02/stable-diffusion-text-to-image-modeling-journey/</link>
      <pubDate>Sat, 03 Feb 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/02/stable-diffusion-text-to-image-modeling-journey/</guid>
      <description>This post explores Stable Diffusion, a latent text-to-image diffusion model in machine learning. Diffusion models, with forward, reverse, and sampling components, understand and generate patterns in datasets. Illustrating applications in image tasks, it introduces the process of installing and utilizing Stable Diffusion. The post details image generation and modification using prompts, with examples and troubleshooting. Notably, it shares an encounter with CUDA out-of-memory errors and the resolution through image resizing. Overall, it offers a comprehensive guide, combining theoretical insights with practical implementation steps in a professional manner.</description>
    </item>
    <item>
      <title>OpenVINO, Optimum-Intel, CPU: An Exploration in Model Optimization</title>
      <link>https://seehiong.github.io/posts/2024/01/openvino-optimum-intel-cpu-an-exploration-in-model-optimization/</link>
      <pubDate>Sat, 27 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/openvino-optimum-intel-cpu-an-exploration-in-model-optimization/</guid>
      <description>Explore the convergence of OpenVINO and Optimum-Intel in this post, where I detail the setup and execution of example code on my aging laptop. Focused on applying Quantization-aware Training and the Token Merging method to optimize the UNet model within the Stable Diffusion pipeline, this journey showcases the synergy of open-source tools for deep learning model deployment. Note that the provided code is tailored for CPU-based inference due to limitations in my aging GeForce graphics card, making it a valuable resource for users with similar hardware constraints. Dive into the world of optimized models and delightful Pokemon creation!</description>
    </item>
    <item>
      <title>Java Integration with Jupyter Notebooks</title>
      <link>https://seehiong.github.io/posts/2024/01/java-integration-with-jupyter-notebooks/</link>
      <pubDate>Sun, 21 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/java-integration-with-jupyter-notebooks/</guid>
      <description>Embark on a seamless integration of Java into Jupyter notebooks with this comprehensive guide. Beginning with the selection of a relevant Jupyter Docker Stack, the post details setup steps and deployment in HomeLab, showcasing application results for verification. The integration of Java Kernel through JBang and testing with &amp;ldquo;Hello World&amp;rdquo; and Apache Commons library exemplifies the versatility. Further exploration involves experimenting with Java in a Python kernel using JBang. Concluding with a call to joyful coding, this journey promises a harmonious blend of Java&amp;rsquo;s robustness and Jupyter&amp;rsquo;s interactive nature. Discover the joy of coding in this enriched Java-in-Jupyter experience. Happy coding!</description>
    </item>
    <item>
      <title>Exploring Autogen Studio</title>
      <link>https://seehiong.github.io/posts/2024/01/exploring-autogen-studio/</link>
      <pubDate>Sun, 14 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/exploring-autogen-studio/</guid>
      <description>In this exploration of Autogen Studio, we navigated through the AI landscape, harnessing the LM Studio API to compare responses from diverse language models. Employing the Mistral Instruct 7B model, we scrutinized prompts like Stock Price and Paint, visualizing outcomes and delving into key configurations. The post also offered insights into the primary assistant, model configuration, and agent workflows, accompanied by a comparative analysis of Mistral model responses. This comprehensive journey demystifies the power of Autogen Studio and its seamless integration with LM Studio API, providing practical guidance for AI enthusiasts.</description>
    </item>
    <item>
      <title>Deploying LLMs with WasmEdge in HomeLab</title>
      <link>https://seehiong.github.io/posts/2024/01/deploying-llms-with-wasmedge-in-homelab/</link>
      <pubDate>Sat, 13 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/deploying-llms-with-wasmedge-in-homelab/</guid>
      <description>In this post, we explored deploying Lightweight Language Models (LLMs) using WasmEdge, a high-performance WebAssembly runtime, within a HomeLab environment. The process involved preparing an OpenAI-compatible API server, configuring the Wasi-NN plugin, and deploying the setup to HomeLab using Kubernetes (K3s). The post also detailed the steps for testing the API server and integrating it into a Java application. Overall, the guide provides a comprehensive walkthrough of hosting and utilizing LLMs with WasmEdge in a local environment.</description>
    </item>
    <item>
      <title>Integrating NFS for Improved Scalability</title>
      <link>https://seehiong.github.io/posts/2024/01/integrating-nfs-for-improved-scalability/</link>
      <pubDate>Sun, 07 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/integrating-nfs-for-improved-scalability/</guid>
      <description>In this post, we explored the integration of NFS to enhance scalability in deploying LLM models within a home lab. Setting up NFS involved connecting to a TerraMaster NAS, and the K3s cluster was configured to dynamically provision storage. With NFS in place, the deployment process became more efficient, eliminating the need to rebuild images for each new model introduction. The post detailed the setup steps, from configuring NFS and K3s to deploying LLM models dynamically. This approach simplifies the scaling of Language Models, providing a centralized and scalable storage solution through NFS in a Kubernetes environment.</description>
    </item>
    <item>
      <title>Integration of Kong into AI Workflow</title>
      <link>https://seehiong.github.io/posts/2024/01/integration-of-kong-into-ai-workflow/</link>
      <pubDate>Sat, 06 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/integration-of-kong-into-ai-workflow/</guid>
      <description>This comprehensive guide navigates through configuring Kong OSS and Kong Ingress Controller (KIC), seamlessly integrating Kong into an AI workflow. Starting with Kong OSS configuration, the tutorial covers updating environment variables and service ports. The Langchain4j application is then adapted to leverage Kong API, allowing for flexible path-based APIs. Additionally, potential timeout issues are addressed. The guide concludes with a demonstration of Kong Ingress Controller configuration, emphasizing optimal settings for specific use cases. Whether through Kong OSS or KIC, readers gain insights into enhancing API management and integration within their AI workflows.</description>
    </item>
    <item>
      <title>Exploring Kong Ingress Controller (KIC)</title>
      <link>https://seehiong.github.io/posts/2024/01/exploring-kong-ingress-controller-kic/</link>
      <pubDate>Mon, 01 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/exploring-kong-ingress-controller-kic/</guid>
      <description>Embark on a journey into the new year by exploring Kong Ingress Controller (KIC) in your home lab. This guide, transitioning from a previous discussion on Kong Gateway, details the seamless setup of KIC using Helm and K3s. From initial preparations to installing Kong Ingress Controller and Gateway, witness the efficient management of APIs in your home lab environment. Learn to add Kong Ingresses, ensuring optimal routing for various paths. Through concise steps and illustrative visuals, this post simplifies the process, allowing you to experience KIC&amp;rsquo;s capabilities firsthand. Dive into the year with a hands-on exploration of API management with Kong in your home lab. Happy New Year!</description>
    </item>
    <item>
      <title>Streamlining API Management with Kong</title>
      <link>https://seehiong.github.io/posts/2023/12/streamlining-api-management-with-kong/</link>
      <pubDate>Sun, 31 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/streamlining-api-management-with-kong/</guid>
      <description>This comprehensive guide walks you through integrating Kong, a powerful unified API platform, into your home lab environment. Starting with Docker installation and a custom Kong image, it covers PostgreSQL deployment, MetalLB setup for load balancing, and Kong service and route configuration. The post concludes with troubleshooting tips and instructions for deploying your customized Kong image in a K3s cluster. This step-by-step tutorial empowers you to efficiently manage APIs in your home lab using Kong.</description>
    </item>
    <item>
      <title>AI Integration: LocalAI, Chroma, and Langchain4j</title>
      <link>https://seehiong.github.io/posts/2023/12/ai-integration-localai-chroma-and-langchain4j/</link>
      <pubDate>Fri, 29 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/ai-integration-localai-chroma-and-langchain4j/</guid>
      <description>Explore AI integration in a home lab with LocalAI, Chroma, and Langchain4j. Begin by creating a custom LocalAI image, deploying it alongside Chroma, and configuring the Kubernetes environment. The post details deploying and exposing services, ensuring seamless communication between applications. Learn to modify endpoints in the Langchain4j application for smooth integration with the Home Lab setup. With a focus on simplicity, this guide empowers users to harness the capabilities of these AI tools within a controlled home environment, fostering experimentation and development.</description>
    </item>
    <item>
      <title>Upgrading My Tech Blog: Hugo, Giscus, and Pagefind Integration</title>
      <link>https://seehiong.github.io/posts/2023/12/upgrading-my-tech-blog-hugo-giscus-and-pagefind-integration/</link>
      <pubDate>Tue, 26 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/upgrading-my-tech-blog-hugo-giscus-and-pagefind-integration/</guid>
      <description>Explore my journey of enhancing my tech blog by adopting Hugo, a powerful static site generator. Discover the streamlined setup process using Chocolately, theme selection, and local site preview. Dive into seamless integration with Giscus for robust GitHub Discussions-powered comments. Enhance user experience with Pagefind, a fully static search library, for efficient content discovery. Follow this step-by-step guide to leverage these tools and elevate your tech blog&amp;rsquo;s functionality and engagement. Uncover insights into Hugo, Giscus, and Pagefind, making your blogging experience more dynamic and user-friendly.</description>
    </item>
    <item>
      <title>GitLab Setup: Installation, Migration, and CI/CD Simplified</title>
      <link>https://seehiong.github.io/posts/2023/12/gitlab-setup-installation-migration-and-ci/cd-simplified/</link>
      <pubDate>Sun, 24 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/gitlab-setup-installation-migration-and-ci/cd-simplified/</guid>
      <description>&lt;p&gt;In this guide, I&amp;rsquo;ll walk you through the process of installing &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://docs.gitlab.com/omnibus/installation/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;GitLab&lt;/a&gt;&#xD;&#xA;, a comprehensive suite of tools for version control, continuous integration, continuous delivery, and more, in my Home Lab collection.&lt;/p&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;After obtaining the latest &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://ubuntu.com/download/server&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;Ubuntu Server&lt;/a&gt;&#xD;&#xA;, I utilized &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://rufus.ie/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;Rufus&lt;/a&gt;&#xD;&#xA;, a utility for formatting and creating bootable USB flash drives.&lt;/p&gt;&#xA;&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;&#xA;&lt;p&gt;Following the &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://packages.gitlab.com/gitlab/gitlab-ce/install&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;installation instructions&lt;/a&gt;&#xD;&#xA;, initiate a quick installation using the following command:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deploying OpenAI-Compatible LLAMA CPP Server with K3S</title>
      <link>https://seehiong.github.io/posts/2023/12/deploying-openai-compatible-llama-cpp-server-with-k3s/</link>
      <pubDate>Fri, 22 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/deploying-openai-compatible-llama-cpp-server-with-k3s/</guid>
      <description>In this post, I expand my Home Lab by adding a perpetual LLAMA model for on-demand inferencing. The steps involve crafting a Dockerfile, packaging Microsoft&amp;rsquo;s Phi2 model, and deploying it with K3S. This ensures a continuously accessible LLAMA server for seamless integration into various inferencing projects.</description>
    </item>
    <item>
      <title>Unveiling Agent AutoBuild in Autogen</title>
      <link>https://seehiong.github.io/posts/2023/12/unveiling-agent-autobuild-in-autogen/</link>
      <pubDate>Sun, 17 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/unveiling-agent-autobuild-in-autogen/</guid>
      <description>In this blog, I explored Autogen&amp;rsquo;s Agent AutoBuild and experimented with the Mixtral 8x7B model. I configured Autogen, envisioning a software academy project for coding novices. Through code snippets, I showcased AutoBuild&amp;rsquo;s multi-agent system creation and tailored a task that wrote a General Paper article on art and courage. The Mixtral 8x7B model in LM Studio brought excitement but posed challenges with duplicate content. Check out the blog for a firsthand look at the dynamic interplay between Autogen and cutting-edge AI, complete with code snippets and images.</description>
    </item>
    <item>
      <title>Empowering Autogen: Enabling Seamless Java Code Execution</title>
      <link>https://seehiong.github.io/posts/2023/12/empowering-autogen-enabling-seamless-java-code-execution/</link>
      <pubDate>Sun, 10 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/empowering-autogen-enabling-seamless-java-code-execution/</guid>
      <description>In this post, I explored enhancing Autogen&amp;rsquo;s capabilities by enabling seamless Java code execution. Drawing inspiration from 0xlws&amp;rsquo; fork supporting JavaScript, I embarked on modifying Autogen to robustly support Java. I detailed the setup process, including installing Java on Windows Subsystem for Linux (WSL) and modifying key files. The post includes code snippets showcasing the changes, recompilation steps, and instructions for generating Java code. I extended functionality to additional test cases, seamlessly switching between Java and Python code execution. Docker integration for Java code execution was also optimized, showcasing Autogen&amp;rsquo;s versatility and robust development experience.</description>
    </item>
    <item>
      <title>Multi-agent Conservation with Autogen</title>
      <link>https://seehiong.github.io/posts/2023/12/multi-agent-conservation-with-autogen/</link>
      <pubDate>Fri, 08 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/multi-agent-conservation-with-autogen/</guid>
      <description>&lt;p&gt;In this post, I&amp;rsquo;ll walk you through setting up a multi-agent conservation using Autogen. Building upon the concepts explored in a previous post &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://seehiong.github.io/posts/2023/12/exploring-autogen-with-lm-studio-and-local-llm/&#34; &gt;Exploration with Autogen&lt;/a&gt;&#xD;&#xA; and following the example of &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://microsoft.github.io/autogen/docs/Examples#automated-multi-agent-chat&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;Automated Multi Agent Chat&lt;/a&gt;&#xD;&#xA;, we&amp;rsquo;ll delve into the steps to create a dynamic debate environment.&lt;/p&gt;&#xA;&lt;h2 id=&#34;agent-setup&#34;&gt;Agent Setup&lt;/h2&gt;&#xA;&lt;p&gt;I&amp;rsquo;ll be setting up two agents: &lt;strong&gt;for_motion&lt;/strong&gt; and &lt;strong&gt;against_motion&lt;/strong&gt;. Each agent will engage in a debate on a given topic, providing examples and substantiating their points. A facilitator will oversee the debate rounds, ensuring that each response exceeds 300 words.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring AutoGen with LM Studio and Local LLM</title>
      <link>https://seehiong.github.io/posts/2023/12/exploring-autogen-with-lm-studio-and-local-llm/</link>
      <pubDate>Sat, 02 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/exploring-autogen-with-lm-studio-and-local-llm/</guid>
      <description>I explored AutoGen, an innovative framework on GitHub, enabling the development of Large Language Model (LLM) applications. Collaborating with LM Studio, I set up a local LLM application, showcasing the step-by-step process. Installing LM Studio involved configuring context length, enabling GPU acceleration, and setting CPU threads. The integration process showcased a seamless environment for running local LLMs. Additionally, I explored the AutoGen setup, including installing Anaconda and creating a virtual environment. With the provided guidelines, I executed the app.py script, generating a stock price comparison chart through AutoGen&amp;rsquo;s dynamic conversation.</description>
    </item>
    <item>
      <title>Boosting Inference Speed: SSD and GPU Acceleration</title>
      <link>https://seehiong.github.io/posts/2023/11/boosting-inference-speed-ssd-and-gpu-acceleration/</link>
      <pubDate>Thu, 30 Nov 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/11/boosting-inference-speed-ssd-and-gpu-acceleration/</guid>
      <description>Embarking on an exhilarating upgrade journey, I chronicle the seamless migration to the powerful Lexar NM790 SSD and unveil the secrets behind turbocharging Langchain4j&amp;rsquo;s inferencing speed. With Clonezilla&amp;rsquo;s reliability, my Windows 11 transition to this SSD was flawless, offering a tangible boost. The GPU acceleration saga unfolded with CUDA installation and the NVIDIA Container Toolkit magic, resulting in a high-speed universe. Launching the LocalAI image in a GPU Docker container revealed the grand finale—a remarkable surge in Langchain4j&amp;rsquo;s inference speed. This transformation invites tech enthusiasts to explore elevated performance and redefine possibilities.</description>
    </item>
    <item>
      <title>RAG over Java code with Langchain4j</title>
      <link>https://seehiong.github.io/posts/2023/11/rag-over-java-code-with-langchain4j/</link>
      <pubDate>Sat, 11 Nov 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/11/rag-over-java-code-with-langchain4j/</guid>
      <description>In my latest post, I delve into seamlessly integrating Retrieval-Augmented Generation (RAG) with Java code using Langchain4j. Drawing inspiration from RAG over code, I explore Java Parser&amp;rsquo;s potential for robust codebase analysis. The pivotal JavaParsingService and EmbeddingStoreService orchestrate this integration, enabling users to effortlessly load Java projects and glean profound insights. The enhanced controller boasts user-friendly endpoints, fostering dynamic interactions. Witness Retrieval-Augmented Generation breathe life into Java code, from codebase ingestion to insightful querying with models like gpt4all-j, WizardLM, and OpenAI. This narrative unveils the nuanced capabilities of RAG in querying Java codebases.</description>
    </item>
    <item>
      <title>Building an AI Application with Langchain4j</title>
      <link>https://seehiong.github.io/posts/2023/11/building-an-ai-application-with-langchain4j/</link>
      <pubDate>Tue, 07 Nov 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/11/building-an-ai-application-with-langchain4j/</guid>
      <description>I embarked on a journey to harness the capabilities of Langchain4j, crafting a powerful AI application in Java using the local language model. Utilizing Spring Boot, Postman, and various Langchain4j components, I explored setting up, implementing a chat service, integrating custom tools, embedding functionality with Chroma, translation, persistence, retrieval, and streaming services. The blog post serves as a comprehensive guide for building personalized AI applications, showcasing the versatility and potential of Langchain4j in Java development.</description>
    </item>
    <item>
      <title>Unlocking the Power of Machine Learning with MLC LLM</title>
      <link>https://seehiong.github.io/posts/2023/09/unlocking-the-power-of-machine-learning-with-mlc-llm/</link>
      <pubDate>Sat, 02 Sep 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/09/unlocking-the-power-of-machine-learning-with-mlc-llm/</guid>
      <description>I delve into the transformative realm of MLC LLM, an advanced universal deployment solution for extensive language models. My post guides you personally through the setup, emphasizing critical components like TVM and Conda. I demonstrate the process, including TVM installation via pip, Conda setup on WSL, and Vulkan SDK installation for optimal performance. Navigating the MLC Chat exploration, I detail creating a Conda environment and running MLC LLM&amp;rsquo;s CLI version, offering a glimpse into its potential through a sample question. With MLC LLM and MLC Chat at your fingertips, the world of machine learning and language understanding unfolds boundless possibilities. 🚀🧠</description>
    </item>
    <item>
      <title>Utilizing vLLM for Efficient Language Model Serving</title>
      <link>https://seehiong.github.io/posts/2023/08/utilizing-vllm-for-efficient-language-model-serving/</link>
      <pubDate>Sun, 20 Aug 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/08/utilizing-vllm-for-efficient-language-model-serving/</guid>
      <description>Embarking on my journey with vLLM, I explore its potential for streamlined Large Language Model (LLM) inference and deployment. The blog details my personal experience setting up vLLM on a Windows Subsystem for Linux (WSL) instance running Ubuntu 22.04. I meticulously guide through installing WSL, NVIDIA GPU drivers, CUDA Toolkit, and Docker for efficient utilization. Delving into vLLM setup within the NVIDIA PyTorch Docker image, I navigate through the installation process and launch the API server. The blog provides insights into querying the model and creating a Docker image snapshot, offering a comprehensive guide to efficient language model serving.</description>
    </item>
    <item>
      <title>Setting up K3s</title>
      <link>https://seehiong.github.io/posts/2023/07/setting-up-k3s/</link>
      <pubDate>Sun, 30 Jul 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/07/setting-up-k3s/</guid>
      <description>In my latest blog post, I share my journey setting up K3S, a lightweight Kubernetes distribution, in my home lab. With a step-by-step guide, I install K3S on an Ubuntu Server 22.04.2 LTS, offering a seamless experience. The post covers creating useful aliases for simplifying interactions with K3S and verifying the installation. Additionally, I introduce Portainer to manage Docker and Kubernetes in my home lab. I walk through setting up Portainer, adding a Kubernetes environment, and connecting it to the K3S cluster. Furthermore, I establish a local Docker registry and demonstrate optional steps for pushing and deploying Docker images within the K3S cluster.</description>
    </item>
    <item>
      <title>Unleashing the Power of LLaMA Server in Docker Container</title>
      <link>https://seehiong.github.io/posts/2023/07/unleashing-the-power-of-llama-server-in-docker-container/</link>
      <pubDate>Sat, 15 Jul 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/07/unleashing-the-power-of-llama-server-in-docker-container/</guid>
      <description>After completing the Generative AI with Large Language Models course, I&amp;rsquo;m thrilled to share my Dockerized experience running the LLaMA model. The guide covers setting up the project structure, creating a FastAPI application, and Dockerizing it. Additionally, I showcase building an AI chatbot, integrating it with FastAPI, HuggingFace embeddings, and LLaMA. The Docker environment loads the LLM and allows seamless interactions with PDFs. I conclude by enhancing performance with OpenBLAS, significantly reducing inferencing time. Explore the power of LLaMA Server in a Docker container for transformative AI experiences! 🚀</description>
    </item>
    <item>
      <title>How to summarize YouTube Videos in Minutes (II)</title>
      <link>https://seehiong.github.io/posts/2023/06/how-to-summarize-youtube-videos-in-minutes-ii/</link>
      <pubDate>Fri, 16 Jun 2023 20:00:00 +2000</pubDate>
      <guid>https://seehiong.github.io/posts/2023/06/how-to-summarize-youtube-videos-in-minutes-ii/</guid>
      <description>In this comprehensive guide, I explore AI-powered techniques to extract and summarize YouTube videos using tools like Whisper.cpp, GPT4All, LLaMA.cpp, and OpenAI models. I detail the step-by-step process, from setting up the environment to transcribing audio and leveraging AI for summarization. Despite encountering issues with GPT4All&amp;rsquo;s accuracy, alternative approaches using LLaMA.cpp and OpenAI models provide versatile summarization options. The tutorial aims to empower researchers, content creators, and information enthusiasts to efficiently analyze and summarize YouTube content using cutting-edge AI technologies.</description>
    </item>
    <item>
      <title>How to summarize YouTube Videos in Minutes (I)</title>
      <link>https://seehiong.github.io/posts/2023/06/how-to-summarize-youtube-videos-in-minutes-i/</link>
      <pubDate>Sat, 10 Jun 2023 20:00:00 +2000</pubDate>
      <guid>https://seehiong.github.io/posts/2023/06/how-to-summarize-youtube-videos-in-minutes-i/</guid>
      <description>Hey folks! Today, I&amp;rsquo;m stoked to introduce you to the game-changer that is GPT4All for summarizing YouTube videos. Join me on this journey of transformation as we set up the magic using Python. We&amp;rsquo;ll load transcripts, chunk them for optimal processing, and then unleash the power of GPT4All for mind-blowing summarizations. Brace yourself for amazement as we witness the magic unfold! Additionally, we&amp;rsquo;ll explore an optional OpenAI approach for comparison. Stay tuned for more exciting updates in the next blog post on video content summarization without embedded transcripts! ✨🚀</description>
    </item>
    <item>
      <title>Receipt OCR with LangChain, OpenAI and PyTesseract</title>
      <link>https://seehiong.github.io/posts/2023/06/receipt-ocr-with-langchain-openai-and-pytesseract/</link>
      <pubDate>Tue, 06 Jun 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/06/receipt-ocr-with-langchain-openai-and-pytesseract/</guid>
      <description>&lt;p&gt;Recently, I embarked on an exhilarating journey into the realm of receipt OCR using LangChain and OpenAI, inspired by the captivating course on &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://learn.deeplearning.ai/langchain/lesson/1/introduction&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;LangChain for LLM Application Development&lt;/a&gt;&#xD;&#xA;. This exploration allowed me to unlock the full potential of PyTesseract, an extraordinary Python tool that serves as my guiding light for optical character recognition (OCR). By harnessing the power of OpenCV and seamlessly integrating OpenAI into the workflow, I aimed to compile the most optimal OCR results and validate them using LangChain&amp;rsquo;s impressive llm-math tool. Join me on this exciting adventure as we unravel the intricacies of receipt OCR and discover the true potential of LangChain, OpenAI, and PyTesseract.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Autofill PDF with LangChain and LangFlow</title>
      <link>https://seehiong.github.io/posts/2023/05/autofill-pdf-with-langchain-and-langflow/</link>
      <pubDate>Fri, 26 May 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/05/autofill-pdf-with-langchain-and-langflow/</guid>
      <description>In this journey, I explore automating PDF autofill using LangChain and LangFlow. Leveraging LangFlow and OpenAI, I streamline the employment form completion process, demonstrating steps to install LangFlow and set up a PostgreSQL table. Despite encountering challenges in prototyping with LangFlow, the exploration progresses to auto-fill PDFs. After extracting form fields and LLaMA model setup, I employ LangChain to fetch PostgreSQL data. Concluding with Python manipulation to interpolate and update the PDF, the process achieves seamless auto-fill. Dive into the details, overcome challenges, and witness the power of LangChain and LangFlow in revolutionizing PDF automation.</description>
    </item>
    <item>
      <title>Running GPT4All for your PostgreSQL with LangChain</title>
      <link>https://seehiong.github.io/posts/2023/05/running-gpt4all-for-your-postgresql-with-langchain/</link>
      <pubDate>Sun, 21 May 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/05/running-gpt4all-for-your-postgresql-with-langchain/</guid>
      <description>In this exploration, I guide you through setting up GPT4All on a Windows PC and demonstrate its synergy with SQL Chain for PostgreSQL queries using LangChain. Utilizing Jupyter Notebook and prerequisites like PostgreSQL and GPT4All-J v1.3-groovy, I install dependencies and showcase LangChain and GPT4All model setup. Navigating an Open Source Shakespeare database, I provide an ER diagram for clarity. Querying GPT4All through LangChain, we delve into PostgreSQL queries and also compare responses with OpenAI. The comprehensive walkthrough empowers you to seamlessly integrate GPT4All into your PostgreSQL workflows for efficient and dynamic interactions.</description>
    </item>
    <item>
      <title>Running LLaMA server in local machine</title>
      <link>https://seehiong.github.io/posts/2023/05/running-llama-server-in-local-machine/</link>
      <pubDate>Sat, 13 May 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/05/running-llama-server-in-local-machine/</guid>
      <description>In continuation from my previous post, I prepared the environment using Pipenv and installed the OpenAI-like web server with specific CMAKE arguments. Running the server with a provided model was straightforward. To create an SSH tunnel to the remote Ubuntu machine from my Windows PC, I used PuTTY, configuring it to forward port 8888. Connecting from BYO-GPT involved adjusting the server endpoint in the Dart file. This seamless integration allowed me to access the Open API for the LLAMA CPP server and successfully connect BYO-GPT to the specified server.</description>
    </item>
    <item>
      <title>Building ChatBot for your PDF files with LangChain</title>
      <link>https://seehiong.github.io/posts/2023/05/building-chatbot-for-your-pdf-files-with-langchain/</link>
      <pubDate>Sun, 07 May 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/05/building-chatbot-for-your-pdf-files-with-langchain/</guid>
      <description>In this post, I extend the use case from my previous post to demonstrate building a ChatBot for PDF files using LangChain. In the preparation phase, I install Chroma, an open-source embedding database, and ingest a PDF file using PyPDFLoader. I then split the document into chunks and use Chroma&amp;rsquo;s default embeddings. Due to a potential issue, I provide an alternative embedding approach. Next, I load a local LLaMA model, prepare for question-answering, and run queries using RetrievalQAWithSourcesChain. I also touch on running with OpenBLAS for optimization. The guide empowers users to explore personalized question-answering over their PDF documents.</description>
    </item>
    <item>
      <title>Building a Basic Chain with LangChain</title>
      <link>https://seehiong.github.io/posts/2023/05/building-a-basic-chain-with-langchain/</link>
      <pubDate>Mon, 01 May 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/05/building-a-basic-chain-with-langchain/</guid>
      <description>With the LangChain framework and a setup from a previous post, I delve into building a basic chain using Llama.cpp within LangChain. Following preparations, I install required packages and run interactive Python code to set up the LLM model. The process involves formatting a prompt template and creating a chain. I explore memory integration, adding a conversation buffer for context. The conversation with AI is initiated and continued through user inputs. Stay tuned for more explorations in upcoming posts!</description>
    </item>
    <item>
      <title>Running LLaMA model locally</title>
      <link>https://seehiong.github.io/posts/2023/04/running-llama-model-locally/</link>
      <pubDate>Sun, 30 Apr 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/04/running-llama-model-locally/</guid>
      <description>In this thorough guide, I prepared my Ubuntu machine (32GB) for the LLaMA (Language Model) build. Following Georgi Gergano&amp;rsquo;s llama.cpp, I executed CMake commands, ensuring the correct tag and building the model successfully. I downloaded Microsoft&amp;rsquo;s Phi2 model in GGUF format, enabling local execution without exposing prompts or data. Running the Phi2 model showcased its capabilities in a few-shot interaction, providing accurate responses. Additionally, I explored optional OpenBLAS integration for improved speed, offering insights into the installation and rebuild process.</description>
    </item>
    <item>
      <title>Developing BYO-GPT with Flutter</title>
      <link>https://seehiong.github.io/posts/2023/04/developing-byo-gpt-with-flutter/</link>
      <pubDate>Sat, 29 Apr 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/04/developing-byo-gpt-with-flutter/</guid>
      <description>I dedicate around 10 minutes to create BYO-GPT, a Flutter app that allows easy interaction with ChatGPT through OpenAI&amp;rsquo;s API. After installing Flutter, setting up the project, and creating necessary widgets and models, I utilize the OpenAI API for chat completion. The app includes user and GPT message bubbles, as well as a user input section with a GPT icon. By employing the Provider package, the app efficiently manages state changes. Additionally, I provide the option to switch models for experimentation. Overall, BYO-GPT provides a user-friendly interface for seamless communication with ChatGPT.</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (IV)</title>
      <link>https://seehiong.github.io/posts/2021/07/ci/cd-pipeline-on-pi-cluster-iv/</link>
      <pubDate>Sun, 18 Jul 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/07/ci/cd-pipeline-on-pi-cluster-iv/</guid>
      <description>In the fourth part of my Raspberry Pi CI/CD pipeline series, I integrated SonarQube into the workflow for continuous code quality and security. I installed SonarQube on my Raspberry Pi Cluster, utilizing a custom Docker image. Additionally, I replaced Gitea with Gitlab for enhanced compatibility with SonarQube. I built and deployed Gitlab on the cluster, managing persistent storage with Longhorn volumes. For seamless integration, I configured Gitlab settings, created a Jenkins user, and set up access tokens. Lastly, I prepared Jenkins by installing necessary plugins and establishing connections with Gitlab. The result is an extended CI/CD pipeline with SonarQube, Jenkins, and Gitlab on a Raspberry Pi Cluster.</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (III)</title>
      <link>https://seehiong.github.io/posts/2021/07/ci/cd-pipeline-on-pi-cluster-iii/</link>
      <pubDate>Sun, 04 Jul 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/07/ci/cd-pipeline-on-pi-cluster-iii/</guid>
      <description>In the third part of my Raspberry Pi CI/CD pipeline series, I incorporated JFrog Container Registry. Following the previous guide, I installed the registry, configured Docker images, and set up Longhorn volumes. Configuring the JFrog Container Registry involved adding local repositories, setting permissions, and configuring HTTP settings. I demonstrated testing the registry with Docker login and pushing an image. For Kubernetes integration, I created registry secrets and updated deployment files. The result is a complete CI/CD pipeline on a Raspberry Pi Cluster with JFrog Container Registry supporting Docker images. Optional Jenkins configuration is provided for maven-agent support.</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (II)</title>
      <link>https://seehiong.github.io/posts/2021/06/ci/cd-pipeline-on-pi-cluster-ii/</link>
      <pubDate>Mon, 21 Jun 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/06/ci/cd-pipeline-on-pi-cluster-ii/</guid>
      <description>In the second installment of my Raspberry Pi CI/CD pipeline series, I seamlessly integrated JFrog Artifactory. Following the groundwork laid in [Part I], I extended the pipeline by configuring Maven-agent for Longhorn volume mounting, building a Raspberry Pi-compatible Artifactory Docker image, and configuring Artifactory. I demonstrated the process of creating permissions, Maven settings, and deploying JAR files. The integration with Jenkins involved plugin installation, settings configuration, and Jenkinsfile creation for artifact deployment. The result is a robust CI/CD pipeline on a Raspberry Pi Cluster, efficiently deploying artifacts to Artifactory. Troubleshooting tips address Longhorn volume stability and Jenkins volume permission issues.</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (I)</title>
      <link>https://seehiong.github.io/posts/2021/06/ci/cd-pipeline-on-pi-cluster-i/</link>
      <pubDate>Sun, 13 Jun 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/06/ci/cd-pipeline-on-pi-cluster-i/</guid>
      <description>In this series, I documented my journey building a CI/CD pipeline on a Raspberry Pi Cluster, featuring 3 master and 1 worker nodes, all housed in a custom LEGO structure. The setup includes tools like Metallb for load balancing, along with specific volumes for MySQL, Gitea, Jenkins, and Maven-agent. I detailed the installation processes for MySQL, Gitea, Jenkins, and Maven-agent, complete with YAML deployment files. The configuration steps for Jenkins, both for Kubernetes and Gitea integration, were outlined. The troubleshooting section covers issues related to Kubernetes connection errors and finding the Jenkins initial admin password. The final result showcases a functional CI/CD pipeline: when code is committed, it triggers the CI pipeline, with the Maven-agent building and compiling the code successfully.</description>
    </item>
    <item>
      <title>Pi Cluster with Longhorn</title>
      <link>https://seehiong.github.io/posts/2021/06/pi-cluster-with-longhorn/</link>
      <pubDate>Sun, 06 Jun 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/06/pi-cluster-with-longhorn/</guid>
      <description>I documented my journey setting up a Raspberry Pi Cluster with Longhorn for simplified cloud-native persistent block storage. The process took 30 minutes and assumed a functional Raspberry Pi Cluster. I prepared the environment by installing Helm, Calico CLI, and optionally, Kubernetes Dashboard. Then, I detailed the installation of Longhorn with Helm, including verification steps. Accessing Longhorn involved port-forwarding to the frontend service. The result: a highly available persistent storage solution for my Raspberry Pi Cluster, as depicted in the Longhorn dashboard. I addressed troubleshooting issues related to Calico and Longhorn uninstallation, ensuring a smooth experience.</description>
    </item>
    <item>
      <title>K8s Pi Cluster with Ansible</title>
      <link>https://seehiong.github.io/posts/2021/05/k8s-pi-cluster-with-ansible/</link>
      <pubDate>Sat, 29 May 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/05/k8s-pi-cluster-with-ansible/</guid>
      <description>I documented my journey configuring a Kubernetes Cluster on a Raspberry Pi using Ansible, totaling 50 minutes. I deployed three Raspberry Pi 4 Model B 8GB as master nodes and one Raspberry Pi 3 Model B as a worker. After installing Ansible, Flash, and kubectl, I prepared the SD cards with customized cloud-config.yml files. Ansible inventory was configured accordingly. Additional SSH and system adjustments were made on each node. Customizations were applied, and the Kubernetes cluster setup was initiated using the Ansible playbook. Troubleshooting tips were provided for potential issues. Finally, the Kubernetes Pi Cluster with Ansible was ready for use.</description>
    </item>
    <item>
      <title>HA K8s Pi Cluster (II)</title>
      <link>https://seehiong.github.io/posts/2020/08/ha-k8s-pi-cluster-ii/</link>
      <pubDate>Mon, 17 Aug 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/08/ha-k8s-pi-cluster-ii/</guid>
      <description>In my journey to establish a Highly Available Kubernetes Pi Cluster, I&amp;rsquo;ve successfully configured the cluster following an external etcd setup. The process involves installing Docker, setting up the Docker daemon, and installing kubeadm. Initializing Kubernetes Master Nodes, preparing certificates, and configuring Calico for networking are key steps. Troubleshooting tips include addressing refused connections and certificate expiration. To rejoin a faulty node, cordoning, draining, and generating new keys are essential. Now, I proudly own a fully operational Highly Available Kubernetes Pi Cluster.</description>
    </item>
    <item>
      <title>HA K8s Pi Cluster (I)</title>
      <link>https://seehiong.github.io/posts/2020/08/ha-k8s-pi-cluster-i/</link>
      <pubDate>Sun, 09 Aug 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/08/ha-k8s-pi-cluster-i/</guid>
      <description>In this special guide, I celebrate Singapore&amp;rsquo;s 55th National Day by setting up a Highly Available Kubernetes Pi Cluster using 2x Raspberry Pi Model B 8GB. With a total setup time of 25 minutes, I configure an external etcd key-value store, laying the foundation for high availability. I detail OS preparation, creating a virtual IP with Keepalived, generating certificates for etcd, and setting up etcd on each master node. Troubleshooting tips are provided, including addressing cluster ID mismatches and replacing faulty members. Stay tuned for the next article covering the continuation of the HA configuration.</description>
    </item>
    <item>
      <title>Private Registry for K8s Cluster</title>
      <link>https://seehiong.github.io/posts/2020/08/private-registry-for-k8s-cluster/</link>
      <pubDate>Fri, 07 Aug 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/08/private-registry-for-k8s-cluster/</guid>
      <description>I&amp;rsquo;ve successfully set up my Private Registry for the Kubernetes Cluster on Raspberry Pi. With this, I have full control over the Docker registry, enhancing overall performance. The process involves creating a self-signed certificate, installing it on master and leaf nodes, and deploying the registry. Utilizing the private registry with Jenkins is seamless: tagging, pushing, and pulling images. Troubleshooting tips include updating the hosts file and trusting the certificate at the OS level. Now, my Kubernetes Cluster benefits from a personalized, efficient private registry.</description>
    </item>
    <item>
      <title>OpenWrt Router on Pi 3</title>
      <link>https://seehiong.github.io/posts/2020/08/openwrt-router-on-pi-3/</link>
      <pubDate>Sun, 02 Aug 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/08/openwrt-router-on-pi-3/</guid>
      <description>I&amp;rsquo;ve successfully configured OpenWrt Router on my Raspberry Pi 3, enhancing customization for my application needs. The process involves selecting the appropriate Raspberry Pi image, inserting the SD card, and configuring OpenWrt settings. After adjusting LED configurations and network interfaces, I added static leases for Kubernetes nodes. Following a reboot, I reconfigured my Kubernetes Cluster due to IP changes. Troubleshooting involved handling missing wireless menus and resolving issues with Jenkins caused by taints. Now, my Raspberry Pi serves as a versatile OpenWrt Router seamlessly integrated with my Kubernetes Cluster.</description>
    </item>
    <item>
      <title>Jenkins Maven Agent</title>
      <link>https://seehiong.github.io/posts/2020/07/jenkins-maven-agent/</link>
      <pubDate>Fri, 31 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/jenkins-maven-agent/</guid>
      <description>I&amp;rsquo;ve successfully created a Jenkins Maven Agent for my Kubernetes Cluster, significantly improving Maven build times. Configuring Jenkins involved adding a pod template named maven with specific container and volume settings. I created a persistent volume and claims for the Maven repository, reducing build times for subsequent executions. Troubleshooting included resolving errors related to missing persistent volume claims and ownership issues. Now, my Jenkins builds efficiently leverage a local Maven repository within the Kubernetes environment, resulting in faster and more efficient Maven builds.</description>
    </item>
    <item>
      <title>Jenkins Pipeline for K8s Cluster</title>
      <link>https://seehiong.github.io/posts/2020/07/jenkins-pipeline-for-k8s-cluster/</link>
      <pubDate>Fri, 31 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/jenkins-pipeline-for-k8s-cluster/</guid>
      <description>I effortlessly set up a Jenkins Pipeline for my Kubernetes Cluster, enabling seamless continuous integration for my projects. Following my previous post on integrating Jenkins and Gitea, I configured Git and Gitea, creating a declarative Jenkins pipeline. With Gitea webhooks triggering builds on Git commits, I successfully tested the pipeline for a Spring Boot Hello-World application. The pipeline integrates with Git, Maven, and Gitea, ensuring efficient builds and synchronization with each commit. Troubleshooting tips address potential issues, providing a smooth Jenkins experience. Next, I plan to enhance Maven build times in my upcoming guide.</description>
    </item>
    <item>
      <title>Integrating Jenkins and Gitea</title>
      <link>https://seehiong.github.io/posts/2020/07/integrating-jenkins-and-gitea/</link>
      <pubDate>Sun, 26 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/integrating-jenkins-and-gitea/</guid>
      <description>I seamlessly integrated Jenkins and Gitea, establishing full control over my self-hosted continuous integration (CI) environment. I installed the Gitea plugin on Jenkins, configured Gitea, and set up Jenkins to recognize the Gitea organization. The integration allows automatic build triggers upon committing to the Gitea repository. Additionally, I tested the webhook connection for smooth functionality. With this setup, I&amp;rsquo;m ready to dive into the CI workflow for my Spring Boot application in the upcoming post. Stay tuned for more!</description>
    </item>
    <item>
      <title>Helm for K8s Cluster</title>
      <link>https://seehiong.github.io/posts/2020/07/helm-for-k8s-cluster/</link>
      <pubDate>Fri, 24 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/helm-for-k8s-cluster/</guid>
      <description>I&amp;rsquo;ve successfully set up Helm as the package manager for my Raspberry Pi Kubernetes Cluster, enabling easy discovery, sharing, and use of Kubernetes software. After installing Helm, I set up the NGINX Ingress Controller using Helm for external access. Additionally, I configured MetalLB as a layer 2 load balancer to manage external IP addresses. Revisiting my Gitea setup, I updated the service configuration to leverage MetalLB, enhancing the overall scalability and efficiency of my Kubernetes environment on Raspberry Pi. Helm proves to be a valuable tool for managing Kubernetes packages effortlessly.</description>
    </item>
    <item>
      <title>Jenkins for K8s Cluster (II)</title>
      <link>https://seehiong.github.io/posts/2020/07/jenkins-for-k8s-cluster-ii/</link>
      <pubDate>Sun, 19 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/jenkins-for-k8s-cluster-ii/</guid>
      <description>I&amp;rsquo;ve successfully set up Jenkins Agents for my Kubernetes Cluster, enhancing its capabilities for automated build, test, and scalable deployment pipelines. Following Docker image creation for the Jenkins agent on the Raspberry Pi, I configured Jenkins for scalability. Adjustments included setting the inbound agent protocol and configuring Kubernetes cloud settings. Creating Jenkins jobs and scheduling builds demonstrated the functionality, with agents initially suspended and later executing jobs successfully. The troubleshooting tip highlighted the importance of naming the container as jnlp. My Jenkins on Kubernetes Cluster is now fully operational, ready for future pipeline configurations.</description>
    </item>
    <item>
      <title>Jenkins for K8s Cluster (I)</title>
      <link>https://seehiong.github.io/posts/2020/07/jenkins-for-k8s-cluster-i/</link>
      <pubDate>Sun, 12 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/jenkins-for-k8s-cluster-i/</guid>
      <description>I&amp;rsquo;ve successfully set up Jenkins on my Kubernetes Cluster, streamlining build, test, and deployment pipelines. Following a Docker image creation for Jenkins on the Raspberry Pi, I deployed it to the Kubernetes Cluster. Troubleshooting involved building a custom Docker image due to ARM architecture limitations. Additionally, I addressed a service account error by creating the necessary role and role binding. Now, I can access Jenkins and proceed to configure Jenkins Agents for Kubernetes in the next post, enhancing automation within my cluster.</description>
    </item>
    <item>
      <title>Gitea for K8s Cluster</title>
      <link>https://seehiong.github.io/posts/2020/07/gitea-for-k8s-cluster/</link>
      <pubDate>Fri, 10 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/gitea-for-k8s-cluster/</guid>
      <description>In my recent endeavor, I spent 40 minutes setting up Gitea on my Kubernetes Pi cluster, granting me absolute control over personal Git repositories. I seamlessly integrated MySQL, using Docker images and Kubernetes configurations. The meticulous setup involved creating necessary paths on an external HDD, configuring persistent volumes, and ensuring a smooth deployment. I prepared MySQL for Gitea, creating a user, database, and granting privileges. Gitea installation via Docker and subsequent exposure to external access using NodePort were executed flawlessly. A troubleshooting tip addressed a MySQL access issue. Now, my Gitea on Kubernetes Pi Cluster is fully operational for efficient repository management.</description>
    </item>
    <item>
      <title>Kubernetes Cluster on Pi</title>
      <link>https://seehiong.github.io/posts/2020/07/kubernetes-cluster-on-pi/</link>
      <pubDate>Sat, 04 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/kubernetes-cluster-on-pi/</guid>
      <description>I recently spent 70 minutes setting up a Kubernetes Cluster on Raspberry Pi using Ubuntu Server 20.04 LTS. After burning the OS image and configuring a headless setup, I updated the OS, changed the hostname, and enabled memory cgroup. The Docker installation involved setting up external storage and configuring Docker daemon. Installing kubeadm and creating the Kubernetes cluster took an additional 45 minutes. I verified the cluster status, installed networking addons (Calico), and added leaf nodes. Troubleshooting included resolving conntrack and socat issues. Overall, the Raspberry Pi Kubernetes Cluster provides full control over Docker container orchestration.</description>
    </item>
    <item>
      <title>Gitea for MicroK8s Cluster</title>
      <link>https://seehiong.github.io/posts/2020/06/gitea-for-microk8s-cluster/</link>
      <pubDate>Mon, 29 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/gitea-for-microk8s-cluster/</guid>
      <description>I dedicated 45 minutes to set up Gitea on my Raspberry Pi cluster using MicroK8s. Gitea, a self-hosted Git service, grants my team cost savings and enhanced server control. I ensured a smooth installation by preparing MySQL, creating required paths on an external HDD, and configuring persistent volumes. Following MySQL setup, I seamlessly prepared the database and moved on to setting up Gitea with Docker, utilizing a docker-compose.yml file. After injecting images into MicroK8s cache, I exposed Gitea externally using NodePort. Troubleshooting tips were handy, addressing MySQL connection issues. My self-hosted Git service is now ready for efficient collaboration.</description>
    </item>
    <item>
      <title>Docker for MicroK8s Cluster</title>
      <link>https://seehiong.github.io/posts/2020/06/docker-for-microk8s-cluster/</link>
      <pubDate>Sun, 21 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/docker-for-microk8s-cluster/</guid>
      <description>Setting up Docker on my Raspberry Pi Cluster took just 15 minutes. After installing Docker, I added the ubuntu user to the Docker group. Configuring Docker included adjusting the daemon settings for external storage. Testing Docker with a hello-world container went smoothly. To use local images for MicroK8s, I exported and injected the image successfully. Troubleshooting involved resolving daemon start errors, addressing connection issues, and handling permission errors. Formatting the existing NTFS HDD to ext4 and adjusting boot-up settings resolved challenges, making Docker work seamlessly on my Raspberry Pi Cluster.</description>
    </item>
    <item>
      <title>GNU Health</title>
      <link>https://seehiong.github.io/posts/2020/06/gnu-health/</link>
      <pubDate>Sun, 21 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/gnu-health/</guid>
      <description>Exploring GNU Health Embedded on Raspberry Pi 3 for a personal Electronic Medical Record took me 45 minutes. Downloading the image from GNU Health, I utilized Balena Etcher for SD card writing. After attaching peripherals, openSUSE OS booted with the default credentials gnuhealth and freedom. Navigating the GNU Health HMIS, I used admin/gnusolidario to access features like Families and Family Members. Troubleshooting openSUSE involved the root user with the password test. This health system is a potential asset for managing medical information locally, emphasizing personal well-being during the ongoing pandemic.</description>
    </item>
    <item>
      <title>External Storage</title>
      <link>https://seehiong.github.io/posts/2020/06/external-storage/</link>
      <pubDate>Fri, 19 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/external-storage/</guid>
      <description>Expanding my Raspberry Pi Cluster&amp;rsquo;s storage with an external 640GB USB hard disk took 35 minutes. After mounting the external storage and addressing troubleshooting issues, I configured MicroK8s default storage to utilize the added space. Despite encountering errors, a reset and careful configuration solved the problem. Adding leaf nodes for MicroK8s and troubleshooting service unavailability for the dashboard completed the setup. I also disabled and re-enabled addons, ensuring a smooth integration of external storage with my MicroK8s cluster. Accessing the Kubernetes dashboard and checking nodes confirmed a successful expansion.</description>
    </item>
    <item>
      <title>Plasma Bigscreen</title>
      <link>https://seehiong.github.io/posts/2020/06/plasma-bigscreen/</link>
      <pubDate>Sun, 14 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/plasma-bigscreen/</guid>
      <description>Excited to explore, I set up Plasma Bigscreen on my Raspberry Pi 4 Model B 8GB in just 30 minutes. Downloading the beta image and using Win32DiskImager to write it onto the SD card, I encountered an activation step on home.mycroft.ai after booting up. Registering with Mycroft and adding the device, I faced voice recognition issues with Apple earpods and opted for a hard reboot. Although the beta stage led me to wait for improvements, I&amp;rsquo;m eager to retry with a USB microphone. Stay tuned for updates! Troubleshooting TV remote and USB keyboard issues involved username/password and OS update attempts.</description>
    </item>
    <item>
      <title>MicroK8s on Pi 4 8GB (II)</title>
      <link>https://seehiong.github.io/posts/2020/06/microk8s-on-pi-4-8gb-ii/</link>
      <pubDate>Tue, 09 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/microk8s-on-pi-4-8gb-ii/</guid>
      <description>In the second part of my MicroK8s adventure on Raspberry Pi 4 Model B 8GB, I spent 45 minutes adding low-cost Raspberry Pi nodes to enhance cluster performance. Utilizing two older Pi 3B devices with Ubuntu Server (64-bit), I updated the OS, installed MicroK8s, and adjusted configurations. The master node initiated new node creation with &amp;ldquo;sudo microk8s add-node,&amp;rdquo; copying the output to each node. Successful integration was confirmed with &amp;ldquo;microk8s kubectl get node.&amp;rdquo; Excited to explore Kubernetes possibilities and gradually shift CI/CD pipelines to this lightweight cluster. Stay tuned for more on its diverse use cases!</description>
    </item>
    <item>
      <title>MicroK8s on Pi 4 8GB (I)</title>
      <link>https://seehiong.github.io/posts/2020/06/microk8s-on-pi-4-8gb-i/</link>
      <pubDate>Sat, 06 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/microk8s-on-pi-4-8gb-i/</guid>
      <description>I recently spent 40 minutes setting up MicroK8s on my new Raspberry Pi 4 Model B 8GB. Opting for a headless install due to a lack of a microHDMI cable, I used Ubuntu Server (64-bit) for the 64-bit requirements of MicroK8s. After initial setup, including changing the hostname and enabling memory cgroup, I installed MicroK8s, ensuring compatibility by adding my user to the MicroK8s group. Verification and usage of MicroK8s followed, with additional steps for enabling services like the dashboard. Troubleshooting involved switching to a 64-bit OS and finding the Pi&amp;rsquo;s IP using nmap. Excited to explore MicroK8s on my Raspberry Pi!</description>
    </item>
    <item>
      <title>NAS Server</title>
      <link>https://seehiong.github.io/posts/2020/06/nas-server/</link>
      <pubDate>Fri, 05 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/nas-server/</guid>
      <description>Repurposing my Raspberry Pi 3B into a NAS server using OpenMediaVault (OMV) was a 90-minute project. I opted for Raspberry Pi OS Lite, ensuring its integrity with MD5 &amp;amp; SHA checksums. Win32DiskImager facilitated OS installation on a 16GB SD card. After powering up, I updated the OS, configured settings, and initiated OMV installation using commands provided by developers. Post-installation, I accessed OMV through the Pi&amp;rsquo;s IP address, configured settings, added a user, mounted an external HDD, created a shared folder, and enabled SMB/CIFS service. Following these steps, I successfully owned a personal OMV on Raspberry Pi!</description>
    </item>
    <item>
      <title>About Me</title>
      <link>https://seehiong.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seehiong.github.io/about/</guid>
      <description>&lt;hr&gt;&#xA;&lt;h2 id=&#34;hosted-projects&#34;&gt;Hosted Projects&lt;/h2&gt;&#xA;&lt;p&gt;Explore some of the open-source and experimental projects I’ve developed. Each comes with a blog post outlining the build process, deployment strategies, and lessons learned:&lt;/p&gt;&#xA;&lt;p&gt;🔹&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://byogpt-chat.github.io/web&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;BYOGPT-CHAT&lt;/a&gt;&#xD;&#xA; - An AI-powered chatbot built with Flutter and integrated with local LLMs → &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://seehiong.github.io/posts/2023/04/developing-byo-gpt-with-flutter/&#34; &gt;related post&lt;/a&gt;&#xD;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;🌍 &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://seehiong.github.io/qgis2web&#34; &gt;QGIS2Web&lt;/a&gt;&#xD;&#xA; - A geospatial visualization tool built with QGIS and Leaflet, used for planning and route optimization → &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://seehiong.github.io/posts/2024/06/planning-gift-deliveries-with-qgis/&#34; &gt;related post&lt;/a&gt;&#xD;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;🏢 &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://hdb-resale-price-xgb-predictor.streamlit.app/&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;HDB Resale Price Predictor App&lt;/a&gt;&#xD;&#xA; - A full-stack ML application that runs an XGBoost model locally within Streamlit Community Cloud. The app predicts resale flat prices using housing attributes and showcases a lightweight, serverless deployment of machine learning in a self-contained web app → &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://seehiong.github.io/posts/2025/05/deploying-kserve-on-oke/&#34; &gt;related post&lt;/a&gt;&#xD;&#xA;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
