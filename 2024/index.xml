<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2024 on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/2024/</link>
    <description>Recent content in 2024 on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 29 Dec 2024 10:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/2024/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building a Flexible Optimizer Framework with Micronaut</title>
      <link>https://seehiong.github.io/2024/designing-an-optimizer-framework/</link>
      <pubDate>Sun, 29 Dec 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/designing-an-optimizer-framework/</guid>
      <description>&lt;p&gt;Combinatorial optimization problems are fundamental challenges in modern computing, particularly in logistics, network design, and operations research. The &lt;em&gt;Facility Location Problem (FLP)&lt;/em&gt; and &lt;em&gt;Traveling Salesman Problem (TSP)&lt;/em&gt; represent prime examples of these challenges. In this post, we&amp;rsquo;ll explore the development of a sophisticated optimizer framework using Micronaut, featuring real-time progress tracking and a modular, extensible architecture.&lt;/p&gt;&#xA;&lt;p&gt;With the exciting announcement of the &lt;a href=&#34;https://code.visualstudio.com/blogs/2024/12/18/free-github-copilot&#34; target=&#34;_blank&#34;&gt;free plan for Github Copilot&lt;/a&gt;, we&amp;rsquo;ll leverage AI-assisted development to create our Micronaut Optimizer framework. This powerful combination of tools will help us tackle complex combinatorial optimization problems efficiently.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Porting Llama3.java to Micronaut</title>
      <link>https://seehiong.github.io/2024/porting-llama3.java-to-micronaut/</link>
      <pubDate>Sun, 15 Dec 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/porting-llama3.java-to-micronaut/</guid>
      <description>This project ports the original single-file llama3.java by Alfonso² Peterssen into a modular Micronaut application, transforming it from a console app to a stream-based, production-ready API. The internals and performance of the original GGUF-format LLM remain unchanged. Updates focus on restructuring the codebase into logical packages and adapting it to Micronaut’s ecosystem, enabling easier integration with Java microservices. This streamlined design retains the original’s simplicity while enhancing scalability and usability for modern AI applications.</description>
    </item>
    <item>
      <title>Porting Llama2.java to Micronaut</title>
      <link>https://seehiong.github.io/2024/porting-llama2.java-to-micronaut/</link>
      <pubDate>Sat, 07 Dec 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/porting-llama2.java-to-micronaut/</guid>
      <description>This post explores porting the single-file llama2.java into a robust Micronaut application, demonstrating both JDK and GraalVM native mode performance. While GraalVM offers faster startup (56ms), its serving throughput is slower (210 tokens/sec). For high-performance inference, JDK mode is preferred, but GraalVM shines for lightweight, startup-critical scenarios. The journey highlights Micronaut&amp;rsquo;s ease of integration for AI applications.</description>
    </item>
    <item>
      <title>Building an AI Knowledge Assistant</title>
      <link>https://seehiong.github.io/2024/building-an-ai-knowledge-assistant/</link>
      <pubDate>Sun, 24 Nov 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/building-an-ai-knowledge-assistant/</guid>
      <description>Learn how to build an AI-powered knowledge assistant using Python. This guide covers data ingestion from sources like PDFs, deploying a FastAPI-based API, and querying the assistant for detailed answers. Using advanced retrieval mechanisms, the assistant provides contextually relevant responses. You&amp;rsquo;ll also explore a working example with the CQRS design pattern. The complete project code is available on &lt;a href=&#34;https://github.com/seehiong/ai-knowledge-assistant&#34; target=&#34;_blank&#34;&gt;GitHub&lt;/a&gt;.</description>
    </item>
    <item>
      <title>Exploring AI with Raspberry Pi 5</title>
      <link>https://seehiong.github.io/2024/exploring-ai-with-raspberry-pi-5/</link>
      <pubDate>Sat, 09 Nov 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/exploring-ai-with-raspberry-pi-5/</guid>
      <description>In this post, I dive into the powerful capabilities of the Raspberry Pi 5 paired with the Hailo-8L AI Kit, a neural network accelerator offering 13 TOPS. After setting up the system and camera, I explore object detection, pose estimation, and instance segmentation, showcasing the Pi’s impressive AI potential. Whether using pre-trained models or custom configurations, this compact setup proves to be a versatile tool for AI enthusiasts and developers alike. It&amp;rsquo;s a fun, hands-on introduction to the world of edge AI on a budget-friendly platform.</description>
    </item>
    <item>
      <title>GPT-2 Training Guide</title>
      <link>https://seehiong.github.io/2024/gpt-2-training-guide/</link>
      <pubDate>Thu, 31 Oct 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/gpt-2-training-guide/</guid>
      <description>This post documents my journey training GPT-2 on the Tiny Shakespeare dataset, inspired by Andrej Karpathy&amp;rsquo;s instructional video and nanoGPT repository. Following each step, I detail the setup process, from encoding data and optimizing the model with AdamW, to improving training stability with mixed precision and flash attention. The post includes practical insights on using pretrained weights, weight sharing, and efficient data handling, concluding with sample outputs from training and sampling a “baby” GPT model.</description>
    </item>
    <item>
      <title>GPT-2 Setup and Pretraining Guide</title>
      <link>https://seehiong.github.io/2024/gpt-2-setup-and-pretraining-guide/</link>
      <pubDate>Mon, 28 Oct 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/gpt-2-setup-and-pretraining-guide/</guid>
      <description>This guide explores reproducing GPT-2 (124M) using Andrej Karpathy’s video walkthrough. It begins with an overview of the GPT-2 architecture, a decoder-only transformer model inspired by &amp;ldquo;Attention Is All You Need.&amp;rdquo; Using pretrained GPT-2 weights, we analyze and initialize a custom GPT class, with detailed steps to handle token embeddings, causal attention, and layer normalization. The guide includes code for generating text from pretrained weights. In the next segment, we’ll continue with a deeper dive into dataset preparation and training from scratch, moving from small samples to large-scale training.</description>
    </item>
    <item>
      <title>Integrating MLflow and Kubeflow on Talos</title>
      <link>https://seehiong.github.io/2024/integrating-mlflow-and-kubeflow-on-talos/</link>
      <pubDate>Sun, 20 Oct 2024 08:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/integrating-mlflow-and-kubeflow-on-talos/</guid>
      <description>This post details the installation of MLflow and Kubeflow on a Talos HomeLab cluster. It covers the setup process, including Talos configuration, local-path and NFS provisioning, and Metallb installation. Step-by-step instructions are provided for deploying Kubeflow, followed by the installation of MLflow for managing the machine learning lifecycle. Finally, the post illustrates how to log experiments and models in MLflow and perform inference, demonstrating a seamless integration of these tools for enhanced machine learning operations.</description>
    </item>
    <item>
      <title>Deploy Microservices with Talos Locally</title>
      <link>https://seehiong.github.io/2024/deploy-microservices-with-talos-locally/</link>
      <pubDate>Sun, 13 Oct 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/deploy-microservices-with-talos-locally/</guid>
      <description>In this guide, we walk through deploying the Google Cloud Microservices Demo locally using Talos Linux in a VirtualBox VM. This step-by-step tutorial replicates a GKE environment, enabling seamless integration of microservices in a local Kubernetes cluster. We cover Talos installation, setting up the microservices demo, integrating MetalLB for load balancing, and optional Istio service mesh and Kiali observability for advanced monitoring. This approach is perfect for developers looking to simulate cloud environments locally and ensure their microservices run smoothly before deploying to production.</description>
    </item>
    <item>
      <title>Controlling RoArm-M2-S with ROS2</title>
      <link>https://seehiong.github.io/2024/controlling-roarm-m2-s-with-ros2/</link>
      <pubDate>Sun, 06 Oct 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/controlling-roarm-m2-s-with-ros2/</guid>
      <description>Learn how to set up and control the RoArm-M2-S robotic arm using ROS2 in a virtual environment. This guide walks you through installing VirtualBox, creating a custom Ubuntu VM, setting up ROS2 with MoveIt2, and running driver nodes to control the arm through RViz, MoveIt, keyboard, and a web interface.</description>
    </item>
    <item>
      <title>Wave Rover with Raspberry Pi 4</title>
      <link>https://seehiong.github.io/2024/wave-rover-with-raspberry-pi-4/</link>
      <pubDate>Sat, 28 Sep 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/wave-rover-with-raspberry-pi-4/</guid>
      <description>This post documents using a Raspberry Pi 4 as the main controller for the Wave Rover project. It covers installing Raspberry Pi OS, setting up the UGV_RPI package, enabling VNC, and configuring the Pi camera. Additionally, it details how to control the rover&amp;rsquo;s movement with Python and stream camera feeds via Flask. A sample HTML interface is provided for controlling the rover with arrow keys or buttons. Troubleshooting steps are included for resolving issues related to Picamera2 and V4L2 errors during the setup.</description>
    </item>
    <item>
      <title>Wave Rover: Setup Guide and Troubleshooting Tips</title>
      <link>https://seehiong.github.io/2024/wave-rover-setup-guide-and-troubleshooting-tips/</link>
      <pubDate>Sat, 21 Sep 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/wave-rover-setup-guide-and-troubleshooting-tips/</guid>
      <description>This guide walks you through setting up the Wave Rover, including hardware connections and software configuration. It covers common issues like missing drivers and file errors, providing step-by-step solutions for problems such as the CP2102N USB to UART Bridge Controller and missing libraries like ArduinoJson or Adafruit_GFX. Whether you&amp;rsquo;re troubleshooting hardware connections or resolving compilation errors, this guide ensures a smooth setup process.</description>
    </item>
    <item>
      <title>Talos Linux: Setting Up a Secure, Immutable Kubernetes Cluster</title>
      <link>https://seehiong.github.io/2024/talos-linux-setting-up-a-secure-immutable-kubernetes-cluster/</link>
      <pubDate>Sun, 01 Sep 2024 08:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/talos-linux-setting-up-a-secure-immutable-kubernetes-cluster/</guid>
      <description>This post guides you through setting up a secure, immutable Kubernetes cluster using Talos Linux. It covers installing Talos on control and worker nodes, configuring local storage with hostPath and Local Path Provisioner, and setting up the Kubernetes Dashboard with an admin user for cluster management. With Talos Linux, you achieve a minimal, API-managed Kubernetes environment without SSH or systemd, making it ideal for a secure and reliable homelab or production setup.</description>
    </item>
    <item>
      <title>Audio Generation with NVIDIA Jetson Orin NX</title>
      <link>https://seehiong.github.io/2024/audio-generation-with-nvidia-jetson-orin-nx/</link>
      <pubDate>Sun, 25 Aug 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/audio-generation-with-nvidia-jetson-orin-nx/</guid>
      <description>This post explores the audio generation capabilities of the NVIDIA Jetson Orin NX. It covers transcribing audio using Whisper, setting up text-to-speech (TTS) and automatic speech recognition (ASR) with Llamaspeak, and preparing the RIVA server for advanced speech AI applications. Detailed instructions and command examples are provided, making it easy for developers to experiment with these tools on the Jetson platform.</description>
    </item>
    <item>
      <title>Unleashing Text Generation with NVIDIA Jetson Orin NX</title>
      <link>https://seehiong.github.io/2024/unleashing-text-generation-with-nvidia-jetson-orin-nx/</link>
      <pubDate>Sat, 17 Aug 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/unleashing-text-generation-with-nvidia-jetson-orin-nx/</guid>
      <description>This post explores the powerful capabilities of NVIDIA Jetson Orin NX for text generation tasks. It covers the setup and use of models like Llama 2 and Llama 3, including installation steps, performance benchmarks, and examples of interactive AI sessions. Additionally, it provides insights into using the Jetson platform for deploying AI models efficiently, with practical tips on getting started and maximizing performance. Whether you&amp;rsquo;re a developer or AI enthusiast, this guide offers a hands-on look at harnessing NVIDIA Jetson&amp;rsquo;s potential for advanced AI applications.</description>
    </item>
    <item>
      <title>Scaling Kafka Workloads with KEDA in Kubernetes</title>
      <link>https://seehiong.github.io/2024/scaling-kafka-workloads-with-keda-in-kubernetes/</link>
      <pubDate>Sat, 10 Aug 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/scaling-kafka-workloads-with-keda-in-kubernetes/</guid>
      <description>This post demonstrates how to use KEDA, a Kubernetes-based Event Driven Autoscaler, to dynamically scale Kafka consumer workloads. Building on a previous setup with Kafka on MicroK8s, the guide walks through the installation of KEDA, configuring Kafka consumers, setting up secrets for authentication, and creating a ScaledObject to manage scaling based on message load. The post also includes practical examples of scaling under different loads, showcasing how KEDA automates horizontal scaling without requiring changes to the microservices code, making it easier to manage workloads in a Kubernetes environment.</description>
    </item>
    <item>
      <title>Exploring NVIDIA Jetson Orin NX: Flashing and Setup Guide</title>
      <link>https://seehiong.github.io/2024/exploring-nvidia-jetson-orin-nx-flashing-and-setup-guide/</link>
      <pubDate>Fri, 09 Aug 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/exploring-nvidia-jetson-orin-nx-flashing-and-setup-guide/</guid>
      <description>In this guide, I document the process of setting up and flashing the NVIDIA Jetson Orin NX, a powerful embedded AI computer ideal for advanced robotics and generative AI applications. The post covers preparation steps, including selecting the right SSD and downloading the necessary Ubuntu image. I provide a detailed walkthrough of the installation using NVIDIA&amp;rsquo;s SDK Manager, along with troubleshooting tips based on my experience. Whether you&amp;rsquo;re new to the Jetson Orin NX or looking to optimize your setup, this guide offers practical insights and step-by-step instructions to get you started.</description>
    </item>
    <item>
      <title>Setting Up Kafka with MicroK8s and Multipass</title>
      <link>https://seehiong.github.io/2024/setting-up-kafka-with-microk8s-and-multipass/</link>
      <pubDate>Sat, 03 Aug 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/setting-up-kafka-with-microk8s-and-multipass/</guid>
      <description>My homelab is a playground for experimenting with various tools and setups. However, for Proof of Concept (POC) environments, a lightweight and portable setup is often more suitable. In this post, I will guide you through setting up a MicroK8s environment in a virtual machine using Multipass. This POC demonstrates how Kafka can be set up in this environment.</description>
    </item>
    <item>
      <title>Building Your First Kubeflow Pipeline: A Step-by-Step Guide</title>
      <link>https://seehiong.github.io/2024/building-your-first-kubeflow-pipeline-a-step-by-step-guide/</link>
      <pubDate>Sat, 20 Jul 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/building-your-first-kubeflow-pipeline-a-step-by-step-guide/</guid>
      <description>In this blog post, I guide you through creating and running your first Kubeflow pipeline. We&amp;rsquo;ll start with the &amp;ldquo;Hello World&amp;rdquo; example, demonstrate how to manage sequential and shared pipelines, and explore artifact storage with MinIO. Additionally, I&amp;rsquo;ll introduce K9s, a powerful terminal-based UI for managing your Kubernetes clusters efficiently. By the end, you&amp;rsquo;ll have a solid understanding of setting up and managing Kubeflow pipelines in your machine learning workflows.</description>
    </item>
    <item>
      <title>Integrating Draw.io and PlantUML with GitLab</title>
      <link>https://seehiong.github.io/2024/integrating-draw-io-and-plantuml-with-gitlab/</link>
      <pubDate>Sat, 06 Jul 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/integrating-draw-io-and-plantuml-with-gitlab/</guid>
      <description>As we transition from Lucidchart to draw.io for team diagramming, this guide outlines the steps to integrate draw.io and PlantUML with GitLab. I&amp;rsquo;ll configure the Diagrams.net server, enable integration, and demonstrate creating and editing diagrams within GitLab. Additionally, I&amp;rsquo;ll cover the setup and integration of PlantUML for creating detailed design diagrams. Follow along to seamlessly incorporate these powerful diagramming tools into your GitLab workflow.</description>
    </item>
    <item>
      <title>Setting Up and Using KServe with Kubeflow</title>
      <link>https://seehiong.github.io/2024/setting-up-and-using-kserve-with-kubeflow/</link>
      <pubDate>Sun, 30 Jun 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/setting-up-and-using-kserve-with-kubeflow/</guid>
      <description>In this post, we explore KServe, a model inference platform on Kubernetes designed for scalability. Building on our previous Kubeflow guide, we detail how to set up your first KServe endpoint, make predictions, and troubleshoot common issues. Follow our step-by-step instructions to seamlessly integrate KServe with your Kubeflow environment and enhance your machine learning deployment process.</description>
    </item>
    <item>
      <title>Setting Up Kubeflow on Kubernetes: A Step-by-Step Guide</title>
      <link>https://seehiong.github.io/2024/setting-up-kubeflow-on-kubernetes-a-step-by-step-guide/</link>
      <pubDate>Mon, 24 Jun 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/setting-up-kubeflow-on-kubernetes-a-step-by-step-guide/</guid>
      <description>In this post, I provide a comprehensive guide to setting up Kubeflow, a machine learning toolkit for Kubernetes. From initial preparation and downloading necessary binaries to installing all Kubeflow components and troubleshooting common issues, this step-by-step tutorial ensures a smooth installation process. You&amp;rsquo;ll also learn how to create your first notebook and resolve potential errors, making it easier to leverage Kubeflow&amp;rsquo;s powerful features for your machine learning projects.</description>
    </item>
    <item>
      <title>Building Advanced RAG Applications with MyScaleDB and LlamaIndex</title>
      <link>https://seehiong.github.io/2024/building-advanced-rag-applications-with-myscaledb-and-llamaindex/</link>
      <pubDate>Sat, 15 Jun 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/building-advanced-rag-applications-with-myscaledb-and-llamaindex/</guid>
      <description>Explore how to build advanced Retrieval-Augmented Generation (RAG) applications using MyScaleDB and LlamaIndex. This guide covers the installation of necessary tools, setting up a virtual environment, and creating an index for document categorization. Learn how to execute simple and filtered queries, and troubleshoot common issues. Enhance your understanding of integrating high-performance SQL vector databases with cutting-edge data frameworks for efficient LLM applications.</description>
    </item>
    <item>
      <title>Planning Gift Deliveries With QGIS</title>
      <link>https://seehiong.github.io/2024/planning-gift-deliveries-with-qgis/</link>
      <pubDate>Sat, 08 Jun 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/planning-gift-deliveries-with-qgis/</guid>
      <description>In this post, I document my journey of using QGIS, a free and open-source geographic information system, to plan gift deliveries. I outline the steps to install QGIS, add essential plugins, create a shapefile layer for mapping locations, and use ORS Tools for route planning. After configuring the map, I determined that my delivery route would take 3 hours. This process, while tailored to my use case, is versatile and applicable to various fields such as logistics, urban planning, and environmental management. QGIS provides robust tools for efficient spatial analysis and mapping tasks.</description>
    </item>
    <item>
      <title>From Routing Models to MIP: Solving Capacitated Vehicle Routing Problem</title>
      <link>https://seehiong.github.io/2024/from-routing-models-to-mip-solving-capacitated-vehicle-routing-problem/</link>
      <pubDate>Sat, 01 Jun 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/from-routing-models-to-mip-solving-capacitated-vehicle-routing-problem/</guid>
      <description>In this post, we delve into solving the Capacitated Vehicle Routing Problem (CVRP) by transitioning from traditional routing models to the advanced Mixed Integer Programming (MIP) approach. We&amp;rsquo;ll start with the basics of creating a routing model using Google OR-Tools and then explore how to formulate and solve the CVRP using MIP for more optimized solutions. Whether you&amp;rsquo;re new to vehicle routing or looking to enhance your optimization techniques, this comprehensive guide provides the insights and code examples you need.</description>
    </item>
    <item>
      <title>Solving Facility Location Problem with OR-Tools and Micronaut</title>
      <link>https://seehiong.github.io/2024/solving-facility-location-problem-with-or-tools-and-micronaut/</link>
      <pubDate>Mon, 27 May 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/solving-facility-location-problem-with-or-tools-and-micronaut/</guid>
      <description>This post demonstrates solving the Facility Location Problem (FLP) using OR-Tools and Micronaut. It covers defining the solver, variables, constraints, and objective function in Java. The implementation includes creating a Micronaut service and controller to handle file uploads, process the data, and compute the optimal solution. The example input file format and expected outputs are also illustrated, providing a complete guide to implementing and testing the FLP solution.</description>
    </item>
    <item>
      <title>Optimizing TSP with Genetic Algorithms in Micronaut</title>
      <link>https://seehiong.github.io/2024/optimizing-tsp-with-genetic-algorithms-in-micronaut/</link>
      <pubDate>Thu, 23 May 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/optimizing-tsp-with-genetic-algorithms-in-micronaut/</guid>
      <description>In this post, I explore solving a Traveling Salesman Problem (TSP) involving 200 cities using genetic algorithms within a Micronaut framework. Leveraging techniques like inversion, insertion, and swap mutations, I illustrate how to maintain genetic diversity and improve solution quality over generations. The implementation showcases significant performance improvements compared to previous solvers. This approach combines simulated annealing, genetic algorithms, and local search to tackle complex optimization challenges effectively.</description>
    </item>
    <item>
      <title>Efficient TSP Solver API with Micronaut</title>
      <link>https://seehiong.github.io/2024/efficient-tsp-solver-api-with-micronaut/</link>
      <pubDate>Sat, 27 Apr 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/efficient-tsp-solver-api-with-micronaut/</guid>
      <description>Solve the Travelling Salesman Problem using Choco-solver and convert it into a powerful API with Micronaut. Explore the efficient solution and its integration for optimal city tours.</description>
    </item>
    <item>
      <title>Log Management with Graylog</title>
      <link>https://seehiong.github.io/2024/log-management-with-graylog/</link>
      <pubDate>Fri, 19 Apr 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/log-management-with-graylog/</guid>
      <description>Explore setting up Graylog in your HomeLab for comprehensive log management. Configure MongoDB and OpenSearch, deploy Fluent Bit for log forwarding, and implement advanced features like Grok patterns and pipelines. Troubleshoot efficiently with tools like netshoot and tcpdump. Enhance your HomeLab environment with a scalable and efficient log management solution.</description>
    </item>
    <item>
      <title>Coding with CrewAI: AI Orchestration Simplified</title>
      <link>https://seehiong.github.io/2024/coding-with-crewai-ai-orchestration-simplified/</link>
      <pubDate>Fri, 29 Mar 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/coding-with-crewai-ai-orchestration-simplified/</guid>
      <description>Explore CrewAI, a pioneering framework streamlining AI agent orchestration. Discover practical applications, from Jan and LM Studio integration to Serper API utilization. Follow along as we delve into coding with CrewAI, showcasing its versatility in crafting resumes and more. Experience the seamless synergy of autonomous AI agents, revolutionizing workflows with efficiency and innovation. Unlock the power of CrewAI, propelling your projects to new heights in artificial intelligence.</description>
    </item>
    <item>
      <title>AutoPilot Setup for VS Code</title>
      <link>https://seehiong.github.io/2024/autopilot-setup-for-vs-code/</link>
      <pubDate>Sat, 16 Mar 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/autopilot-setup-for-vs-code/</guid>
      <description>Discover the quick setup of AutoPilot for VS Code, enabling seamless code completion with LM Studio and OpenAI-compatible models. Learn the configuration steps and see them in action, empowering your coding experience.</description>
    </item>
    <item>
      <title>Configuring Appwrite Functions with K3s</title>
      <link>https://seehiong.github.io/2024/configuring-appwrite-functions-with-k3s/</link>
      <pubDate>Sun, 10 Mar 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/configuring-appwrite-functions-with-k3s/</guid>
      <description>This guide outlines configuring Appwrite Functions within a K3s environment. It covers essential steps, including installing ngrok for external network access, registering a GitHub App, and setting up Appwrite with required configurations. The process involves updating YAML files for deployment, ensuring proper routing with Traefik, and creating functions through the Appwrite interface. Once set up, the functions are deployed successfully, enabling seamless integration and execution within the K3s infrastructure.</description>
    </item>
    <item>
      <title>Deploying Budibase in HomeLab</title>
      <link>https://seehiong.github.io/2024/deploying-budibase-in-homelab/</link>
      <pubDate>Sun, 25 Feb 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/deploying-budibase-in-homelab/</guid>
      <description>This post outlines the process of installing Budibase in a HomeLab environment, starting with testing it on Docker Desktop and then deploying it using Helm in Kubernetes. It guides through setting up an admin user, building the first app by creating a database, designing an application form, and configuring submission actions. The summary encapsulates the steps involved in testing, deploying, and building an application with Budibase, highlighting key actions such as Docker Compose setup, Helm installation, app creation, and deployment in a concise manner.</description>
    </item>
    <item>
      <title>Deploying Appwrite in HomeLab with K3s</title>
      <link>https://seehiong.github.io/2024/deploying-appwrite-in-homelab-with-k3s/</link>
      <pubDate>Fri, 16 Feb 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/deploying-appwrite-in-homelab-with-k3s/</guid>
      <description>Learn how to seamlessly integrate Appwrite, an open-source platform, into your HomeLab setup using K3s. Follow step-by-step instructions to deploy K3s with Portainer, prepare Appwrite volumes, and configure miscellaneous services like MariaDB and InfluxDB. Utilize Kompose to convert Docker Compose files to Kubernetes for efficient deployment. Ensure smooth installation by mapping necessary environment variables and applying all required deployments and services. Finally, witness the successful deployment of Appwrite services and access the login page to start building scalable applications. Master the art of HomeLab application deployment with Appwrite and K3s.</description>
    </item>
    <item>
      <title>Text-to-Image with StableDiffusionPipeline</title>
      <link>https://seehiong.github.io/2024/text-to-image-with-stablediffusionpipeline/</link>
      <pubDate>Sat, 10 Feb 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/text-to-image-with-stablediffusionpipeline/</guid>
      <description>In this post, we explore the capabilities of StableDiffusionPipeline for generating photorealistic images from textual inputs. We start with setting up the environment and installing necessary libraries. Then, we dive into Textual Inversion, demonstrating how the model learns new concepts from images. Image-to-Image transformations are also explored, showcasing the pipeline&amp;rsquo;s versatility. Additionally, we introduce Animagine XL 2.0, a model for high-resolution anime image creation, and provide sample code for its implementation. Lastly, we highlight Stable Diffusion XL, a powerful text-to-image model, and share a festive image generated using it.</description>
    </item>
    <item>
      <title>Stable Diffusion: Text-to-Image Modeling Journey</title>
      <link>https://seehiong.github.io/2024/stable-diffusion-text-to-image-modeling-journey/</link>
      <pubDate>Sat, 03 Feb 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/stable-diffusion-text-to-image-modeling-journey/</guid>
      <description>This post explores Stable Diffusion, a latent text-to-image diffusion model in machine learning. Diffusion models, with forward, reverse, and sampling components, understand and generate patterns in datasets. Illustrating applications in image tasks, it introduces the process of installing and utilizing Stable Diffusion. The post details image generation and modification using prompts, with examples and troubleshooting. Notably, it shares an encounter with CUDA out-of-memory errors and the resolution through image resizing. Overall, it offers a comprehensive guide, combining theoretical insights with practical implementation steps in a professional manner.</description>
    </item>
    <item>
      <title>OpenVINO, Optimum-Intel, CPU: An Exploration in Model Optimization</title>
      <link>https://seehiong.github.io/2024/openvino-optimum-intel-cpu-an-exploration-in-model-optimization/</link>
      <pubDate>Sat, 27 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/openvino-optimum-intel-cpu-an-exploration-in-model-optimization/</guid>
      <description>Explore the convergence of OpenVINO and Optimum-Intel in this post, where I detail the setup and execution of example code on my aging laptop. Focused on applying Quantization-aware Training and the Token Merging method to optimize the UNet model within the Stable Diffusion pipeline, this journey showcases the synergy of open-source tools for deep learning model deployment. Note that the provided code is tailored for CPU-based inference due to limitations in my aging GeForce graphics card, making it a valuable resource for users with similar hardware constraints. Dive into the world of optimized models and delightful Pokemon creation!</description>
    </item>
    <item>
      <title>Java Integration with Jupyter Notebooks</title>
      <link>https://seehiong.github.io/2024/java-integration-with-jupyter-notebooks/</link>
      <pubDate>Sun, 21 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/java-integration-with-jupyter-notebooks/</guid>
      <description>Embark on a seamless integration of Java into Jupyter notebooks with this comprehensive guide. Beginning with the selection of a relevant Jupyter Docker Stack, the post details setup steps and deployment in HomeLab, showcasing application results for verification. The integration of Java Kernel through JBang and testing with &amp;ldquo;Hello World&amp;rdquo; and Apache Commons library exemplifies the versatility. Further exploration involves experimenting with Java in a Python kernel using JBang. Concluding with a call to joyful coding, this journey promises a harmonious blend of Java&amp;rsquo;s robustness and Jupyter&amp;rsquo;s interactive nature. Discover the joy of coding in this enriched Java-in-Jupyter experience. Happy coding!</description>
    </item>
    <item>
      <title>Exploring Autogen Studio</title>
      <link>https://seehiong.github.io/2024/exploring-autogen-studio/</link>
      <pubDate>Sun, 14 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/exploring-autogen-studio/</guid>
      <description>In this exploration of Autogen Studio, we navigated through the AI landscape, harnessing the LM Studio API to compare responses from diverse language models. Employing the Mistral Instruct 7B model, we scrutinized prompts like Stock Price and Paint, visualizing outcomes and delving into key configurations. The post also offered insights into the primary assistant, model configuration, and agent workflows, accompanied by a comparative analysis of Mistral model responses. This comprehensive journey demystifies the power of Autogen Studio and its seamless integration with LM Studio API, providing practical guidance for AI enthusiasts.</description>
    </item>
    <item>
      <title>Deploying LLMs with WasmEdge in HomeLab</title>
      <link>https://seehiong.github.io/2024/deploying-llms-with-wasmedge-in-homelab/</link>
      <pubDate>Sat, 13 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/deploying-llms-with-wasmedge-in-homelab/</guid>
      <description>In this post, we explored deploying Lightweight Language Models (LLMs) using WasmEdge, a high-performance WebAssembly runtime, within a HomeLab environment. The process involved preparing an OpenAI-compatible API server, configuring the Wasi-NN plugin, and deploying the setup to HomeLab using Kubernetes (K3s). The post also detailed the steps for testing the API server and integrating it into a Java application. Overall, the guide provides a comprehensive walkthrough of hosting and utilizing LLMs with WasmEdge in a local environment.</description>
    </item>
    <item>
      <title>Integrating NFS for Improved Scalability</title>
      <link>https://seehiong.github.io/2024/integrating-nfs-for-improved-scalability/</link>
      <pubDate>Sun, 07 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/integrating-nfs-for-improved-scalability/</guid>
      <description>In this post, we explored the integration of NFS to enhance scalability in deploying LLM models within a home lab. Setting up NFS involved connecting to a TerraMaster NAS, and the K3s cluster was configured to dynamically provision storage. With NFS in place, the deployment process became more efficient, eliminating the need to rebuild images for each new model introduction. The post detailed the setup steps, from configuring NFS and K3s to deploying LLM models dynamically. This approach simplifies the scaling of Language Models, providing a centralized and scalable storage solution through NFS in a Kubernetes environment.</description>
    </item>
    <item>
      <title>Integration of Kong into AI Workflow</title>
      <link>https://seehiong.github.io/2024/integration-of-kong-into-ai-workflow/</link>
      <pubDate>Sat, 06 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/integration-of-kong-into-ai-workflow/</guid>
      <description>This comprehensive guide navigates through configuring Kong OSS and Kong Ingress Controller (KIC), seamlessly integrating Kong into an AI workflow. Starting with Kong OSS configuration, the tutorial covers updating environment variables and service ports. The Langchain4j application is then adapted to leverage Kong API, allowing for flexible path-based APIs. Additionally, potential timeout issues are addressed. The guide concludes with a demonstration of Kong Ingress Controller configuration, emphasizing optimal settings for specific use cases. Whether through Kong OSS or KIC, readers gain insights into enhancing API management and integration within their AI workflows.</description>
    </item>
    <item>
      <title>Exploring Kong Ingress Controller (KIC)</title>
      <link>https://seehiong.github.io/2024/exploring-kong-ingress-controller-kic/</link>
      <pubDate>Mon, 01 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/exploring-kong-ingress-controller-kic/</guid>
      <description>Embark on a journey into the new year by exploring Kong Ingress Controller (KIC) in your home lab. This guide, transitioning from a previous discussion on Kong Gateway, details the seamless setup of KIC using Helm and K3s. From initial preparations to installing Kong Ingress Controller and Gateway, witness the efficient management of APIs in your home lab environment. Learn to add Kong Ingresses, ensuring optimal routing for various paths. Through concise steps and illustrative visuals, this post simplifies the process, allowing you to experience KIC&amp;rsquo;s capabilities firsthand. Dive into the year with a hands-on exploration of API management with Kong in your home lab. Happy New Year!</description>
    </item>
  </channel>
</rss>
