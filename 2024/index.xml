<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>2024 on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/2024/</link>
    <description>Recent content in 2024 on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 06 Oct 2024 20:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/2024/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Controlling RoArm-M2-S with ROS2</title>
      <link>https://seehiong.github.io/2024/controlling-roarm-m2-s-with-ros2/</link>
      <pubDate>Sun, 06 Oct 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/controlling-roarm-m2-s-with-ros2/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://seehiong.github.io/images/roarm/roarm-m2-s-ros2.jpeg&#34; alt=&#34;roarm-m2-s-ros2&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;In this post, I explore the RoArm-M2-S with the &lt;a href=&#34;https://seehiong.github.io/2024/wave-rover-with-raspberry-pi-4/&#34; target=&#34;_blank&#34;&gt;Wave Rover&lt;/a&gt;. Due to the small base, there&amp;rsquo;s a tendency for instability, so I plan to upgrade to a &lt;a href=&#34;https://www.waveshare.com/ugv-rover.htm&#34; target=&#34;_blank&#34;&gt;UGV Rover&lt;/a&gt;. Meanwhile, let&amp;rsquo;s focus on setting up the RoArm.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;&#xA;&lt;p&gt;Following the official &lt;a href=&#34;https://www.waveshare.com/wiki/RoArm-M2-S_ROS2_Getting_Started_Tutorial&#34; target=&#34;_blank&#34;&gt;Getting Started Tutorial&lt;/a&gt;, we begin by installing Oracle VirtualBox.&lt;/p&gt;&#xA;&lt;h3 id=&#34;installing-oracle-virtualbox&#34;&gt;Installing Oracle VirtualBox&lt;/h3&gt;&#xA;&lt;p&gt;Download the &lt;a href=&#34;https://www.virtualbox.org/wiki/Downloads&#34; target=&#34;_blank&#34;&gt;VirtualBox Platform Packages&lt;/a&gt; and its Extension Pack. Install both, then proceed to create a new Virtual Machine (VM) named &lt;em&gt;RoArm&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Wave Rover with Raspberry Pi 4</title>
      <link>https://seehiong.github.io/2024/wave-rover-with-raspberry-pi-4/</link>
      <pubDate>Sat, 28 Sep 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/wave-rover-with-raspberry-pi-4/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://seehiong.github.io/images/rover2/wave-rover-with-raspberry-pi-4.jpeg&#34; alt=&#34;wave-rover-with-raspberry-pi-4&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Continuing my previous journey with the &lt;a href=&#34;https://seehiong.github.io/2024/wave-rover-setup-guide-and-troubleshooting-tips/&#34; target=&#34;_blank&#34;&gt;Wave Rover&lt;/a&gt;, this post documents how I used a Raspberry Pi 4 as the main controller for the project.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;Using the &lt;a href=&#34;https://github.com/raspberrypi/rpi-imager/releases&#34; target=&#34;_blank&#34;&gt;Raspberry Pi Imager&lt;/a&gt;, I installed the 64-bit Raspberry Pi OS on a 64GB microSD card. I customized the installation by setting the hostname, username, password, and configuring the wireless LAN.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://seehiong.github.io/images/rover2/raspberry-pi-imager.png&#34; alt=&#34;raspberry-pi-imager&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Wave Rover: Setup Guide and Troubleshooting Tips</title>
      <link>https://seehiong.github.io/2024/wave-rover-setup-guide-and-troubleshooting-tips/</link>
      <pubDate>Sat, 21 Sep 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/wave-rover-setup-guide-and-troubleshooting-tips/</guid>
      <description>&lt;p&gt;After a long wait, my &lt;a href=&#34;https://www.waveshare.com/wiki/WAVE_ROVER&#34; target=&#34;_blank&#34;&gt;Wave Rover&lt;/a&gt;, a robust 4WD full-metal body mobile robot chassis, and the &lt;a href=&#34;https://www.waveshare.com/wiki/RoArm-M2-S&#34; target=&#34;_blank&#34;&gt;RoArm-M2-S&lt;/a&gt;, a 4DOF smart robotic arm designed for innovative applications, have finally arrived. Along with these, I received three 18650 lithium batteries (which are not included in the base package) for powering the setup.&lt;/p&gt;&#xA;&lt;h2 id=&#34;initial-preparation&#34;&gt;Initial Preparation&lt;/h2&gt;&#xA;&lt;p&gt;To begin, I carefully opened the Wave Rover chassis by loosening the four screws on the bottom with an allen key, ensuring not to pull any wires accidentally.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Talos Linux: Setting Up a Secure, Immutable Kubernetes Cluster</title>
      <link>https://seehiong.github.io/2024/talos-linux-setting-up-a-secure-immutable-kubernetes-cluster/</link>
      <pubDate>Sun, 01 Sep 2024 08:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/talos-linux-setting-up-a-secure-immutable-kubernetes-cluster/</guid>
      <description>&lt;p&gt;In this post, I will walk you through the process of setting up a Kubernetes cluster using &lt;a href=&#34;https://www.talos.dev/&#34; target=&#34;_blank&#34;&gt;Talos Linux&lt;/a&gt;, an operating system specifically designed for Kubernetes that is secure, immutable, and minimal by design. Talos Linux is distinguished by its unique architecture: it is hardened by default, has no shell (bash), no SSH access, and no systemd. Instead, all management is conducted through an API.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;After downloading the &lt;a href=&#34;https://www.talos.dev/v1.7/talos-guides/install/bare-metal-platforms/iso/&#34; target=&#34;_blank&#34;&gt;ISO&lt;/a&gt; image, I used &lt;a href=&#34;https://etcher.balena.io/&#34; target=&#34;_blank&#34;&gt;balenaEtcher&lt;/a&gt; to create a bootable USB installation media. My setup consists of one control plane node and two worker nodes. The following IP addresses were assigned:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Audio Generation with NVIDIA Jetson Orin NX</title>
      <link>https://seehiong.github.io/2024/audio-generation-with-nvidia-jetson-orin-nx/</link>
      <pubDate>Sun, 25 Aug 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/audio-generation-with-nvidia-jetson-orin-nx/</guid>
      <description>&lt;p&gt;Building on my exploration of &lt;a href=&#34;https://seehiong.github.io/2024/unleashing-text-generation-with-nvidia-jetson-orin-nx/&#34; target=&#34;_blank&#34;&gt;text generation with NVIDIA Jetson Orin NX&lt;/a&gt;, this post delves into the audio generation capabilities of the Jetson platform.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;transcribing-audio-with-whisper&#34;&gt;Transcribing Audio with Whisper&lt;/h2&gt;&#xA;&lt;p&gt;Following the &lt;a href=&#34;https://www.jetson-ai-lab.com/tutorial_whisper.html&#34; target=&#34;_blank&#34;&gt;Tutorial Whisper&lt;/a&gt;, after starting the container with the command below, you can access Jupyter Lab at https://192.168.68.100:8888 (password: &lt;em&gt;nvidia&lt;/em&gt;):&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;jetson-containers run &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;autotag whisper&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Unleashing Text Generation with NVIDIA Jetson Orin NX</title>
      <link>https://seehiong.github.io/2024/unleashing-text-generation-with-nvidia-jetson-orin-nx/</link>
      <pubDate>Sat, 17 Aug 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/unleashing-text-generation-with-nvidia-jetson-orin-nx/</guid>
      <description>&lt;p&gt;Navigating through the &lt;a href=&#34;https://www.jetson-ai-lab.com/&#34; target=&#34;_blank&#34;&gt;NVIDIA Jetson AI Lab&lt;/a&gt; has been an exhilarating experience, showcasing the potential of generative AI powered by NVIDIA® Jetson™. With a plethora of labs to explore, it’s challenging to cover everything in a limited time. In this post, I&amp;rsquo;ll focus on labs related to text generation.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;If you follow my &lt;a href=&#34;https://seehiong.github.io/2024/exploring-nvidia-jetson-orin-nx-flashing-and-setup-guide/&#34; target=&#34;_blank&#34;&gt;Jetson Orin NX flashing guide&lt;/a&gt;, you might have noticed that a browser is not pre-installed. I recommend installing  &lt;a href=&#34;https://brave.com/&#34; target=&#34;_blank&#34;&gt;Brave&lt;/a&gt;, a browser that blocks ads and conserves data. To install it, simply run:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scaling Kafka Workloads with KEDA in Kubernetes</title>
      <link>https://seehiong.github.io/2024/scaling-kafka-workloads-with-keda-in-kubernetes/</link>
      <pubDate>Sat, 10 Aug 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/scaling-kafka-workloads-with-keda-in-kubernetes/</guid>
      <description>&lt;p&gt;Building up my previous &lt;a href=&#34;https://seehiong.github.io/2024/setting-up-kafka-with-microk8s-and-multipass/&#34; target=&#34;_blank&#34;&gt;Kafka post&lt;/a&gt;, this article focuses on leveraging KEDA to scale Kafka consumer workloads dynamically. &lt;a href=&#34;https://keda.sh/&#34; target=&#34;_blank&#34;&gt;KEDA&lt;/a&gt; is a Kubernetes-based Event Driven Autoscaler that enables automatic scaling of pods based on the volume of events to be processed.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;keda-setup&#34;&gt;KEDA Setup&lt;/h2&gt;&#xA;&lt;p&gt;To begin, after accessing the &lt;em&gt;mk8s-vm&lt;/em&gt;, simply install KEDA with the following commands:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo microk8s enable community&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo microk8s enable keda&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Disable KEDA if necessary&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo microk8s disable keda&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Exploring NVIDIA Jetson Orin NX: Flashing and Setup Guide</title>
      <link>https://seehiong.github.io/2024/exploring-nvidia-jetson-orin-nx-flashing-and-setup-guide/</link>
      <pubDate>Fri, 09 Aug 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/exploring-nvidia-jetson-orin-nx-flashing-and-setup-guide/</guid>
      <description>&lt;p&gt;On this special &lt;a href=&#34;https://www.visitsingapore.com/whats-happening/all-happenings/festivals/singapore-national-day/&#34; target=&#34;_blank&#34;&gt;Singapore National Day&lt;/a&gt;, I am delighted to extend my best wishes as we celebrate Singapore&amp;rsquo;s 59th birthday. Today, I&amp;rsquo;m particularly excited to share that I’ve finally received the long-awaited &lt;a href=&#34;https://files.seeedstudio.com/wiki/reComputer/reComputer-J40.pdf&#34; target=&#34;_blank&#34;&gt;NVIDIA® Jetson Orin™ NX&lt;/a&gt; board. I’ll be documenting the flashing process for this powerful device. &lt;a href=&#34;https://www.nvidia.com/en-sg/autonomous-machines/embedded-systems/jetson-orin/&#34; target=&#34;_blank&#34;&gt;NVIDIA Jetson Orin&lt;/a&gt; is a game-changer, bringing next-generation products to life with the world’s most advanced embedded AI computers, perfect for generative AI, computer vision, and cutting-edge robotics.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Setting Up Kafka with MicroK8s and Multipass</title>
      <link>https://seehiong.github.io/2024/setting-up-kafka-with-microk8s-and-multipass/</link>
      <pubDate>Sat, 03 Aug 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/setting-up-kafka-with-microk8s-and-multipass/</guid>
      <description>&lt;p&gt;My homelab is a playground for experimenting with various tools and setups. However, for Proof of Concept (POC) environments, a lightweight and portable setup is often more suitable. In this post, I will guide you through setting up a MicroK8s environment in a virtual machine using Multipass. This POC demonstrates how Kafka can be set up in this environment. &lt;a href=&#34;https://multipass.run/&#34; target=&#34;_blank&#34;&gt;Multipass&lt;/a&gt; is a CLI tool for launching and managing VMs on Windows, Mac, and Linux, simulating a cloud environment with support for cloud-init.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building Your First Kubeflow Pipeline: A Step-by-Step Guide</title>
      <link>https://seehiong.github.io/2024/building-your-first-kubeflow-pipeline-a-step-by-step-guide/</link>
      <pubDate>Sat, 20 Jul 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/building-your-first-kubeflow-pipeline-a-step-by-step-guide/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.kubeflow.org/docs/components/pipelines/overview/&#34; target=&#34;_blank&#34;&gt;Kubeflow Pipelines (KFP)&lt;/a&gt; is a powerful platform for creating and deploying scalable machine learning (ML) workflows using Docker containers. It enables data scientists and ML engineers to author workflows in Python, manage and visualize pipeline runs, and efficiently utilize compute resources. KFP supports custom ML components, leverages existing ones, and ensures cross-platform portability with a platform-neutral &lt;a href=&#34;https://www.kubeflow.org/docs/components/pipelines/user-guides/core-functions/compile-a-pipeline/#ir-yaml&#34; target=&#34;_blank&#34;&gt;IR YAML definition&lt;/a&gt;. In this post, I’ll share my learnings about KFP v2.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Integrating Draw.io and PlantUML with GitLab</title>
      <link>https://seehiong.github.io/2024/integrating-draw-io-and-plantuml-with-gitlab/</link>
      <pubDate>Sat, 06 Jul 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/integrating-draw-io-and-plantuml-with-gitlab/</guid>
      <description>&lt;p&gt;As we are migrating away from &lt;a href=&#34;https://www.lucidchart.com/&#34; target=&#34;_blank&#34;&gt;Lucidchart&lt;/a&gt; to &lt;a href=&#34;https://www.drawio.com/&#34; target=&#34;_blank&#34;&gt;draw.io&lt;/a&gt;, a security-first diagramming for teams, I will be documenting the steps to integrate draw.io with GitLab.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;configure-diagramsnet-server&#34;&gt;Configure Diagrams.net Server&lt;/h2&gt;&#xA;&lt;p&gt;Referencing the official &lt;a href=&#34;https://docs.gitlab.com/ee/administration/integration/diagrams_net.html&#34; target=&#34;_blank&#34;&gt;Diagrams.net&lt;/a&gt; documentation, I run the diagrams.net container in Docker, using the following command:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker run --rm --name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;draw&amp;#34;&lt;/span&gt; -p 8888:8080 -p 8443:8443 jgraph/drawio&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Setting Up and Using KServe with Kubeflow</title>
      <link>https://seehiong.github.io/2024/setting-up-and-using-kserve-with-kubeflow/</link>
      <pubDate>Sun, 30 Jun 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/setting-up-and-using-kserve-with-kubeflow/</guid>
      <description>&lt;p&gt;Expanding on my previous post on &lt;a href=&#34;https://seehiong.github.io/2024/setting-up-kubeflow-on-kubernetes-a-step-by-step-guide/&#34; target=&#34;_blank&#34;&gt;Kubeflow&lt;/a&gt;, I will explore &lt;a href=&#34;https://kserve.github.io/website/latest/&#34; target=&#34;_blank&#34;&gt;KServe&lt;/a&gt;, a standard Model Inference Platform on Kubernetes built for highly scalable use cases.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;first-kserve-endpoint&#34;&gt;First KServe Endpoint&lt;/h2&gt;&#xA;&lt;p&gt;Referencing &lt;a href=&#34;https://github.com/kserve/kserve/blob/master/docs/samples/istio-dex/README.md&#34; target=&#34;_blank&#34;&gt;KServe on Kubeflow with Istio-Dex&lt;/a&gt;, below is the &lt;em&gt;sklearn.yaml&lt;/em&gt; configuration. Note the sidecar annotation, which instructs not to inject the istio sidecar. Without this annotation, you may encounter error (refer to the troubleshooting section):&lt;/p&gt;</description>
    </item>
    <item>
      <title>Setting Up Kubeflow on Kubernetes: A Step-by-Step Guide</title>
      <link>https://seehiong.github.io/2024/setting-up-kubeflow-on-kubernetes-a-step-by-step-guide/</link>
      <pubDate>Mon, 24 Jun 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/setting-up-kubeflow-on-kubernetes-a-step-by-step-guide/</guid>
      <description>&lt;p&gt;The car inspection went well, and I will spend the rest of my half-day leave documenting the steps for setting up &lt;a href=&#34;https://www.kubeflow.org/&#34; target=&#34;_blank&#34;&gt;Kubeflow&lt;/a&gt;, the machine learning toolkit for kubernetes.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://kustomize.io/&#34; target=&#34;_blank&#34;&gt;Kustomize&lt;/a&gt; introduces a template-free way to customize application configuration, simplifying the use of off-the-shelf application. The simplest way to get started is to download the precompiled binaries:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -s &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh&amp;#34;&lt;/span&gt;  | bash&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Moves kustomize to a system-wide location&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo mv kustomize /usr/local/bin/&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Building Advanced RAG Applications with MyScaleDB and LlamaIndex</title>
      <link>https://seehiong.github.io/2024/building-advanced-rag-applications-with-myscaledb-and-llamaindex/</link>
      <pubDate>Sat, 15 Jun 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/building-advanced-rag-applications-with-myscaledb-and-llamaindex/</guid>
      <description>&lt;p&gt;In this post, I will explore &lt;a href=&#34;https://github.com/myscale/myscaledb&#34; target=&#34;_blank&#34;&gt;MyScaleDB&lt;/a&gt;, an open-source, high-performance SQL vector database built on ClickHouse, and &lt;a href=&#34;https://www.llamaindex.ai/&#34; target=&#34;_blank&#34;&gt;LlamaIndex&lt;/a&gt;, the leading data framework for building LLM applications.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;&#xA;&lt;p&gt;After installing &lt;a href=&#34;https://vscodium.com/#install&#34; target=&#34;_blank&#34;&gt;VSCodium&lt;/a&gt; as my primary IDE, I proceeded with installing the Python extension via &lt;a href=&#34;https://open-vsx.org/vscode/item?itemName=ms-python.python&#34; target=&#34;_blank&#34;&gt;Marketplace Link&lt;/a&gt;.&#xA;Next, I created the &lt;a href=&#34;https://docs.python.org/3/library/venv.html&#34; target=&#34;_blank&#34;&gt;virtual environment&lt;/a&gt; using venv:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create the envrionment&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python -m venv myscaledb&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Activate the environment&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;myscaledb&lt;span style=&#34;color:#ae81ff&#34;&gt;\S&lt;/span&gt;cripts&lt;span style=&#34;color:#ae81ff&#34;&gt;\a&lt;/span&gt;ctivate&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Planning Gift Deliveries With QGIS</title>
      <link>https://seehiong.github.io/2024/planning-gift-deliveries-with-qgis/</link>
      <pubDate>Sat, 08 Jun 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/planning-gift-deliveries-with-qgis/</guid>
      <description>&lt;p&gt;In this post, I will document my journey into learning &lt;a href=&#34;https://qgis.org/en/site/&#34; target=&#34;_blank&#34;&gt;QGIS&lt;/a&gt;, a free and open-source geographic information system, with the goal of visualizing and calculating the total time required for me to deliver gifts to friends and relatives during special occasions.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;After installing QGIS 3.36 desktop version on my Windows PC, I proceeded to the &lt;a href=&#34;https://docs.qgis.org/3.34/en/docs/training_manual/index.html&#34; target=&#34;_blank&#34;&gt;QGIS Training Manual&lt;/a&gt;, to familiarize myself with the software.&lt;/p&gt;</description>
    </item>
    <item>
      <title>From Routing Models to MIP: Solving Capacitated Vehicle Routing Problem</title>
      <link>https://seehiong.github.io/2024/from-routing-models-to-mip-solving-capacitated-vehicle-routing-problem/</link>
      <pubDate>Sat, 01 Jun 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/from-routing-models-to-mip-solving-capacitated-vehicle-routing-problem/</guid>
      <description>&lt;h2 id=&#34;problem-statement&#34;&gt;Problem Statement&lt;/h2&gt;&#xA;&lt;p&gt;In this post, I will follow the &lt;a href=&#34;https://developers.google.com/optimization/routing/vrp&#34; target=&#34;_blank&#34;&gt;Vehicle Routing Problem&lt;/a&gt; (VRP) with a focus on the capacitated vehicle routing problem (CVRP) and utilizing an alternative Mixed Integer Programming (MIP) approach.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;routing-model&#34;&gt;Routing Model&lt;/h2&gt;&#xA;&lt;p&gt;The main section of the program creates the index manager and the routing model.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Create Routing Index Manager&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;RoutingIndexManager manager &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; RoutingIndexManager(data.&lt;span style=&#34;color:#a6e22e&#34;&gt;distanceMatrix&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;length&lt;/span&gt;, data.&lt;span style=&#34;color:#a6e22e&#34;&gt;vehicleNumber&lt;/span&gt;, data.&lt;span style=&#34;color:#a6e22e&#34;&gt;depot&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// Create Routing Model&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;RoutingModel routing &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; RoutingModel(manager);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Solving Facility Location Problem with OR-Tools and Micronaut</title>
      <link>https://seehiong.github.io/2024/solving-facility-location-problem-with-or-tools-and-micronaut/</link>
      <pubDate>Mon, 27 May 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/solving-facility-location-problem-with-or-tools-and-micronaut/</guid>
      <description>&lt;h2 id=&#34;problem-statement&#34;&gt;Problem Statement&lt;/h2&gt;&#xA;&lt;p&gt;In this post, I&amp;rsquo;ll tackle the &lt;a href=&#34;https://en.wikipedia.org/wiki/Facility_location_problem&#34; target=&#34;_blank&#34;&gt;Facility Location Problem&lt;/a&gt;, which involves deciding the optimal placement of facilities to minimize costs. Unlike my previous post on using a &lt;a href=&#34;https://seehiong.github.io/2024/optimizing-tsp-with-genetic-algorithms-in-micronaut/&#34; target=&#34;_blank&#34;&gt;genetic algorithm for the TSP&lt;/a&gt;, I&amp;rsquo;ll utilize &lt;a href=&#34;https://developers.google.com/optimization/&#34; target=&#34;_blank&#34;&gt;OR-Tools&lt;/a&gt; to solve this problem.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;defining-the-solver&#34;&gt;Defining the solver&lt;/h2&gt;&#xA;&lt;p&gt;Referencing the &lt;a href=&#34;https://developers.google.com/optimization/mip/mip_example&#34; target=&#34;_blank&#34;&gt;MIP example&lt;/a&gt;,  I&amp;rsquo;ll solve the FLP using the MIP approach. Let&amp;rsquo;s place all solver codes in &lt;strong&gt;FLPService.java&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optimizing TSP with Genetic Algorithms in Micronaut</title>
      <link>https://seehiong.github.io/2024/optimizing-tsp-with-genetic-algorithms-in-micronaut/</link>
      <pubDate>Thu, 23 May 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/optimizing-tsp-with-genetic-algorithms-in-micronaut/</guid>
      <description>&lt;h2 id=&#34;problem-statement&#34;&gt;Problem Statement&lt;/h2&gt;&#xA;&lt;p&gt;Research suggests that the  &lt;a href=&#34;https://www.math.uwaterloo.ca/tsp/pla85900/index.html&#34; target=&#34;_blank&#34;&gt;Optimal 85,900-Point Tour&lt;/a&gt; is the largest solved instance of the Traveling Salesman Problem (TSP). For this post, I will attempt to solve the TSP problem involving 200 cities.&lt;/p&gt;&#xA;&lt;p&gt;Genetic algorithms simulate the process of natural selection, mimicking &amp;ldquo;survival of the fittest&amp;rdquo; to solve problems. These algorithms evolve over generations, with each generation comprising individuals better adapted to solving the problem.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Efficient TSP Solver API with Micronaut</title>
      <link>https://seehiong.github.io/2024/efficient-tsp-solver-api-with-micronaut/</link>
      <pubDate>Sat, 27 Apr 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/efficient-tsp-solver-api-with-micronaut/</guid>
      <description>&lt;h2 id=&#34;problem-statement&#34;&gt;Problem Statement&lt;/h2&gt;&#xA;&lt;p&gt;I&amp;rsquo;m embarking on a journey to solve the &lt;a href=&#34;https://en.wikipedia.org/wiki/Travelling_salesman_problem&#34; target=&#34;_blank&#34;&gt;Travelling Salesman Problem (TSP)&lt;/a&gt; utilizing &lt;a href=&#34;https://choco-solver.org/&#34; target=&#34;_blank&#34;&gt;Choco-solver&lt;/a&gt;, an effective Java library for constraint programming. Additionally, I&amp;rsquo;ll be converting this solution into an API using &lt;a href=&#34;https://micronaut.io/&#34; target=&#34;_blank&#34;&gt;Micronaut&lt;/a&gt;, a cutting-edge, JVM-based framework for building modular, testable microservices and serverless applications.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setting-up-with-micronaut&#34;&gt;Setting up with Micronaut&lt;/h2&gt;&#xA;&lt;p&gt;Following the &lt;a href=&#34;https://guides.micronaut.io/latest/creating-your-first-micronaut-app-gradle-java.html&#34; target=&#34;_blank&#34;&gt;official Micronaut guide&lt;/a&gt;, I downloaded the source and proceeded with the setup.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Log Management with Graylog</title>
      <link>https://seehiong.github.io/2024/log-management-with-graylog/</link>
      <pubDate>Fri, 19 Apr 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/log-management-with-graylog/</guid>
      <description>&lt;p&gt;In this blog post, I&amp;rsquo;ll guide you through the setup of &lt;a href=&#34;https://graylog.org/&#34; target=&#34;_blank&#34;&gt;Graylog&lt;/a&gt;, an open-source log management platform, within a HomeLab environment, providing a comprehensive solution for log analysis and monitoring.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setting-up-graylog-with-docker&#34;&gt;Setting up Graylog with Docker&lt;/h2&gt;&#xA;&lt;p&gt;To initiate our exploration of Graylog, we&amp;rsquo;ll opt for a &lt;a href=&#34;https://go2docs.graylog.org/5-2/downloading_and_installing_graylog/docker_installation.htm&#34; target=&#34;_blank&#34;&gt;Docker Installation&lt;/a&gt;, which ensures simplicity and ease of deployment. Follow the steps outlined in the official documentation to set up Graylog via Docker. Upon successful installation, access the Graylog interface by navigating to &lt;em&gt;http://localhost:9000/&lt;/em&gt;, and use the default credentials: &lt;strong&gt;admin/admin&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Coding with CrewAI: AI Orchestration Simplified</title>
      <link>https://seehiong.github.io/2024/coding-with-crewai-ai-orchestration-simplified/</link>
      <pubDate>Fri, 29 Mar 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/coding-with-crewai-ai-orchestration-simplified/</guid>
      <description>&lt;p&gt;Welcome to an exploration of &lt;a href=&#34;https://www.crewai.io/&#34; target=&#34;_blank&#34;&gt;CrewAI&lt;/a&gt;, a state-of-the-art framework designed to orchestrate autonomous AI agents. In this post, we&amp;rsquo;ll dive into the practical aspects of CrewAI, discovering its functionalities and potential applications.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;&#xA;&lt;p&gt;To dive into the world of AI-driven creativity, let&amp;rsquo;s start by setting up our environment. We&amp;rsquo;ll create a dedicated Conda environment to ensure seamless integration with CrewAI:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Create a new Conda environment&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create -n crewai python&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;3.10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Active the environment&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate crewai&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>AutoPilot Setup for VS Code</title>
      <link>https://seehiong.github.io/2024/autopilot-setup-for-vs-code/</link>
      <pubDate>Sat, 16 Mar 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/autopilot-setup-for-vs-code/</guid>
      <description>&lt;p&gt;In this post, I&amp;rsquo;m going to demonstrate the setup of &lt;a href=&#34;https://continue.dev/docs/quickstart&#34; target=&#34;_blank&#34;&gt;Continue&lt;/a&gt;, an open-source autopilot designed for VS Code.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;&#xA;&lt;p&gt;Once you&amp;rsquo;ve installed the plugin from the market place, let&amp;rsquo;s proceed by adding Continue to the right sidebar of VS Code, as recommended.&lt;/p&gt;&#xA;&lt;h3 id=&#34;provider---lm-studio&#34;&gt;Provider - LM Studio&lt;/h3&gt;&#xA;&lt;p&gt;First, on my Windows machine, I&amp;rsquo;ll execute &lt;a href=&#34;https://lmstudio.ai/&#34; target=&#34;_blank&#34;&gt;LM Studio&lt;/a&gt; and download &lt;a href=&#34;https://huggingface.co/lmstudio-ai/gemma-2b-it-GGUF&#34; target=&#34;_blank&#34;&gt;Google&amp;rsquo;s Gemma 2B Instruct&lt;/a&gt; model.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Configuring Appwrite Functions with K3s</title>
      <link>https://seehiong.github.io/2024/configuring-appwrite-functions-with-k3s/</link>
      <pubDate>Sun, 10 Mar 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/configuring-appwrite-functions-with-k3s/</guid>
      <description>&lt;p&gt;Following up on my previous post about &lt;a href=&#34;https://seehiong.github.io/2024/deploying-appwrite-in-homelab-with-k3s/&#34; target=&#34;_blank&#34;&gt;deploying Appwrite with K3s&lt;/a&gt;, I will now guide you through configuring K3s to support Appwrite Functions.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;prepartion&#34;&gt;Prepartion&lt;/h2&gt;&#xA;&lt;h3 id=&#34;install-ngrok&#34;&gt;Install Ngrok&lt;/h3&gt;&#xA;&lt;p&gt;Since I am running Appwrite in my HomeLab, I need to utilize &lt;a href=&#34;https://ngrok.com/&#34; target=&#34;_blank&#34;&gt;ngrok&lt;/a&gt; to enable external network access (such as GitHub) to our internal network. After signing up, install ngrok via Chocolatey:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;choco install ngrok&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ngrok config add-authtoken xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ngrok http http://appwrite.local/                      &#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Deploying Budibase in HomeLab</title>
      <link>https://seehiong.github.io/2024/deploying-budibase-in-homelab/</link>
      <pubDate>Sun, 25 Feb 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/deploying-budibase-in-homelab/</guid>
      <description>&lt;p&gt;In this guide, we&amp;rsquo;ll delve into the process of installing &lt;a href=&#34;https://budibase.com/&#34; target=&#34;_blank&#34;&gt;Budibase&lt;/a&gt; within our HomeLab environment. Budibase offers the capability to craft robust applications and workflows from various data sources, enabling the secure deployment of professional-grade solutions across our teams.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;testing-budibase-with-docker-desktop&#34;&gt;Testing Budibase with Docker Desktop&lt;/h2&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s start our exploration by testing Budibase using &lt;a href=&#34;https://docs.budibase.com/docs/docker-compose&#34; target=&#34;_blank&#34;&gt;Docker compose&lt;/a&gt;. To begin, download both the &lt;em&gt;docker-compose.yaml&lt;/em&gt; and &lt;em&gt;.env&lt;/em&gt; files, then launch the platform with the following command:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deploying Appwrite in HomeLab with K3s</title>
      <link>https://seehiong.github.io/2024/deploying-appwrite-in-homelab-with-k3s/</link>
      <pubDate>Fri, 16 Feb 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/deploying-appwrite-in-homelab-with-k3s/</guid>
      <description>&lt;p&gt;In this post, we&amp;rsquo;ll embark on installing &lt;a href=&#34;https://appwrite.io/&#34; target=&#34;_blank&#34;&gt;Appwrite&lt;/a&gt;, an open-source platform designed to facilitate the integration of authentication, databases, functions, and storage, enabling the development of scalable applications within our HomeLab setup.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;prepartion&#34;&gt;Prepartion&lt;/h2&gt;&#xA;&lt;p&gt;Referencing my &lt;a href=&#34;https://seehiong.github.io/archives/2023/setting-up-k3s/&#34; target=&#34;_blank&#34;&gt;previous K3s setup post&lt;/a&gt;, let&amp;rsquo;s initiate the installation process by deploying K3s server, this time with Traefik disabled:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;--disable traefik&amp;#34;&lt;/span&gt; K3S_KUBECONFIG_MODE&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;644&amp;#34;&lt;/span&gt; sh -&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Text-to-Image with StableDiffusionPipeline</title>
      <link>https://seehiong.github.io/2024/text-to-image-with-stablediffusionpipeline/</link>
      <pubDate>Sat, 10 Feb 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/text-to-image-with-stablediffusionpipeline/</guid>
      <description>&lt;p&gt;In this post, I&amp;rsquo;ll delve into the capabilities of the &lt;a href=&#34;https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline&#34; target=&#34;_blank&#34;&gt;StableDiffusionPipeline&lt;/a&gt; for generating photorealistic images based on textual inputs.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;text-to-image&#34;&gt;Text-to-Image&lt;/h2&gt;&#xA;&lt;p&gt;Continuing from the &lt;a href=&#34;https://seehiong.github.io/2024/stable-diffusion-text-to-image-modeling-journey/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt;, I initiated the environment setup:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd stable-diffusion&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate ldm&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Subsequently, I installed the necessary libraries, &lt;a href=&#34;https://pypi.org/project/diffusers/&#34; target=&#34;_blank&#34;&gt;diffusers&lt;/a&gt; and &lt;a href=&#34;https://pypi.org/project/transformers/&#34; target=&#34;_blank&#34;&gt;transformers&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install --upgrade diffusers&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; transformers&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Stable Diffusion: Text-to-Image Modeling Journey</title>
      <link>https://seehiong.github.io/2024/stable-diffusion-text-to-image-modeling-journey/</link>
      <pubDate>Sat, 03 Feb 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/stable-diffusion-text-to-image-modeling-journey/</guid>
      <description>&lt;p&gt;In this article, we will delve into &lt;a href=&#34;https://github.com/CompVis/stable-diffusion&#34; target=&#34;_blank&#34;&gt;Stable Diffusion&lt;/a&gt;, a latent text-to-image diffusion model. In simple terms, diffusion models in machine learning represent a type of sophisticated computer program designed to learn how patterns evolve over time. Comprising three essential components – a forward process, a reverse process, and a sampling procedure – these models aim to comprehend and generate intricate patterns within a given dataset.&lt;/p&gt;&#xA;&lt;p&gt;Consider having a blurry image that needs enhancement. Diffusion models act as intelligent tools that learn to eliminate blurriness by grasping how images blur and then effectively reversing that process.&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenVINO, Optimum-Intel, CPU: An Exploration in Model Optimization</title>
      <link>https://seehiong.github.io/2024/openvino-optimum-intel-cpu-an-exploration-in-model-optimization/</link>
      <pubDate>Sat, 27 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/openvino-optimum-intel-cpu-an-exploration-in-model-optimization/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.openvino.ai/2023.3/home.html&#34; target=&#34;_blank&#34;&gt;OpenVINO&lt;/a&gt; represents an open-source toolkit designed for the optimization and deployment of deep learning models. Acting as the interface between the Transformers and Diffusers libraries, &lt;a href=&#34;https://huggingface.co/docs/optimum/intel/inference&#34; target=&#34;_blank&#34;&gt;Optimum-Intel&lt;/a&gt; seamlessly integrates with various Intel tools and libraries, facilitating the acceleration of end-to-end pipelines on Intel architectures. This post documents my journey as I set up and execute example code on my aging laptop, exploring the application of Quantization-aware Training (QAT) and the Token Merging method to optimize the UNet model within the Stable Diffusion pipeline.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Java Integration with Jupyter Notebooks</title>
      <link>https://seehiong.github.io/2024/java-integration-with-jupyter-notebooks/</link>
      <pubDate>Sun, 21 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/java-integration-with-jupyter-notebooks/</guid>
      <description>&lt;p&gt;In this post, I am delighted to share my journey of seamlessly integrating Java programming within Jupyter notebooks.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;&#xA;&lt;p&gt;Commencing with the selection of a pertinent Jupyter Docker Stack image, as detailed in the &lt;a href=&#34;https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html&#34; target=&#34;_blank&#34;&gt;Jupyter Docker Stacks documentation&lt;/a&gt;, the following Docker command initializes the setup:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker pull quay.io/jupyter/minimal-notebook:notebook-7.0.6&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Subsequently, the Docker image is run on a Windows WSL environment, with the host IP set to &lt;em&gt;192.168.68.114&lt;/em&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Autogen Studio</title>
      <link>https://seehiong.github.io/2024/exploring-autogen-studio/</link>
      <pubDate>Sun, 14 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/exploring-autogen-studio/</guid>
      <description>&lt;p&gt;In this comprehensive exploration, we delve into the realm of &lt;a href=&#34;https://microsoft.github.io/autogen/blog/2023/12/01/AutoGenStudio/&#34; target=&#34;_blank&#34;&gt;Autogen Studio&lt;/a&gt;, a powerful tool designed to streamline the rapid prototyping of multi-agent solutions for various tasks.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;&#xA;&lt;p&gt;The journey begins with the initial setup. A new Python virtual environment is created using Conda, followed by the installation of Autogen Studio and the essential configuration of API keys.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create -n autogenstudio python&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;3.10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate autogenstudio&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install autogenstudio&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export OPENAI_API_KEY&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sk-xxxx&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;autogenstudio ui --port &lt;span style=&#34;color:#ae81ff&#34;&gt;8081&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Deploying LLMs with WasmEdge in HomeLab</title>
      <link>https://seehiong.github.io/2024/deploying-llms-with-wasmedge-in-homelab/</link>
      <pubDate>Sat, 13 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/deploying-llms-with-wasmedge-in-homelab/</guid>
      <description>&lt;p&gt;In this post, we delve into the deployment of Lightweight Language Models (LLMs) using &lt;a href=&#34;https://github.com/WasmEdge/WasmEdge&#34; target=&#34;_blank&#34;&gt;WasmEdge&lt;/a&gt;, a lightweight, high-performance, and extensible WebAssembly runtime. This setup is tailored to run LLMs in our previously configured HomeLab environment.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;To establish an OpenAI-compatible &lt;a href=&#34;https://github.com/LlamaEdge/LlamaEdge/tree/main/llama-api-server&#34; target=&#34;_blank&#34;&gt;API server&lt;/a&gt;, begin by downloading the API server application:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -LO https://github.com/LlamaEdge/LlamaEdge/releases/latest/download/llama-api-server.wasm&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For Rust-based &lt;a href=&#34;https://wasmedge.org/docs/develop/rust/wasinn/llm_inference/&#34; target=&#34;_blank&#34;&gt;Llama 2 inference&lt;/a&gt;, we require the &lt;a href=&#34;https://wasmedge.org/docs/contribute/source/plugin/wasi_nn/&#34; target=&#34;_blank&#34;&gt;Wasi-NN&lt;/a&gt; plugin. The &lt;em&gt;Dockerfile&lt;/em&gt; below reflects this configuration:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Integrating NFS for Improved Scalability</title>
      <link>https://seehiong.github.io/2024/integrating-nfs-for-improved-scalability/</link>
      <pubDate>Sun, 07 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/integrating-nfs-for-improved-scalability/</guid>
      <description>&lt;p&gt;If you&amp;rsquo;ve been following the &lt;a href=&#34;https://seehiong.github.io/2024/integration-of-kong-into-ai-workflow/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt;, you might have observed that deploying LLM may not be as scalable. In this post, we delve into the integration of NFS (Network File System) to externalize model environment variables. This approach eliminates the need to rebuild a new image each time a new LLM (Language Model) is introduced into your workflow.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setting-up-nfs&#34;&gt;Setting up NFS&lt;/h2&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s start by setting up NFS to connect to my recently acquired TerraMaster NAS.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Integration of Kong into AI Workflow</title>
      <link>https://seehiong.github.io/2024/integration-of-kong-into-ai-workflow/</link>
      <pubDate>Sat, 06 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/integration-of-kong-into-ai-workflow/</guid>
      <description>&lt;p&gt;This post will guide you through the process of configuring Kong Gateway OSS and Kong Ingress Controller (KIC) separately and integrating Kong into our AI workflow.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;integrate-via-kong-gateway-oss-configuration&#34;&gt;Integrate via Kong Gateway OSS Configuration&lt;/h2&gt;&#xA;&lt;p&gt;If you followed my earlier guide on &lt;a href=&#34;https://seehiong.github.io/archives/2023/streamlining-api-management-with-kong/&#34; target=&#34;_blank&#34;&gt;setting up Kong Gateway&lt;/a&gt; setup, you likely use api.local:8000 to access the API.&lt;/p&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s revisit and update &lt;em&gt;KONG_ADMIN_GUI_URL&lt;/em&gt; environment  variable in the &lt;em&gt;kong-deploy-svc.yaml&lt;/em&gt; file:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Kong Ingress Controller (KIC)</title>
      <link>https://seehiong.github.io/2024/exploring-kong-ingress-controller-kic/</link>
      <pubDate>Mon, 01 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/exploring-kong-ingress-controller-kic/</guid>
      <description>&lt;p&gt;Wishing everyone a Happy New Year 2024! In this post, I shift focus from my previous discussion on &lt;a href=&#34;https://seehiong.github.io/archives/2023/streamlining-api-management-with-kong/&#34; target=&#34;_blank&#34;&gt;Kong Gateway&lt;/a&gt; to delve into the setup of the Kong Ingress Controller (KIC). Keeping it concise and celebratory for the New Year!&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://helm.sh/&#34; target=&#34;_blank&#34;&gt;Helm&lt;/a&gt; serves as a Kubernetes package manager. To install it, execute the following command:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo snap install helm --classic&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
  </channel>
</rss>
