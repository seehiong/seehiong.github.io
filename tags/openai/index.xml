<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>OpenAI on See Hiong&#39;s Blog</title>
    <link>//localhost:1313/tags/openai/</link>
    <description>Recent content in OpenAI on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 16 Mar 2024 10:00:00 +0800</lastBuildDate>
    <atom:link href="//localhost:1313/tags/openai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AutoPilot Setup for VS Code</title>
      <link>//localhost:1313/2024/autopilot-setup-for-vs-code/</link>
      <pubDate>Sat, 16 Mar 2024 10:00:00 +0800</pubDate>
      <guid>//localhost:1313/2024/autopilot-setup-for-vs-code/</guid>
      <description>&lt;p&gt;In this post, I&amp;rsquo;m going to demonstrate the setup of &lt;a href=&#34;https://continue.dev/docs/quickstart&#34; target=&#34;_blank&#34;&gt;Continue&lt;/a&gt;, an open-source autopilot designed for VS Code.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;&#xA;&lt;p&gt;Once you&amp;rsquo;ve installed the plugin from the market place, let&amp;rsquo;s proceed by adding Continue to the right sidebar of VS Code, as recommended.&lt;/p&gt;&#xA;&lt;h3 id=&#34;provider---lm-studio&#34;&gt;Provider - LM Studio&lt;/h3&gt;&#xA;&lt;p&gt;First, on my Windows machine, I&amp;rsquo;ll execute &lt;a href=&#34;https://lmstudio.ai/&#34; target=&#34;_blank&#34;&gt;LM Studio&lt;/a&gt; and download &lt;a href=&#34;https://huggingface.co/lmstudio-ai/gemma-2b-it-GGUF&#34; target=&#34;_blank&#34;&gt;Google&amp;rsquo;s Gemma 2B Instruct&lt;/a&gt; model.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Autogen Studio</title>
      <link>//localhost:1313/2024/exploring-autogen-studio/</link>
      <pubDate>Sun, 14 Jan 2024 20:00:00 +0800</pubDate>
      <guid>//localhost:1313/2024/exploring-autogen-studio/</guid>
      <description>&lt;p&gt;In this comprehensive exploration, we delve into the realm of &lt;a href=&#34;https://microsoft.github.io/autogen/blog/2023/12/01/AutoGenStudio/&#34; target=&#34;_blank&#34;&gt;Autogen Studio&lt;/a&gt;, a powerful tool designed to streamline the rapid prototyping of multi-agent solutions for various tasks.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;&#xA;&lt;p&gt;The journey begins with the initial setup. A new Python virtual environment is created using Conda, followed by the installation of Autogen Studio and the essential configuration of API keys.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create -n autogenstudio python&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;3.10&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate autogenstudio&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install autogenstudio&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export OPENAI_API_KEY&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sk-xxxx&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;autogenstudio ui --port &lt;span style=&#34;color:#ae81ff&#34;&gt;8081&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Deploying OpenAI-Compatible LLAMA CPP Server with K3S</title>
      <link>//localhost:1313/archives/2023/deploying-openai-compatible-llama-cpp-server-with-k3s/</link>
      <pubDate>Fri, 22 Dec 2023 20:00:00 +0800</pubDate>
      <guid>//localhost:1313/archives/2023/deploying-openai-compatible-llama-cpp-server-with-k3s/</guid>
      <description>&lt;p&gt;Commencing my week-long Christmas break, I extend the concepts from my &lt;a href=&#34;//localhost:1313/archives/2023/running-llama-server-in-local-machine/&#34;&gt;previous post&lt;/a&gt; to establish an OpenAI-compatible server in my &lt;a href=&#34;//localhost:1313/archives/2023/setting-up-k3s/&#34;&gt;Home Lab&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;technical-setup&#34;&gt;Technical Setup&lt;/h2&gt;&#xA;&lt;p&gt;After fine-tuning a sample &lt;a href=&#34;https://github.com/abetlen/llama-cpp-python/blob/main/docker/openblas_simple/Dockerfile&#34; target=&#34;_blank&#34;&gt;Dockerfile&lt;/a&gt;, I reinstalled my Ubuntu server, incorporating necessary adjustments. The subsequent setup commands, reflecting my Home Lab&amp;rsquo;s new IP address (192.168.68.115), include:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt update &amp;amp; sudo apt upgrade -y&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Install docker&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install docker.io&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo usermod -aG docker pi&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Install Anaconda&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -O https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chmod +x Anaconda3-2023.09-0-Linux-x86_64.sh&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./Anaconda3-2023.09-0-Linux-x86_64.sh&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Init conda&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;source /home/pi/anaconda3/bin/activate&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda init&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create -n docker-llama python&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate docker-llama &#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>RAG over Java code with Langchain4j</title>
      <link>//localhost:1313/archives/2023/rag-over-java-code-with-langchain4j/</link>
      <pubDate>Sat, 11 Nov 2023 20:00:00 +0800</pubDate>
      <guid>//localhost:1313/archives/2023/rag-over-java-code-with-langchain4j/</guid>
      <description>&lt;p&gt;Expanding upon the concepts introduced in the &lt;a href=&#34;//localhost:1313/archives/2023/building-an-ai-application-with-langchain4j/&#34;&gt;previous post&lt;/a&gt; and drawing inspiration from &lt;a href=&#34;https://python.langchain.com/docs/use_cases/question_answering/code_understanding&#34; target=&#34;_blank&#34;&gt;RAG over code&lt;/a&gt;, this article dives into the integration of a Retrieval-Augmented Generation (RAG) service. The goal is to empower users to query their Java codebase effectively.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;&#xA;&lt;p&gt;To embark on this journey, I&amp;rsquo;ve opted for &lt;a href=&#34;https://javaparser.org/&#34; target=&#34;_blank&#34;&gt;Java Parser&lt;/a&gt; , a powerful tool for traversing Java source code. Let&amp;rsquo;s begin by incorporating the latest version of Java Parser into our build.gradle file:&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to summarize YouTube Videos in Minutes (II)</title>
      <link>//localhost:1313/archives/2023/how-to-summarize-youtube-videos-in-minutes-2/</link>
      <pubDate>Fri, 16 Jun 2023 20:00:00 +2000</pubDate>
      <guid>//localhost:1313/archives/2023/how-to-summarize-youtube-videos-in-minutes-2/</guid>
      <description>&lt;p&gt;In continuation with the &lt;a href=&#34;//localhost:1313/archives/2023/how-to-summarize-youtube-videos-in-minutes-1/&#34;&gt;previous&lt;/a&gt; post, we will explore the power of AI by leveraging the &lt;a href=&#34;https://github.com/ggerganov/whisper.cpp&#34; target=&#34;_blank&#34;&gt;whisper.cpp&lt;/a&gt; library to convert audio to text, extracting audio from YouTube videos using &lt;a href=&#34;https://github.com/yt-dlp/yt-dlp&#34; target=&#34;_blank&#34;&gt;yt-dlp&lt;/a&gt;, and demonstrating how to utilize AI models like GPT4All and OpenAI for summarization.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setting-up-the-environment&#34;&gt;Setting Up the Environment&lt;/h2&gt;&#xA;&lt;p&gt;To get started, we need to set up the necessary tools and libraries. Follow the steps below:&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to summarize YouTube Videos in Minutes (I)</title>
      <link>//localhost:1313/archives/2023/how-to-summarize-youtube-videos-in-minutes-1/</link>
      <pubDate>Sat, 10 Jun 2023 20:00:00 +2000</pubDate>
      <guid>//localhost:1313/archives/2023/how-to-summarize-youtube-videos-in-minutes-1/</guid>
      <description>&lt;p&gt;Hey there, readers! Today, I&amp;rsquo;m thrilled to introduce you to an incredible tool that will completely transform the way you summarize YouTube videos. Get ready to dive into the captivating world of video content summarization using the powerful GPT4All. Trust me, this is an opportunity you don&amp;rsquo;t want to miss!&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setting-up-the-magic&#34;&gt;Setting up the Magic&lt;/h2&gt;&#xA;&lt;p&gt;Before we embark on this exciting journey, let&amp;rsquo;s ensure we have everything we need to get started. Install the necessary dependencies by running the following command:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Receipt OCR with LangChain, OpenAI and PyTesseract</title>
      <link>//localhost:1313/archives/2023/receipt-ocr-with-langchain-and-openai/</link>
      <pubDate>Tue, 06 Jun 2023 20:00:00 +0800</pubDate>
      <guid>//localhost:1313/archives/2023/receipt-ocr-with-langchain-and-openai/</guid>
      <description>&lt;p&gt;Recently, I embarked on an exhilarating journey into the realm of receipt OCR using LangChain and OpenAI, inspired by the captivating course on &lt;a href=&#34;https://learn.deeplearning.ai/langchain/lesson/1/introduction&#34; target=&#34;_blank&#34;&gt;LangChain for LLM Application Development&lt;/a&gt;. This exploration allowed me to unlock the full potential of PyTesseract, an extraordinary Python tool that serves as my guiding light for optical character recognition (OCR). By harnessing the power of OpenCV and seamlessly integrating OpenAI into the workflow, I aimed to compile the most optimal OCR results and validate them using LangChain&amp;rsquo;s impressive llm-math tool. Join me on this exciting adventure as we unravel the intricacies of receipt OCR and discover the true potential of LangChain, OpenAI, and PyTesseract.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Autofill PDF with LangChain and LangFlow</title>
      <link>//localhost:1313/archives/2023/auto-fill-pdf-with-langchain-and-langflow/</link>
      <pubDate>Fri, 26 May 2023 20:00:00 +0800</pubDate>
      <guid>//localhost:1313/archives/2023/auto-fill-pdf-with-langchain-and-langflow/</guid>
      <description>&lt;p&gt;In this blog post, we will explore the usage of &lt;a href=&#34;https://pypi.org/project/langflow/&#34; target=&#34;_blank&#34;&gt;LangFlow&lt;/a&gt;, a Python library available on PyPI, to streamline the process of capturing ideas and conducting proof-of-concepts for our intended use case. Considering the current &amp;ldquo;trend&amp;rdquo; of tech layoffs, there might be a time (touch wood) where there is a need to go for interviews and fill-up various interview forms that require filling out personal information. Building upon the previous blog post on running GPT4All for PostgreSQL with LangChain (referenced &lt;a href=&#34;//localhost:1313/archives/2023/running-gpt4all-for-postgresql-with-langchain/&#34;&gt;here&lt;/a&gt;), we will now leverage LangFlow and OpenAI to automate the population of a sample employment form with our personal data stored in PostgreSQL.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Running GPT4All for your PostgreSQL with LangChain</title>
      <link>//localhost:1313/archives/2023/running-gpt4all-for-postgresql-with-langchain/</link>
      <pubDate>Sun, 21 May 2023 20:00:00 +0800</pubDate>
      <guid>//localhost:1313/archives/2023/running-gpt4all-for-postgresql-with-langchain/</guid>
      <description>&lt;p&gt;In this post, I will walk you through the process of setting up &lt;a href=&#34;https://github.com/nomic-ai/gpt4all/blob/main/gpt4all-bindings/python/README.md&#34; target=&#34;_blank&#34;&gt;Python GPT4All&lt;/a&gt; on my Windows PC. Additionally, I will demonstrate how to utilize the power of GPT4All along with &lt;a href=&#34;https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html&#34; target=&#34;_blank&#34;&gt;SQL Chain&lt;/a&gt; for querying a postgreSQL database.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;&#xA;&lt;p&gt;Before we proceed with the installation process, it is important to have the necessary prerequisites in place.&lt;/p&gt;&#xA;&lt;p&gt;To follow along with this guide, make sure you have the following:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
