<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chart.js on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/tags/chart.js/</link>
    <description>Recent content in Chart.js on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 09 Feb 2025 20:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/tags/chart.js/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chat-Driven Insights with Chart.js</title>
      <link>https://seehiong.github.io/posts/2025/02/chat-driven-insights-with-chart.js/</link>
      <pubDate>Sun, 09 Feb 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/02/chat-driven-insights-with-chart.js/</guid>
      <description>Enhance your Vue.js application by integrating chat capabilities with Chart.js and LLMs like OpenAI and Deepseek-R1. This post walks through adding a chat node to the Micronaut-Optimizer workflow, enabling dynamic interactions with optimization results. Learn how to configure environment variables, connect workflow nodes, and send Chart.js data to LLMs. See it in action with sample inputs and responses, and explore running Deepseek-R1 locally with Ollama.</description>
    </item>
  </channel>
</rss>
