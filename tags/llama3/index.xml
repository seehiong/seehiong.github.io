<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Llama3 on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/tags/llama3/</link>
    <description>Recent content in Llama3 on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 15 Dec 2024 20:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/tags/llama3/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Porting Llama3.java to Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/12/porting-llama3.java-to-micronaut/</link>
      <pubDate>Sun, 15 Dec 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/12/porting-llama3.java-to-micronaut/</guid>
      <description>This project ports the original single-file llama3.java by Alfonso² Peterssen into a modular Micronaut application, transforming it from a console app to a stream-based, production-ready API. The internals and performance of the original GGUF-format LLM remain unchanged. Updates focus on restructuring the codebase into logical packages and adapting it to Micronaut’s ecosystem, enabling easier integration with Java microservices. This streamlined design retains the original’s simplicity while enhancing scalability and usability for modern AI applications.</description>
    </item>
    <item>
      <title>Building an AI Knowledge Assistant</title>
      <link>https://seehiong.github.io/posts/2024/11/building-an-ai-knowledge-assistant/</link>
      <pubDate>Sun, 24 Nov 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/11/building-an-ai-knowledge-assistant/</guid>
      <description>Learn how to build an AI-powered knowledge assistant using Python. This guide covers data ingestion from sources like PDFs, deploying a FastAPI-based API, and querying the assistant for detailed answers. Using advanced retrieval mechanisms, the assistant provides contextually relevant responses. You&amp;rsquo;ll also explore a working example with the CQRS design pattern. The complete project code is available on &#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;  &lt;a href=&#34;https://github.com/seehiong/ai-knowledge-assistant&#34; target=&#34;_blank&#34; rel=&#34;noopener noreferrer&#34; &gt;GitHub&lt;/a&gt;&#xD;&#xA;.</description>
    </item>
    <item>
      <title>Unleashing Text Generation with NVIDIA Jetson Orin NX</title>
      <link>https://seehiong.github.io/posts/2024/08/unleashing-text-generation-with-nvidia-jetson-orin-nx/</link>
      <pubDate>Sat, 17 Aug 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/08/unleashing-text-generation-with-nvidia-jetson-orin-nx/</guid>
      <description>This post explores the powerful capabilities of NVIDIA Jetson Orin NX for text generation tasks. It covers the setup and use of models like Llama 2 and Llama 3, including installation steps, performance benchmarks, and examples of interactive AI sessions. Additionally, it provides insights into using the Jetson platform for deploying AI models efficiently, with practical tips on getting started and maximizing performance. Whether you&amp;rsquo;re a developer or AI enthusiast, this guide offers a hands-on look at harnessing NVIDIA Jetson&amp;rsquo;s potential for advanced AI applications.</description>
    </item>
  </channel>
</rss>
