<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MLC on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/tags/mlc/</link>
    <description>Recent content in MLC on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sat, 02 Sep 2023 20:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/tags/mlc/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Unlocking the Power of Machine Learning with MLC LLM</title>
      <link>https://seehiong.github.io/posts/2023/09/unlocking-the-power-of-machine-learning-with-mlc-llm/</link>
      <pubDate>Sat, 02 Sep 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/09/unlocking-the-power-of-machine-learning-with-mlc-llm/</guid>
      <description>I delve into the transformative realm of MLC LLM, an advanced universal deployment solution for extensive language models. My post guides you personally through the setup, emphasizing critical components like TVM and Conda. I demonstrate the process, including TVM installation via pip, Conda setup on WSL, and Vulkan SDK installation for optimal performance. Navigating the MLC Chat exploration, I detail creating a Conda environment and running MLC LLM&amp;rsquo;s CLI version, offering a glimpse into its potential through a sample question. With MLC LLM and MLC Chat at your fingertips, the world of machine learning and language understanding unfolds boundless possibilities. ðŸš€ðŸ§ </description>
    </item>
  </channel>
</rss>
