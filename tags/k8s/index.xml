<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>K8s on See Hiong&#39;s Blog</title>
    <link>http://localhost:1313/tags/k8s/</link>
    <description>Recent content in K8s on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 01 Sep 2024 08:00:00 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/k8s/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Talos Linux: Setting Up a Secure, Immutable Kubernetes Cluster</title>
      <link>http://localhost:1313/2024/talos-linux-setting-up-a-secure-immutable-kubernetes-cluster/</link>
      <pubDate>Sun, 01 Sep 2024 08:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/talos-linux-setting-up-a-secure-immutable-kubernetes-cluster/</guid>
      <description>&lt;p&gt;In this post, I will walk you through the process of setting up a Kubernetes cluster using &lt;a href=&#34;https://www.talos.dev/&#34; target=&#34;_blank&#34;&gt;Talos Linux&lt;/a&gt;, an operating system specifically designed for Kubernetes that is secure, immutable, and minimal by design. Talos Linux is distinguished by its unique architecture: it is hardened by default, has no shell (bash), no SSH access, and no systemd. Instead, all management is conducted through an API.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;After downloading the &lt;a href=&#34;https://www.talos.dev/v1.7/talos-guides/install/bare-metal-platforms/iso/&#34; target=&#34;_blank&#34;&gt;ISO&lt;/a&gt; image, I used &lt;a href=&#34;https://etcher.balena.io/&#34; target=&#34;_blank&#34;&gt;balenaEtcher&lt;/a&gt; to create a bootable USB installation media. My setup consists of one control plane node and two worker nodes. The following IP addresses were assigned:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scaling Kafka Workloads with KEDA in Kubernetes</title>
      <link>http://localhost:1313/2024/scaling-kafka-workloads-with-keda-in-kubernetes/</link>
      <pubDate>Sat, 10 Aug 2024 10:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/scaling-kafka-workloads-with-keda-in-kubernetes/</guid>
      <description>&lt;p&gt;Building up my previous &lt;a href=&#34;http://localhost:1313/2024/setting-up-kafka-with-microk8s-and-multipass/&#34; target=&#34;_blank&#34;&gt;Kafka post&lt;/a&gt;, this article focuses on leveraging KEDA to scale Kafka consumer workloads dynamically. &lt;a href=&#34;https://keda.sh/&#34; target=&#34;_blank&#34;&gt;KEDA&lt;/a&gt; is a Kubernetes-based Event Driven Autoscaler that enables automatic scaling of pods based on the volume of events to be processed.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;keda-setup&#34;&gt;KEDA Setup&lt;/h2&gt;&#xA;&lt;p&gt;To begin, after accessing the &lt;em&gt;mk8s-vm&lt;/em&gt;, simply install KEDA with the following commands:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo microk8s enable community&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo microk8s enable keda&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Disable KEDA if necessary&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo microk8s disable keda&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Building Your First Kubeflow Pipeline: A Step-by-Step Guide</title>
      <link>http://localhost:1313/2024/building-your-first-kubeflow-pipeline-a-step-by-step-guide/</link>
      <pubDate>Sat, 20 Jul 2024 10:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/building-your-first-kubeflow-pipeline-a-step-by-step-guide/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.kubeflow.org/docs/components/pipelines/overview/&#34; target=&#34;_blank&#34;&gt;Kubeflow Pipelines (KFP)&lt;/a&gt; is a powerful platform for creating and deploying scalable machine learning (ML) workflows using Docker containers. It enables data scientists and ML engineers to author workflows in Python, manage and visualize pipeline runs, and efficiently utilize compute resources. KFP supports custom ML components, leverages existing ones, and ensures cross-platform portability with a platform-neutral &lt;a href=&#34;https://www.kubeflow.org/docs/components/pipelines/user-guides/core-functions/compile-a-pipeline/#ir-yaml&#34; target=&#34;_blank&#34;&gt;IR YAML definition&lt;/a&gt;. In this post, Iâ€™ll share my learnings about KFP v2.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Setting Up and Using KServe with Kubeflow</title>
      <link>http://localhost:1313/2024/setting-up-and-using-kserve-with-kubeflow/</link>
      <pubDate>Sun, 30 Jun 2024 10:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/setting-up-and-using-kserve-with-kubeflow/</guid>
      <description>&lt;p&gt;Expanding on my previous post on &lt;a href=&#34;http://localhost:1313/2024/setting-up-kubeflow-on-kubernetes-a-step-by-step-guide/&#34; target=&#34;_blank&#34;&gt;Kubeflow&lt;/a&gt;, I will explore &lt;a href=&#34;https://kserve.github.io/website/latest/&#34; target=&#34;_blank&#34;&gt;KServe&lt;/a&gt;, a standard Model Inference Platform on Kubernetes built for highly scalable use cases.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;first-kserve-endpoint&#34;&gt;First KServe Endpoint&lt;/h2&gt;&#xA;&lt;p&gt;Referencing &lt;a href=&#34;https://github.com/kserve/kserve/blob/master/docs/samples/istio-dex/README.md&#34; target=&#34;_blank&#34;&gt;KServe on Kubeflow with Istio-Dex&lt;/a&gt;, below is the &lt;em&gt;sklearn.yaml&lt;/em&gt; configuration. Note the sidecar annotation, which instructs not to inject the istio sidecar. Without this annotation, you may encounter error (refer to the troubleshooting section):&lt;/p&gt;</description>
    </item>
    <item>
      <title>Log Management with Graylog</title>
      <link>http://localhost:1313/2024/log-management-with-graylog/</link>
      <pubDate>Fri, 19 Apr 2024 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/log-management-with-graylog/</guid>
      <description>&lt;p&gt;In this blog post, I&amp;rsquo;ll guide you through the setup of &lt;a href=&#34;https://graylog.org/&#34; target=&#34;_blank&#34;&gt;Graylog&lt;/a&gt;, an open-source log management platform, within a HomeLab environment, providing a comprehensive solution for log analysis and monitoring.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setting-up-graylog-with-docker&#34;&gt;Setting up Graylog with Docker&lt;/h2&gt;&#xA;&lt;p&gt;To initiate our exploration of Graylog, we&amp;rsquo;ll opt for a &lt;a href=&#34;https://go2docs.graylog.org/5-2/downloading_and_installing_graylog/docker_installation.htm&#34; target=&#34;_blank&#34;&gt;Docker Installation&lt;/a&gt;, which ensures simplicity and ease of deployment. Follow the steps outlined in the official documentation to set up Graylog via Docker. Upon successful installation, access the Graylog interface by navigating to &lt;em&gt;http://localhost:9000/&lt;/em&gt;, and use the default credentials: &lt;strong&gt;admin/admin&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Configuring Appwrite Functions with K3s</title>
      <link>http://localhost:1313/2024/configuring-appwrite-functions-with-k3s/</link>
      <pubDate>Sun, 10 Mar 2024 10:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/configuring-appwrite-functions-with-k3s/</guid>
      <description>&lt;p&gt;Following up on my previous post about &lt;a href=&#34;http://localhost:1313/2024/deploying-appwrite-in-homelab-with-k3s/&#34; target=&#34;_blank&#34;&gt;deploying Appwrite with K3s&lt;/a&gt;, I will now guide you through configuring K3s to support Appwrite Functions.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;prepartion&#34;&gt;Prepartion&lt;/h2&gt;&#xA;&lt;h3 id=&#34;install-ngrok&#34;&gt;Install Ngrok&lt;/h3&gt;&#xA;&lt;p&gt;Since I am running Appwrite in my HomeLab, I need to utilize &lt;a href=&#34;https://ngrok.com/&#34; target=&#34;_blank&#34;&gt;ngrok&lt;/a&gt; to enable external network access (such as GitHub) to our internal network. After signing up, install ngrok via Chocolatey:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;choco install ngrok&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ngrok config add-authtoken xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ngrok http http://appwrite.local/                      &#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Deploying Budibase in HomeLab</title>
      <link>http://localhost:1313/2024/deploying-budibase-in-homelab/</link>
      <pubDate>Sun, 25 Feb 2024 10:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/deploying-budibase-in-homelab/</guid>
      <description>&lt;p&gt;In this guide, we&amp;rsquo;ll delve into the process of installing &lt;a href=&#34;https://budibase.com/&#34; target=&#34;_blank&#34;&gt;Budibase&lt;/a&gt; within our HomeLab environment. Budibase offers the capability to craft robust applications and workflows from various data sources, enabling the secure deployment of professional-grade solutions across our teams.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;testing-budibase-with-docker-desktop&#34;&gt;Testing Budibase with Docker Desktop&lt;/h2&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s start our exploration by testing Budibase using &lt;a href=&#34;https://docs.budibase.com/docs/docker-compose&#34; target=&#34;_blank&#34;&gt;Docker compose&lt;/a&gt;. To begin, download both the &lt;em&gt;docker-compose.yaml&lt;/em&gt; and &lt;em&gt;.env&lt;/em&gt; files, then launch the platform with the following command:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deploying Appwrite in HomeLab with K3s</title>
      <link>http://localhost:1313/2024/deploying-appwrite-in-homelab-with-k3s/</link>
      <pubDate>Fri, 16 Feb 2024 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/deploying-appwrite-in-homelab-with-k3s/</guid>
      <description>&lt;p&gt;In this post, we&amp;rsquo;ll embark on installing &lt;a href=&#34;https://appwrite.io/&#34; target=&#34;_blank&#34;&gt;Appwrite&lt;/a&gt;, an open-source platform designed to facilitate the integration of authentication, databases, functions, and storage, enabling the development of scalable applications within our HomeLab setup.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;prepartion&#34;&gt;Prepartion&lt;/h2&gt;&#xA;&lt;p&gt;Referencing my &lt;a href=&#34;http://localhost:1313/archives/2023/setting-up-k3s/&#34; target=&#34;_blank&#34;&gt;previous K3s setup post&lt;/a&gt;, let&amp;rsquo;s initiate the installation process by deploying K3s server, this time with Traefik disabled:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;--disable traefik&amp;#34;&lt;/span&gt; K3S_KUBECONFIG_MODE&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;644&amp;#34;&lt;/span&gt; sh -&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Java Integration with Jupyter Notebooks</title>
      <link>http://localhost:1313/2024/java-integration-with-jupyter-notebooks/</link>
      <pubDate>Sun, 21 Jan 2024 10:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/java-integration-with-jupyter-notebooks/</guid>
      <description>&lt;p&gt;In this post, I am delighted to share my journey of seamlessly integrating Java programming within Jupyter notebooks.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;&#xA;&lt;p&gt;Commencing with the selection of a pertinent Jupyter Docker Stack image, as detailed in the &lt;a href=&#34;https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html&#34; target=&#34;_blank&#34;&gt;Jupyter Docker Stacks documentation&lt;/a&gt;, the following Docker command initializes the setup:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker pull quay.io/jupyter/minimal-notebook:notebook-7.0.6&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Subsequently, the Docker image is run on a Windows WSL environment, with the host IP set to &lt;em&gt;192.168.68.114&lt;/em&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Integrating NFS for Improved Scalability</title>
      <link>http://localhost:1313/2024/integrating-nfs-for-improved-scalability/</link>
      <pubDate>Sun, 07 Jan 2024 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/integrating-nfs-for-improved-scalability/</guid>
      <description>&lt;p&gt;If you&amp;rsquo;ve been following the &lt;a href=&#34;http://localhost:1313/2024/integration-of-kong-into-ai-workflow/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt;, you might have observed that deploying LLM may not be as scalable. In this post, we delve into the integration of NFS (Network File System) to externalize model environment variables. This approach eliminates the need to rebuild a new image each time a new LLM (Language Model) is introduced into your workflow.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setting-up-nfs&#34;&gt;Setting up NFS&lt;/h2&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s start by setting up NFS to connect to my recently acquired TerraMaster NAS.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Integration of Kong into AI Workflow</title>
      <link>http://localhost:1313/2024/integration-of-kong-into-ai-workflow/</link>
      <pubDate>Sat, 06 Jan 2024 10:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/integration-of-kong-into-ai-workflow/</guid>
      <description>&lt;p&gt;This post will guide you through the process of configuring Kong Gateway OSS and Kong Ingress Controller (KIC) separately and integrating Kong into our AI workflow.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;integrate-via-kong-gateway-oss-configuration&#34;&gt;Integrate via Kong Gateway OSS Configuration&lt;/h2&gt;&#xA;&lt;p&gt;If you followed my earlier guide on &lt;a href=&#34;http://localhost:1313/archives/2023/streamlining-api-management-with-kong/&#34; target=&#34;_blank&#34;&gt;setting up Kong Gateway&lt;/a&gt; setup, you likely use api.local:8000 to access the API.&lt;/p&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s revisit and update &lt;em&gt;KONG_ADMIN_GUI_URL&lt;/em&gt; environment  variable in the &lt;em&gt;kong-deploy-svc.yaml&lt;/em&gt; file:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Kong Ingress Controller (KIC)</title>
      <link>http://localhost:1313/2024/exploring-kong-ingress-controller-kic/</link>
      <pubDate>Mon, 01 Jan 2024 10:00:00 +0800</pubDate>
      <guid>http://localhost:1313/2024/exploring-kong-ingress-controller-kic/</guid>
      <description>&lt;p&gt;Wishing everyone a Happy New Year 2024! In this post, I shift focus from my previous discussion on &lt;a href=&#34;http://localhost:1313/archives/2023/streamlining-api-management-with-kong/&#34; target=&#34;_blank&#34;&gt;Kong Gateway&lt;/a&gt; to delve into the setup of the Kong Ingress Controller (KIC). Keeping it concise and celebratory for the New Year!&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://helm.sh/&#34; target=&#34;_blank&#34;&gt;Helm&lt;/a&gt; serves as a Kubernetes package manager. To install it, execute the following command:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo snap install helm --classic&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Streamlining API Management with Kong</title>
      <link>http://localhost:1313/archives/2023/streamlining-api-management-with-kong/</link>
      <pubDate>Sun, 31 Dec 2023 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2023/streamlining-api-management-with-kong/</guid>
      <description>&lt;p&gt;In this comprehensive guide, we will walk through the process of integrating &lt;a href=&#34;https://konghq.com/&#34; target=&#34;_blank&#34;&gt;Kong&lt;/a&gt;, a robust unified API platform, into our home lab environment.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;prerequistes&#34;&gt;Prerequistes&lt;/h2&gt;&#xA;&lt;p&gt;To begin, I will start with a fresh Ubuntu server instance. We&amp;rsquo;ll start by installing Docker and configuring it for non-root usage:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install docker.io&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo usermod -aG docker pi&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Run Docker without sudo by logging back in or executing this&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;su - pi&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>AI Integration: LocalAI, Chroma, and Langchain4j</title>
      <link>http://localhost:1313/archives/2023/ai-integration-localai-chroma-langchain4j/</link>
      <pubDate>Fri, 29 Dec 2023 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2023/ai-integration-localai-chroma-langchain4j/</guid>
      <description>&lt;p&gt;Referring to the &lt;a href=&#34;http://localhost:1313/archives/2023/building-an-ai-application-with-langchain4j/&#34; target=&#34;_blank&#34;&gt;Building an AI application with Langchaing4j&lt;/a&gt; guide, the deployment of necessary Docker images, LocalAI, and Chroma to our Home Lab is outlined.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;creating-custom-localai-image&#34;&gt;Creating custom LocalAI image&lt;/h2&gt;&#xA;&lt;p&gt;Begin with pulling the latest image using the &lt;a href=&#34;https://localai.io/howtos/easy-setup-docker/&#34; target=&#34;_blank&#34;&gt;easy docker setup&lt;/a&gt; guide:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker pull quay.io/go-skynet/local-ai:v2.2.0&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now, run LocalAI from the &lt;em&gt;~/localai&lt;/em&gt; folder and download a model:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Setting up K3s</title>
      <link>http://localhost:1313/archives/2023/setting-up-k3s/</link>
      <pubDate>Sun, 30 Jul 2023 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2023/setting-up-k3s/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.k3s.io/&#34; target=&#34;_blank&#34;&gt;K3S&lt;/a&gt; is a lightweight and easy-to-install Kubernetes distribution, making it an ideal choice for running a Kubernetes cluster in your home lab. In this blog post, we will walk you through the step-by-step process of setting up K3s on an Ubuntu Server 22.04.2 LTS.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-setting-up-k3s&#34;&gt;1 Setting up K3S&lt;/h2&gt;&#xA;&lt;h3 id=&#34;11-installing-ubuntu-server-22042-lts&#34;&gt;1.1 Installing Ubuntu Server 22.04.2 LTS&lt;/h3&gt;&#xA;&lt;p&gt;To start, we&amp;rsquo;ll install &lt;a href=&#34;https://ubuntu.com/download/server&#34; target=&#34;_blank&#34;&gt;Ubuntu server 22.04.2 LTS&lt;/a&gt; on our laptop. You can verify the Linux distribution using the following command:&lt;/p&gt;</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (IV)</title>
      <link>http://localhost:1313/archives/2021/building-a-ci-cd-pipeline-on-a-raspberry-pi-cluster-part-4/</link>
      <pubDate>Sun, 18 Jul 2021 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2021/building-a-ci-cd-pipeline-on-a-raspberry-pi-cluster-part-4/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/pipeline4/raspberry-pi-enclosed-in-lego-structure.jpeg&#34; alt=&#34;raspberry-pi-enclosed-in-lego-structure&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Building a CI/CD pipeline on a Raspberry PI Cluster (Part 4), with SonarQube integrating into Jenkins and Gitlab&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;building-a-cicd-pipeline-on-a-raspberry-pi-cluster-part-iv&#34;&gt;Building a CI/CD pipeline on a Raspberry PI Cluster (Part IV)&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 15 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;In continuation from &lt;a href=&#34;http://localhost:1313/archives/2021/building-a-ci-cd-pipeline-on-a-raspberry-pi-cluster-part-3/&#34; target=&#34;_blank&#34;&gt;part 3&lt;/a&gt; of this guide, I will add &lt;a href=&#34;https://www.sonarqube.org/&#34; target=&#34;_blank&#34;&gt;SonarQube&lt;/a&gt; into my CI/CD pipeline. This will enahnce our workflow with continuous code quality and code security.&lt;/p&gt;</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (III)</title>
      <link>http://localhost:1313/archives/2021/building-a-ci-cd-pipeline-on-a-raspberry-pi-cluster-part-3/</link>
      <pubDate>Sun, 04 Jul 2021 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2021/building-a-ci-cd-pipeline-on-a-raspberry-pi-cluster-part-3/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/pipeline3/raspberry-pi-enclosed-in-lego-structure.jpeg&#34; alt=&#34;raspberry-pi-enclosed-in-lego-structure&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Building a CI/CD pipeline on a Raspberry PI Cluster (Part 3), with JFrog Container Registry supporting our Docker containers and Helm Chart repositories&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;building-a-cicd-pipeline-on-a-raspberry-pi-cluster-part-iii&#34;&gt;Building a CI/CD pipeline on a Raspberry PI Cluster (Part III)&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 15 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Continue from &lt;a href=&#34;http://localhost:1313/archives/2021/building-a-ci-cd-pipeline-on-a-raspberry-pi-cluster-part-2/&#34; target=&#34;_blank&#34;&gt;part 2&lt;/a&gt; of this guide, I will add &lt;a href=&#34;https://jfrog.com/container-registry/&#34; target=&#34;_blank&#34;&gt;JFrog Container Registry&lt;/a&gt; to my CI/CD pipeline.&lt;/p&gt;&#xA;&lt;h2 id=&#34;installing-container-registry&#34;&gt;Installing Container Registry&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(5 mins)&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (II)</title>
      <link>http://localhost:1313/archives/2021/building-a-ci-cd-pipeline-on-a-raspberry-pi-cluster-part-2/</link>
      <pubDate>Mon, 21 Jun 2021 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2021/building-a-ci-cd-pipeline-on-a-raspberry-pi-cluster-part-2/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/pipeline2/raspberry-pi-enclosed-in-lego-structure.jpeg&#34; alt=&#34;raspberry-pi-enclosed-in-lego-structure&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Building a CI/CD pipeline part 2 on a Raspberry PI Cluster, with JFrog Artifactory as the repository manager&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;building-a-cicd-pipeline-on-a-raspberry-pi-cluster-part-ii&#34;&gt;Building a CI/CD pipeline on a Raspberry PI Cluster (Part II)&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 40 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Continuing from &lt;a href=&#34;http://localhost:1313/archives/2021/building-a-ci-cd-pipeline-on-a-raspberry-pi-cluster-part-1/&#34; target=&#34;_blank&#34;&gt;part I&lt;/a&gt; of this guide, I will add &lt;a href=&#34;https://jfrog.com/artifactory/&#34; target=&#34;_blank&#34;&gt;JFrog Artifactory&lt;/a&gt; to my CI/CD pipeline.&lt;/p&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(1 min)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Referencing from my previous post on &lt;a href=&#34;http://localhost:1313/archives/2020/jenkins-maven-agent-for-kubernetes/&#34; target=&#34;_blank&#34;&gt;maven agent&lt;/a&gt;, let&amp;rsquo;s configure maven-agent to mount Longhorn volume. Navigate to &lt;em&gt;Manage Jenkins &amp;gt; Manage Nodes and Clouds &amp;gt; Configure Clouds&lt;/em&gt;. Expand on Pod Template details and add a volume:&lt;/p&gt;</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (I)</title>
      <link>http://localhost:1313/archives/2021/building-a-ci-cd-pipeline-on-a-raspberry-pi-cluster-part-1/</link>
      <pubDate>Sun, 13 Jun 2021 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2021/building-a-ci-cd-pipeline-on-a-raspberry-pi-cluster-part-1/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/pipeline1/raspberry-pi-enclosed-in-lego-structure.jpeg&#34; alt=&#34;raspberry-pi-enclosed-in-lego-structure&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Building a CI/CD pipeline on a Raspberry PI Cluster, with 3 master and 1 worker nodes, enclosed in a custom-made LEGO structure&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;building-a-cicd-pipeline-on-a-raspberry-pi-cluster-part-i&#34;&gt;Building a CI/CD pipeline on a Raspberry PI Cluster (Part I)&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 40 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;In this series, I will build my own CI/CD pipeline, with tools that are configured to run on &lt;a href=&#34;http://localhost:1313/archives/2021/raspberry-pi-cluster-with-longhorn/&#34; target=&#34;_blank&#34;&gt;Raspberry PI Cluster and Longhorn&lt;/a&gt;, a HA Raspberry PI Cluster. By end of this guide, you will have a &lt;a href=&#34;https://gitea.io/en-us/&#34; target=&#34;_blank&#34;&gt;self-hosted Git service&lt;/a&gt;, working hand-in-hand with &lt;a href=&#34;https://www.jenkins.io/&#34; target=&#34;_blank&#34;&gt;Jenkins&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Pi Cluster with Longhorn</title>
      <link>http://localhost:1313/archives/2021/raspberry-pi-cluster-with-longhorn/</link>
      <pubDate>Sun, 06 Jun 2021 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2021/raspberry-pi-cluster-with-longhorn/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/longhorn/highly-available-kubernetes-pi-cluster.png&#34; alt=&#34;highly-available-kubernetes-pi-cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;By running Raspberry PI Cluster with Longhorn, you will have a simplified, easy to deploy cloud-native persistent block storage&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;raspberry-pi-cluster-and-longhorn&#34;&gt;Raspberry Pi Cluster and Longhorn&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 30 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;In this section, I will install &lt;a href=&#34;https://longhorn.io/&#34; target=&#34;_blank&#34;&gt;Longhorn&lt;/a&gt;, a highly available persistance storage for Kubernetes. This guide assumes that you have a working Raspberry PI Cluster. If you do not have, please  follow &lt;a href=&#34;http://localhost:1313/archives/2021/kubernetes-pi-cluster-with-ansible/&#34; target=&#34;_blank&#34;&gt;Kubernetes Cluster with Ansible&lt;/a&gt; or &lt;a href=&#34;http://localhost:1313/archives/2020/highly-available-kubernetes-pi-cluster-part-1/&#34; target=&#34;_blank&#34;&gt;HA Kubernetes Pi Cluster (Part I)&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>K8s Pi Cluster with Ansible</title>
      <link>http://localhost:1313/archives/2021/kubernetes-pi-cluster-with-ansible/</link>
      <pubDate>Sat, 29 May 2021 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2021/kubernetes-pi-cluster-with-ansible/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/ansible/highly-available-kubernetes-pi-cluster.png&#34; alt=&#34;highly-available-kubernetes-pi-cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;By provisioning a Kubernetes PI Cluster with Ansible, you can easily spin off a Raspberry PI cluster&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;kubernetes-cluster-with-ansible&#34;&gt;Kubernetes Cluster with Ansible&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 50 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;In this guide, I will configure a Kubernetes Cluster using &lt;a href=&#34;https://www.ansible.com/&#34; target=&#34;_blank&#34;&gt;Ansible&lt;/a&gt;. This guide follows closely to the &lt;a href=&#34;https://github.com/raspbernetes/k8s-cluster-installation&#34; target=&#34;_blank&#34;&gt;Raspbernetes Cluster Installation&lt;/a&gt;. I will be using 3x Raspberry Pi 4 Model B 8GB as the master nodes and 1x Raspberry Pi 3 Model B as the only worker node.&lt;/p&gt;</description>
    </item>
    <item>
      <title>HA K8s Pi Cluster (II)</title>
      <link>http://localhost:1313/archives/2020/highly-available-kubernetes-pi-cluster-part-2/</link>
      <pubDate>Mon, 17 Aug 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/highly-available-kubernetes-pi-cluster-part-2/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/ha-k8s2/highly-available-kubernetes-pi-cluster.png&#34; alt=&#34;highly-available-kubernetes-pi-cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;By having a Highly Available Kubernetes Pi Cluster, you will have full control over your production grade environment on-premise&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;ha-kubernetes-pi-cluster-part-ii&#34;&gt;HA Kubernetes Pi Cluster (Part II)&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 20 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;In this follow up guide, I will configure the HA Kubernetes Cluster onto the previous &lt;a href=&#34;http://localhost:1313/archives/2020/highly-available-kubernetes-pi-cluster-part-1/&#34; target=&#34;_blank&#34;&gt;external etcd setup&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;installing-docker&#34;&gt;Installing Docker&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(5 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Firstly, installs docker &lt;a href=&#34;https://kubernetes.io/docs/setup/production-environment/container-runtimes/&#34; target=&#34;_blank&#34;&gt;container runtimes&lt;/a&gt; to all master nodes:&lt;/p&gt;</description>
    </item>
    <item>
      <title>HA K8s Pi Cluster (I)</title>
      <link>http://localhost:1313/archives/2020/highly-available-kubernetes-pi-cluster-part-1/</link>
      <pubDate>Sun, 09 Aug 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/highly-available-kubernetes-pi-cluster-part-1/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/ha-k8s1/highly-available-kubernetes-pi-cluster.png&#34; alt=&#34;highly-available-kubernetes-pi-cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;By having a Highly Available Kubernetes Pi Cluster, you will have full control over your production grade environment on-premise&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;ha-kubernetes-pi-cluster-part-i&#34;&gt;HA Kubernetes Pi Cluster (Part I)&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 25 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;On this special day, I will like to wish all Singaporeans and Singapore a Happy 55th &lt;a href=&#34;https://www.ndp.gov.sg/&#34; target=&#34;_blank&#34;&gt;National Day&lt;/a&gt;!&lt;/p&gt;&#xA;&lt;p&gt;With the newly purchase 2x Raspberry Pi Model B 8GB and 64GB SD card to my collection, I will setup a Highly Available Kubernetes Pi Cluster. In this guide, I will setup an &lt;a href=&#34;https://etcd.io/&#34; target=&#34;_blank&#34;&gt;external etcd&lt;/a&gt; key-value store. In the &lt;a href=&#34;http://localhost:1313/archives/2020/highly-available-kubernetes-pi-cluster-part-2/&#34; target=&#34;_blank&#34;&gt;next article&lt;/a&gt;, I will continue with the HA configuration.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Private Registry for K8s Cluster</title>
      <link>http://localhost:1313/archives/2020/private-registry-for-kubernetes-cluster/</link>
      <pubDate>Fri, 07 Aug 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/private-registry-for-kubernetes-cluster/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/registry/raspberrypi4_modelb.png&#34; alt=&#34;raspberrypi4_modelb&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;With your own Private Registry for Kubernetes Cluster, you can have full control over the docker registry and improve overall performance&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;private-registry-on-kubernetes-cluster&#34;&gt;Private Registry on Kubernetes Cluster&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 10 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/_/registry/&#34; target=&#34;_blank&#34;&gt;Docker Registry&lt;/a&gt; is the official implementation for storing and distributing Docker images.&lt;/p&gt;&#xA;&lt;h2 id=&#34;preparing-private-registry&#34;&gt;Preparing Private Registry&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(5mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;First, create the &lt;a href=&#34;https://docs.docker.com/registry/insecure/&#34; target=&#34;_blank&#34;&gt;self-signed certificate&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir -p certs&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;openssl req &lt;span style=&#34;color:#ae81ff&#34;&gt;\&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  -newkey rsa:4096 -nodes -sha256 -keyout certs/domain.key &lt;span style=&#34;color:#ae81ff&#34;&gt;\&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  -x509 -days &lt;span style=&#34;color:#ae81ff&#34;&gt;365&lt;/span&gt; -out certs/domain.crt&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Jenkins Maven Agent</title>
      <link>http://localhost:1313/archives/2020/jenkins-maven-agent-for-kubernetes/</link>
      <pubDate>Fri, 31 Jul 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/jenkins-maven-agent-for-kubernetes/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/jenkins-agent/jenkins-on-kubernetes.png&#34; alt=&#34;jenkins-maven-agent-on-kubernetes&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;By creating Jenkins Maven Agent for Kubernetes Cluster, you can improve build time of your maven builds&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;jenkins-maven-agent-on-kubernetes&#34;&gt;Jenkins Maven Agent on Kubernetes&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 15 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Following up on the &lt;a href=&#34;http://localhost:1313/archives/2020/jenkins-pipeline-for-kubernetes-cluster/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt;, I will create a Jenkins Maven Agent for Kubernetes. By configuring a local maven m2 repository, you can save previous time on your builds.&lt;/p&gt;&#xA;&lt;h2 id=&#34;configuring-jenkins&#34;&gt;Configuring Jenkins&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(1 min)&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jenkins Pipeline for K8s Cluster</title>
      <link>http://localhost:1313/archives/2020/jenkins-pipeline-for-kubernetes-cluster/</link>
      <pubDate>Fri, 31 Jul 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/jenkins-pipeline-for-kubernetes-cluster/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/jenkins-pipeline/jenkins-on-kubernetes.png&#34; alt=&#34;jenkins-pipeline-for-kubernetes-cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;With Jenkins Pipeline for Kubernetes Cluster, you can create a continuous integration environment for your project&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;jenkins-pipeline-on-kubernetes-cluster&#34;&gt;Jenkins Pipeline on Kubernetes Cluster&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 10 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;In this guide, I will create my own &lt;a href=&#34;https://www.jenkins.io/doc/book/pipeline/jenkinsfile/&#34; target=&#34;_blank&#34;&gt;declarative Jenkins pipeline&lt;/a&gt;. With this, I can build, package and run my &lt;a href=&#34;https://spring.io/projects/spring-boot&#34; target=&#34;_blank&#34;&gt;Spring Boot&lt;/a&gt; Hello-World application.&lt;/p&gt;&#xA;&lt;h2 id=&#34;configuring-jenkins-and-gitea&#34;&gt;Configuring Jenkins and Gitea&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(1 min)&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Helm for K8s Cluster</title>
      <link>http://localhost:1313/archives/2020/helm-for-kubernetes-cluster/</link>
      <pubDate>Fri, 24 Jul 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/helm-for-kubernetes-cluster/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/helm/helm-on-kubernetes-cluster.png&#34; alt=&#34;helm-for-kubernetes-cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;With Helm as the package manager for Kubernetes Cluster on Raspberry, you can find, share and and use software built for Kubernetes&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;helm-on-kubernetes-cluster&#34;&gt;Helm on Kubernetes Cluster&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 10 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://helm.sh/&#34; target=&#34;_blank&#34;&gt;Helm&lt;/a&gt; is the package manager for Kubernetes. In this guide, I will install helm and setup ingress nginx controller with metallb as the layer 2 load balancer.&lt;/p&gt;&#xA;&lt;h2 id=&#34;installing-helm&#34;&gt;Installing Helm&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(3 mins)&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jenkins for K8s Cluster (II)</title>
      <link>http://localhost:1313/archives/2020/jenkins-for-kubernetes-cluster-part-2/</link>
      <pubDate>Sun, 19 Jul 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/jenkins-for-kubernetes-cluster-part-2/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/jenkins-k8s2/jenkins-on-kubernetes.png&#34; alt=&#34;jenkins-on-kubernetes&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;With Jenkins Agent for Kubernetes Cluster, you can orchestrate your build, test and scale deployment pipelines automatically&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;jenkins-on-kubernetes-cluster-part-ii&#34;&gt;Jenkins on Kubernetes Cluster (Part II)&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 25 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;In this guide, I will setup Jenkins agents for &lt;a href=&#34;http://localhost:1313/archives/2020/jenkins-for-kubernetes-cluster-part-1/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt;. With these agents, you can expand your Kubernetes cluster capabilities to handle additional loads.&lt;/p&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(15 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;First, you need to create the jenkins agent docker image for raspberry Pi cluster. You may start by creating a new &lt;em&gt;Dockerfile&lt;/em&gt; and insert the following:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jenkins for K8s Cluster (I)</title>
      <link>http://localhost:1313/archives/2020/jenkins-for-kubernetes-cluster-part-1/</link>
      <pubDate>Sun, 12 Jul 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/jenkins-for-kubernetes-cluster-part-1/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/jenkins-k8s1/jenkins-on-kubernetes.png&#34; alt=&#34;jenkins-on-kubernetes&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;With Jenkins for Kubernetes Cluster, you can orchestrate your build, test and deployment pipelines&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;jenkins-on-kubernetes-cluster-part-i&#34;&gt;Jenkins on Kubernetes Cluster (Part I)&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 40 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.jenkins.io/&#34; target=&#34;_blank&#34;&gt;Jenkins&lt;/a&gt; is the leading open source automation server. It provides hundreds of plugins for supporting the building, deploying and automating of any project.&lt;/p&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(25 min)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;In this guide, I am going to build the docker image for Jenkins on &lt;a href=&#34;http://localhost:1313/archives/2020/kubernetes-cluster-on-raspberry-pi/&#34; target=&#34;_blank&#34;&gt;Kubernetes Cluster on Pi&lt;/a&gt;. You may use the &lt;a href=&#34;https://hub.docker.com/r/balenalib/raspberrypi4-64-debian&#34; target=&#34;_blank&#34;&gt;base image&lt;/a&gt; from &lt;a href=&#34;https://www.balena.io/&#34; target=&#34;_blank&#34;&gt;Balena&lt;/a&gt; in any Docker environment. In addition, you can find more details about the Balena base images &lt;a href=&#34;https://www.balena.io/docs/reference/base-images/base-images&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gitea for K8s Cluster</title>
      <link>http://localhost:1313/archives/2020/gitea-on-kubernetes-pi-cluster/</link>
      <pubDate>Fri, 10 Jul 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/gitea-on-kubernetes-pi-cluster/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/gitea-k8s/gitea-on-raspberry-pi-cluster.png&#34; alt=&#34;gitea-on-kubernetes-pi-cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Having Gitea on Kubernetes Pi cluster, you will have full control over your personal Git repositories&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;gitea-for-kubernetes-cluster-on-pi&#34;&gt;Gitea for Kubernetes Cluster on Pi&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 40 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Similar to the previous post on &lt;a href=&#34;http://localhost:1313/archives/2020/gitea-for-raspberry-pi-cluster/&#34; target=&#34;_blank&#34;&gt;Gitea for MicroK8s Cluster&lt;/a&gt;, I will be setting up Git in the newly created &lt;a href=&#34;http://localhost:1313/archives/2020/kubernetes-cluster-on-raspberry-pi/&#34; target=&#34;_blank&#34;&gt;Kubernetes Cluster&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;setup-mysql&#34;&gt;Setup MySQL&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(15 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;First, I download the &lt;a href=&#34;https://dev.mysql.com/doc/mysql-installation-excerpt/8.0/en/docker-mysql-getting-started.html&#34; target=&#34;_blank&#34;&gt;mysql-server docker&lt;/a&gt; image:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kubernetes Cluster on Pi</title>
      <link>http://localhost:1313/archives/2020/kubernetes-cluster-on-raspberry-pi/</link>
      <pubDate>Sat, 04 Jul 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/kubernetes-cluster-on-raspberry-pi/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/kubernetes/kubernetes-cluster-on-raspberry-pi.png&#34; alt=&#34;kubernetes-cluster-on-raspberry-pi&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;With Kubernetes Cluster on Raspberry Pi, you may orchestrate and manage your Docker containers with full control&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;kubernetes-cluster&#34;&gt;Kubernetes Cluster&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 70 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Similar to the previous &lt;a href=&#34;http://localhost:1313/archives/2020/microk8s-cluster-on-raspberry-pi-8gb-part-1/&#34; target=&#34;_blank&#34;&gt;MicroK8s cluster&lt;/a&gt; setup, I am using &lt;a href=&#34;https://ubuntu.com/download/raspberry-pi&#34; target=&#34;_blank&#34;&gt;Ubuntu Server 20.04 LTS (64-bit)&lt;/a&gt; as my OS. Having a Kubernetes Cluster on Raspberry Pi, you will have more control over how the cluster configured.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Docker for MicroK8s Cluster</title>
      <link>http://localhost:1313/archives/2020/docker-on-raspberry-pi-cluster/</link>
      <pubDate>Sun, 21 Jun 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/docker-on-raspberry-pi-cluster/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/docker/docker-on-pi-cluster.png&#34; alt=&#34;docker-for-raspberry-pi&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;With Docker on Raspberry Pi cluster, you can run any containerized applications on your Pi Cluster&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;docker-on-raspberry&#34;&gt;Docker on Raspberry&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 15 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;To install &lt;a href=&#34;https://microk8s.io/docs/registry-images&#34; target=&#34;_blank&#34;&gt;Docker&lt;/a&gt; for Raspberry Pi Cluster, add &lt;strong&gt;ubuntu&lt;/strong&gt; user to the docker group:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install docker.io&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo usermod -aG docker ubuntu&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;su - ubuntu &lt;span style=&#34;color:#75715e&#34;&gt;# open a new shell with updated membership for the user&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>External Storage</title>
      <link>http://localhost:1313/archives/2020/external-storage-for-raspberry-pi-cluster/</link>
      <pubDate>Fri, 19 Jun 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/external-storage-for-raspberry-pi-cluster/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/storage/external-storage-for-pi.png&#34; alt=&#34;external-storage-for-pi&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Expand storage capacity by using external storage for your Raspberry Pi Cluster&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;external-storage-for-pi-cluster&#34;&gt;External Storage for Pi Cluster&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 35 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;With the &lt;a href=&#34;http://localhost:1313/archives/2020/microk8s-cluster-on-raspberry-pi-8gb-part-1/&#34; target=&#34;_blank&#34;&gt;MicroK8s cluster&lt;/a&gt; in place, I decided to expand the External Storage for Raspberry Pi cluster. For this to work, I will use my external 640GB USB hard disk and configure MicroK8s default storage.&lt;/p&gt;&#xA;&lt;h2 id=&#34;mounting-external-storage&#34;&gt;Mounting External Storage&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(5 mins)&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>MicroK8s on Pi 4 8GB (II)</title>
      <link>http://localhost:1313/archives/2020/microk8s-cluster-on-raspberry-pi-8gb-part-2/</link>
      <pubDate>Tue, 09 Jun 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/microk8s-cluster-on-raspberry-pi-8gb-part-2/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/microk8s2/leaf_nodes.png&#34; alt=&#34;raspberry-pi-leaf-nodes-for-microk8s-cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Adding few low-cost Raspberry Pi nodes to improve your MicroK8s performance&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;microk8s-cluster-on-raspberry-pi-4-model-b-8gb-part-ii&#34;&gt;MicroK8s Cluster on Raspberry Pi 4 Model B 8GB (Part II)&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 45 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Following up from the &lt;a href=&#34;http://localhost:1313/archives/2020/jenkins-for-kubernetes-cluster-part-1/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt;, for this second part, I will be adding new Raspberry Pi nodes to the MicroK8s Cluster. However, other than Raspberry Pi, you can also re-purpose some of your older unused laptop or PC and add them to your MicroK8s cluster.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MicroK8s on Pi 4 8GB (I)</title>
      <link>http://localhost:1313/archives/2020/microk8s-cluster-on-raspberry-pi-8gb-part-1/</link>
      <pubDate>Sat, 06 Jun 2020 20:00:00 +0800</pubDate>
      <guid>http://localhost:1313/archives/2020/microk8s-cluster-on-raspberry-pi-8gb-part-1/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/microk8s1/raspberrypi4_modelb.png&#34; alt=&#34;raspberry-pi-4-model-b&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Making your Raspberry Pi works for your MicroK8s cluster&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;microk8s-cluster-on-raspberry-pi-4-model-b-8gb-part-i&#34;&gt;MicroK8s Cluster on Raspberry Pi 4 Model B 8GB (Part I)&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 40 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;I am very excited to receive my Raspberry Pi 4 today. Since I do not have the microHDMI cable, I decided to go for a headless install. With this new Pi 8GB, I plan to check out on the &lt;a href=&#34;https://microk8s.io/&#34; target=&#34;_blank&#34;&gt;MicroK8s&lt;/a&gt;, a lightweight upstream K8s. This tutorial shows my steps for setting up the MicroK8s Cluster on Raspberry Pi 4 Model B 8GB.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
