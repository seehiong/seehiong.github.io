<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>K8s on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/tags/k8s/</link>
    <description>Recent content in K8s on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 13 Oct 2024 20:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/tags/k8s/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deploy Microservices with Talos Locally</title>
      <link>https://seehiong.github.io/posts/2024/10/deploy-microservices-with-talos-locally/</link>
      <pubDate>Sun, 13 Oct 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/10/deploy-microservices-with-talos-locally/</guid>
      <description>In this guide, we walk through deploying the Google Cloud Microservices Demo locally using Talos Linux in a VirtualBox VM. This step-by-step tutorial replicates a GKE environment, enabling seamless integration of microservices in a local Kubernetes cluster. We cover Talos installation, setting up the microservices demo, integrating MetalLB for load balancing, and optional Istio service mesh and Kiali observability for advanced monitoring. This approach is perfect for developers looking to simulate cloud environments locally and ensure their microservices run smoothly before deploying to production.</description>
    </item>
    <item>
      <title>Talos Linux: Setting Up a Secure, Immutable Kubernetes Cluster</title>
      <link>https://seehiong.github.io/posts/2024/09/talos-linux-setting-up-a-secure-immutable-kubernetes-cluster/</link>
      <pubDate>Sun, 01 Sep 2024 08:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/09/talos-linux-setting-up-a-secure-immutable-kubernetes-cluster/</guid>
      <description>This post guides you through setting up a secure, immutable Kubernetes cluster using Talos Linux. It covers installing Talos on control and worker nodes, configuring local storage with hostPath and Local Path Provisioner, and setting up the Kubernetes Dashboard with an admin user for cluster management. With Talos Linux, you achieve a minimal, API-managed Kubernetes environment without SSH or systemd, making it ideal for a secure and reliable homelab or production setup.</description>
    </item>
    <item>
      <title>Scaling Kafka Workloads with KEDA in Kubernetes</title>
      <link>https://seehiong.github.io/posts/2024/08/scaling-kafka-workloads-with-keda-in-kubernetes/</link>
      <pubDate>Sat, 10 Aug 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/08/scaling-kafka-workloads-with-keda-in-kubernetes/</guid>
      <description>This post demonstrates how to use KEDA, a Kubernetes-based Event Driven Autoscaler, to dynamically scale Kafka consumer workloads. Building on a previous setup with Kafka on MicroK8s, the guide walks through the installation of KEDA, configuring Kafka consumers, setting up secrets for authentication, and creating a ScaledObject to manage scaling based on message load. The post also includes practical examples of scaling under different loads, showcasing how KEDA automates horizontal scaling without requiring changes to the microservices code, making it easier to manage workloads in a Kubernetes environment.</description>
    </item>
    <item>
      <title>Building Your First Kubeflow Pipeline: A Step-by-Step Guide</title>
      <link>https://seehiong.github.io/posts/2024/07/building-your-first-kubeflow-pipeline-a-step-by-step-guide/</link>
      <pubDate>Sat, 20 Jul 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/07/building-your-first-kubeflow-pipeline-a-step-by-step-guide/</guid>
      <description>In this blog post, I guide you through creating and running your first Kubeflow pipeline. We&amp;rsquo;ll start with the &amp;ldquo;Hello World&amp;rdquo; example, demonstrate how to manage sequential and shared pipelines, and explore artifact storage with MinIO. Additionally, I&amp;rsquo;ll introduce K9s, a powerful terminal-based UI for managing your Kubernetes clusters efficiently. By the end, you&amp;rsquo;ll have a solid understanding of setting up and managing Kubeflow pipelines in your machine learning workflows.</description>
    </item>
    <item>
      <title>Setting Up and Using KServe with Kubeflow</title>
      <link>https://seehiong.github.io/posts/2024/06/setting-up-and-using-kserve-with-kubeflow/</link>
      <pubDate>Sun, 30 Jun 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/06/setting-up-and-using-kserve-with-kubeflow/</guid>
      <description>In this post, we explore KServe, a model inference platform on Kubernetes designed for scalability. Building on our previous Kubeflow guide, we detail how to set up your first KServe endpoint, make predictions, and troubleshoot common issues. Follow our step-by-step instructions to seamlessly integrate KServe with your Kubeflow environment and enhance your machine learning deployment process.</description>
    </item>
    <item>
      <title>Log Management with Graylog</title>
      <link>https://seehiong.github.io/posts/2024/04/log-management-with-graylog/</link>
      <pubDate>Fri, 19 Apr 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/04/log-management-with-graylog/</guid>
      <description>Explore setting up Graylog in your HomeLab for comprehensive log management. Configure MongoDB and OpenSearch, deploy Fluent Bit for log forwarding, and implement advanced features like Grok patterns and pipelines. Troubleshoot efficiently with tools like netshoot and tcpdump. Enhance your HomeLab environment with a scalable and efficient log management solution.</description>
    </item>
    <item>
      <title>Configuring Appwrite Functions with K3s</title>
      <link>https://seehiong.github.io/posts/2024/03/configuring-appwrite-functions-with-k3s/</link>
      <pubDate>Sun, 10 Mar 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/03/configuring-appwrite-functions-with-k3s/</guid>
      <description>This guide outlines configuring Appwrite Functions within a K3s environment. It covers essential steps, including installing ngrok for external network access, registering a GitHub App, and setting up Appwrite with required configurations. The process involves updating YAML files for deployment, ensuring proper routing with Traefik, and creating functions through the Appwrite interface. Once set up, the functions are deployed successfully, enabling seamless integration and execution within the K3s infrastructure.</description>
    </item>
    <item>
      <title>Deploying Budibase in HomeLab</title>
      <link>https://seehiong.github.io/posts/2024/02/deploying-budibase-in-homelab/</link>
      <pubDate>Sun, 25 Feb 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/02/deploying-budibase-in-homelab/</guid>
      <description>This post outlines the process of installing Budibase in a HomeLab environment, starting with testing it on Docker Desktop and then deploying it using Helm in Kubernetes. It guides through setting up an admin user, building the first app by creating a database, designing an application form, and configuring submission actions. The summary encapsulates the steps involved in testing, deploying, and building an application with Budibase, highlighting key actions such as Docker Compose setup, Helm installation, app creation, and deployment in a concise manner.</description>
    </item>
    <item>
      <title>Deploying Appwrite in HomeLab with K3s</title>
      <link>https://seehiong.github.io/posts/2024/02/deploying-appwrite-in-homelab-with-k3s/</link>
      <pubDate>Fri, 16 Feb 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/02/deploying-appwrite-in-homelab-with-k3s/</guid>
      <description>Learn how to seamlessly integrate Appwrite, an open-source platform, into your HomeLab setup using K3s. Follow step-by-step instructions to deploy K3s with Portainer, prepare Appwrite volumes, and configure miscellaneous services like MariaDB and InfluxDB. Utilize Kompose to convert Docker Compose files to Kubernetes for efficient deployment. Ensure smooth installation by mapping necessary environment variables and applying all required deployments and services. Finally, witness the successful deployment of Appwrite services and access the login page to start building scalable applications. Master the art of HomeLab application deployment with Appwrite and K3s.</description>
    </item>
    <item>
      <title>Java Integration with Jupyter Notebooks</title>
      <link>https://seehiong.github.io/posts/2024/01/java-integration-with-jupyter-notebooks/</link>
      <pubDate>Sun, 21 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/java-integration-with-jupyter-notebooks/</guid>
      <description>Embark on a seamless integration of Java into Jupyter notebooks with this comprehensive guide. Beginning with the selection of a relevant Jupyter Docker Stack, the post details setup steps and deployment in HomeLab, showcasing application results for verification. The integration of Java Kernel through JBang and testing with &amp;ldquo;Hello World&amp;rdquo; and Apache Commons library exemplifies the versatility. Further exploration involves experimenting with Java in a Python kernel using JBang. Concluding with a call to joyful coding, this journey promises a harmonious blend of Java&amp;rsquo;s robustness and Jupyter&amp;rsquo;s interactive nature. Discover the joy of coding in this enriched Java-in-Jupyter experience. Happy coding!</description>
    </item>
    <item>
      <title>Integrating NFS for Improved Scalability</title>
      <link>https://seehiong.github.io/posts/2024/01/integrating-nfs-for-improved-scalability/</link>
      <pubDate>Sun, 07 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/integrating-nfs-for-improved-scalability/</guid>
      <description>In this post, we explored the integration of NFS to enhance scalability in deploying LLM models within a home lab. Setting up NFS involved connecting to a TerraMaster NAS, and the K3s cluster was configured to dynamically provision storage. With NFS in place, the deployment process became more efficient, eliminating the need to rebuild images for each new model introduction. The post detailed the setup steps, from configuring NFS and K3s to deploying LLM models dynamically. This approach simplifies the scaling of Language Models, providing a centralized and scalable storage solution through NFS in a Kubernetes environment.</description>
    </item>
    <item>
      <title>Integration of Kong into AI Workflow</title>
      <link>https://seehiong.github.io/posts/2024/01/integration-of-kong-into-ai-workflow/</link>
      <pubDate>Sat, 06 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/integration-of-kong-into-ai-workflow/</guid>
      <description>This comprehensive guide navigates through configuring Kong OSS and Kong Ingress Controller (KIC), seamlessly integrating Kong into an AI workflow. Starting with Kong OSS configuration, the tutorial covers updating environment variables and service ports. The Langchain4j application is then adapted to leverage Kong API, allowing for flexible path-based APIs. Additionally, potential timeout issues are addressed. The guide concludes with a demonstration of Kong Ingress Controller configuration, emphasizing optimal settings for specific use cases. Whether through Kong OSS or KIC, readers gain insights into enhancing API management and integration within their AI workflows.</description>
    </item>
    <item>
      <title>Exploring Kong Ingress Controller (KIC)</title>
      <link>https://seehiong.github.io/posts/2024/01/exploring-kong-ingress-controller-kic/</link>
      <pubDate>Mon, 01 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/exploring-kong-ingress-controller-kic/</guid>
      <description>Embark on a journey into the new year by exploring Kong Ingress Controller (KIC) in your home lab. This guide, transitioning from a previous discussion on Kong Gateway, details the seamless setup of KIC using Helm and K3s. From initial preparations to installing Kong Ingress Controller and Gateway, witness the efficient management of APIs in your home lab environment. Learn to add Kong Ingresses, ensuring optimal routing for various paths. Through concise steps and illustrative visuals, this post simplifies the process, allowing you to experience KIC&amp;rsquo;s capabilities firsthand. Dive into the year with a hands-on exploration of API management with Kong in your home lab. Happy New Year!</description>
    </item>
    <item>
      <title>Streamlining API Management with Kong</title>
      <link>https://seehiong.github.io/posts/2023/12/streamlining-api-management-with-kong/</link>
      <pubDate>Sun, 31 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/streamlining-api-management-with-kong/</guid>
      <description>This comprehensive guide walks you through integrating Kong, a powerful unified API platform, into your home lab environment. Starting with Docker installation and a custom Kong image, it covers PostgreSQL deployment, MetalLB setup for load balancing, and Kong service and route configuration. The post concludes with troubleshooting tips and instructions for deploying your customized Kong image in a K3s cluster. This step-by-step tutorial empowers you to efficiently manage APIs in your home lab using Kong.</description>
    </item>
    <item>
      <title>AI Integration: LocalAI, Chroma, and Langchain4j</title>
      <link>https://seehiong.github.io/posts/2023/12/ai-integration-localai-chroma-and-langchain4j/</link>
      <pubDate>Fri, 29 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/ai-integration-localai-chroma-and-langchain4j/</guid>
      <description>Explore AI integration in a home lab with LocalAI, Chroma, and Langchain4j. Begin by creating a custom LocalAI image, deploying it alongside Chroma, and configuring the Kubernetes environment. The post details deploying and exposing services, ensuring seamless communication between applications. Learn to modify endpoints in the Langchain4j application for smooth integration with the Home Lab setup. With a focus on simplicity, this guide empowers users to harness the capabilities of these AI tools within a controlled home environment, fostering experimentation and development.</description>
    </item>
    <item>
      <title>Setting up K3s</title>
      <link>https://seehiong.github.io/posts/2023/07/setting-up-k3s/</link>
      <pubDate>Sun, 30 Jul 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/07/setting-up-k3s/</guid>
      <description>In my latest blog post, I share my journey setting up K3S, a lightweight Kubernetes distribution, in my home lab. With a step-by-step guide, I install K3S on an Ubuntu Server 22.04.2 LTS, offering a seamless experience. The post covers creating useful aliases for simplifying interactions with K3S and verifying the installation. Additionally, I introduce Portainer to manage Docker and Kubernetes in my home lab. I walk through setting up Portainer, adding a Kubernetes environment, and connecting it to the K3S cluster. Furthermore, I establish a local Docker registry and demonstrate optional steps for pushing and deploying Docker images within the K3S cluster.</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (IV)</title>
      <link>https://seehiong.github.io/posts/2021/07/ci/cd-pipeline-on-pi-cluster-iv/</link>
      <pubDate>Sun, 18 Jul 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/07/ci/cd-pipeline-on-pi-cluster-iv/</guid>
      <description>In the fourth part of my Raspberry Pi CI/CD pipeline series, I integrated SonarQube into the workflow for continuous code quality and security. I installed SonarQube on my Raspberry Pi Cluster, utilizing a custom Docker image. Additionally, I replaced Gitea with Gitlab for enhanced compatibility with SonarQube. I built and deployed Gitlab on the cluster, managing persistent storage with Longhorn volumes. For seamless integration, I configured Gitlab settings, created a Jenkins user, and set up access tokens. Lastly, I prepared Jenkins by installing necessary plugins and establishing connections with Gitlab. The result is an extended CI/CD pipeline with SonarQube, Jenkins, and Gitlab on a Raspberry Pi Cluster.</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (III)</title>
      <link>https://seehiong.github.io/posts/2021/07/ci/cd-pipeline-on-pi-cluster-iii/</link>
      <pubDate>Sun, 04 Jul 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/07/ci/cd-pipeline-on-pi-cluster-iii/</guid>
      <description>In the third part of my Raspberry Pi CI/CD pipeline series, I incorporated JFrog Container Registry. Following the previous guide, I installed the registry, configured Docker images, and set up Longhorn volumes. Configuring the JFrog Container Registry involved adding local repositories, setting permissions, and configuring HTTP settings. I demonstrated testing the registry with Docker login and pushing an image. For Kubernetes integration, I created registry secrets and updated deployment files. The result is a complete CI/CD pipeline on a Raspberry Pi Cluster with JFrog Container Registry supporting Docker images. Optional Jenkins configuration is provided for maven-agent support.</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (II)</title>
      <link>https://seehiong.github.io/posts/2021/06/ci/cd-pipeline-on-pi-cluster-ii/</link>
      <pubDate>Mon, 21 Jun 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/06/ci/cd-pipeline-on-pi-cluster-ii/</guid>
      <description>In the second installment of my Raspberry Pi CI/CD pipeline series, I seamlessly integrated JFrog Artifactory. Following the groundwork laid in [Part I], I extended the pipeline by configuring Maven-agent for Longhorn volume mounting, building a Raspberry Pi-compatible Artifactory Docker image, and configuring Artifactory. I demonstrated the process of creating permissions, Maven settings, and deploying JAR files. The integration with Jenkins involved plugin installation, settings configuration, and Jenkinsfile creation for artifact deployment. The result is a robust CI/CD pipeline on a Raspberry Pi Cluster, efficiently deploying artifacts to Artifactory. Troubleshooting tips address Longhorn volume stability and Jenkins volume permission issues.</description>
    </item>
    <item>
      <title>CI/CD Pipeline on Pi Cluster (I)</title>
      <link>https://seehiong.github.io/posts/2021/06/ci/cd-pipeline-on-pi-cluster-i/</link>
      <pubDate>Sun, 13 Jun 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/06/ci/cd-pipeline-on-pi-cluster-i/</guid>
      <description>In this series, I documented my journey building a CI/CD pipeline on a Raspberry Pi Cluster, featuring 3 master and 1 worker nodes, all housed in a custom LEGO structure. The setup includes tools like Metallb for load balancing, along with specific volumes for MySQL, Gitea, Jenkins, and Maven-agent. I detailed the installation processes for MySQL, Gitea, Jenkins, and Maven-agent, complete with YAML deployment files. The configuration steps for Jenkins, both for Kubernetes and Gitea integration, were outlined. The troubleshooting section covers issues related to Kubernetes connection errors and finding the Jenkins initial admin password. The final result showcases a functional CI/CD pipeline: when code is committed, it triggers the CI pipeline, with the Maven-agent building and compiling the code successfully.</description>
    </item>
    <item>
      <title>Pi Cluster with Longhorn</title>
      <link>https://seehiong.github.io/posts/2021/06/pi-cluster-with-longhorn/</link>
      <pubDate>Sun, 06 Jun 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/06/pi-cluster-with-longhorn/</guid>
      <description>I documented my journey setting up a Raspberry Pi Cluster with Longhorn for simplified cloud-native persistent block storage. The process took 30 minutes and assumed a functional Raspberry Pi Cluster. I prepared the environment by installing Helm, Calico CLI, and optionally, Kubernetes Dashboard. Then, I detailed the installation of Longhorn with Helm, including verification steps. Accessing Longhorn involved port-forwarding to the frontend service. The result: a highly available persistent storage solution for my Raspberry Pi Cluster, as depicted in the Longhorn dashboard. I addressed troubleshooting issues related to Calico and Longhorn uninstallation, ensuring a smooth experience.</description>
    </item>
    <item>
      <title>K8s Pi Cluster with Ansible</title>
      <link>https://seehiong.github.io/posts/2021/05/k8s-pi-cluster-with-ansible/</link>
      <pubDate>Sat, 29 May 2021 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2021/05/k8s-pi-cluster-with-ansible/</guid>
      <description>I documented my journey configuring a Kubernetes Cluster on a Raspberry Pi using Ansible, totaling 50 minutes. I deployed three Raspberry Pi 4 Model B 8GB as master nodes and one Raspberry Pi 3 Model B as a worker. After installing Ansible, Flash, and kubectl, I prepared the SD cards with customized cloud-config.yml files. Ansible inventory was configured accordingly. Additional SSH and system adjustments were made on each node. Customizations were applied, and the Kubernetes cluster setup was initiated using the Ansible playbook. Troubleshooting tips were provided for potential issues. Finally, the Kubernetes Pi Cluster with Ansible was ready for use.</description>
    </item>
    <item>
      <title>HA K8s Pi Cluster (II)</title>
      <link>https://seehiong.github.io/posts/2020/08/ha-k8s-pi-cluster-ii/</link>
      <pubDate>Mon, 17 Aug 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/08/ha-k8s-pi-cluster-ii/</guid>
      <description>In my journey to establish a Highly Available Kubernetes Pi Cluster, I&amp;rsquo;ve successfully configured the cluster following an external etcd setup. The process involves installing Docker, setting up the Docker daemon, and installing kubeadm. Initializing Kubernetes Master Nodes, preparing certificates, and configuring Calico for networking are key steps. Troubleshooting tips include addressing refused connections and certificate expiration. To rejoin a faulty node, cordoning, draining, and generating new keys are essential. Now, I proudly own a fully operational Highly Available Kubernetes Pi Cluster.</description>
    </item>
    <item>
      <title>HA K8s Pi Cluster (I)</title>
      <link>https://seehiong.github.io/posts/2020/08/ha-k8s-pi-cluster-i/</link>
      <pubDate>Sun, 09 Aug 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/08/ha-k8s-pi-cluster-i/</guid>
      <description>In this special guide, I celebrate Singapore&amp;rsquo;s 55th National Day by setting up a Highly Available Kubernetes Pi Cluster using 2x Raspberry Pi Model B 8GB. With a total setup time of 25 minutes, I configure an external etcd key-value store, laying the foundation for high availability. I detail OS preparation, creating a virtual IP with Keepalived, generating certificates for etcd, and setting up etcd on each master node. Troubleshooting tips are provided, including addressing cluster ID mismatches and replacing faulty members. Stay tuned for the next article covering the continuation of the HA configuration.</description>
    </item>
    <item>
      <title>Private Registry for K8s Cluster</title>
      <link>https://seehiong.github.io/posts/2020/08/private-registry-for-k8s-cluster/</link>
      <pubDate>Fri, 07 Aug 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/08/private-registry-for-k8s-cluster/</guid>
      <description>I&amp;rsquo;ve successfully set up my Private Registry for the Kubernetes Cluster on Raspberry Pi. With this, I have full control over the Docker registry, enhancing overall performance. The process involves creating a self-signed certificate, installing it on master and leaf nodes, and deploying the registry. Utilizing the private registry with Jenkins is seamless: tagging, pushing, and pulling images. Troubleshooting tips include updating the hosts file and trusting the certificate at the OS level. Now, my Kubernetes Cluster benefits from a personalized, efficient private registry.</description>
    </item>
    <item>
      <title>Jenkins Maven Agent</title>
      <link>https://seehiong.github.io/posts/2020/07/jenkins-maven-agent/</link>
      <pubDate>Fri, 31 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/jenkins-maven-agent/</guid>
      <description>I&amp;rsquo;ve successfully created a Jenkins Maven Agent for my Kubernetes Cluster, significantly improving Maven build times. Configuring Jenkins involved adding a pod template named maven with specific container and volume settings. I created a persistent volume and claims for the Maven repository, reducing build times for subsequent executions. Troubleshooting included resolving errors related to missing persistent volume claims and ownership issues. Now, my Jenkins builds efficiently leverage a local Maven repository within the Kubernetes environment, resulting in faster and more efficient Maven builds.</description>
    </item>
    <item>
      <title>Jenkins Pipeline for K8s Cluster</title>
      <link>https://seehiong.github.io/posts/2020/07/jenkins-pipeline-for-k8s-cluster/</link>
      <pubDate>Fri, 31 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/jenkins-pipeline-for-k8s-cluster/</guid>
      <description>I effortlessly set up a Jenkins Pipeline for my Kubernetes Cluster, enabling seamless continuous integration for my projects. Following my previous post on integrating Jenkins and Gitea, I configured Git and Gitea, creating a declarative Jenkins pipeline. With Gitea webhooks triggering builds on Git commits, I successfully tested the pipeline for a Spring Boot Hello-World application. The pipeline integrates with Git, Maven, and Gitea, ensuring efficient builds and synchronization with each commit. Troubleshooting tips address potential issues, providing a smooth Jenkins experience. Next, I plan to enhance Maven build times in my upcoming guide.</description>
    </item>
    <item>
      <title>Helm for K8s Cluster</title>
      <link>https://seehiong.github.io/posts/2020/07/helm-for-k8s-cluster/</link>
      <pubDate>Fri, 24 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/helm-for-k8s-cluster/</guid>
      <description>I&amp;rsquo;ve successfully set up Helm as the package manager for my Raspberry Pi Kubernetes Cluster, enabling easy discovery, sharing, and use of Kubernetes software. After installing Helm, I set up the NGINX Ingress Controller using Helm for external access. Additionally, I configured MetalLB as a layer 2 load balancer to manage external IP addresses. Revisiting my Gitea setup, I updated the service configuration to leverage MetalLB, enhancing the overall scalability and efficiency of my Kubernetes environment on Raspberry Pi. Helm proves to be a valuable tool for managing Kubernetes packages effortlessly.</description>
    </item>
    <item>
      <title>Jenkins for K8s Cluster (II)</title>
      <link>https://seehiong.github.io/posts/2020/07/jenkins-for-k8s-cluster-ii/</link>
      <pubDate>Sun, 19 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/jenkins-for-k8s-cluster-ii/</guid>
      <description>I&amp;rsquo;ve successfully set up Jenkins Agents for my Kubernetes Cluster, enhancing its capabilities for automated build, test, and scalable deployment pipelines. Following Docker image creation for the Jenkins agent on the Raspberry Pi, I configured Jenkins for scalability. Adjustments included setting the inbound agent protocol and configuring Kubernetes cloud settings. Creating Jenkins jobs and scheduling builds demonstrated the functionality, with agents initially suspended and later executing jobs successfully. The troubleshooting tip highlighted the importance of naming the container as jnlp. My Jenkins on Kubernetes Cluster is now fully operational, ready for future pipeline configurations.</description>
    </item>
    <item>
      <title>Jenkins for K8s Cluster (I)</title>
      <link>https://seehiong.github.io/posts/2020/07/jenkins-for-k8s-cluster-i/</link>
      <pubDate>Sun, 12 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/jenkins-for-k8s-cluster-i/</guid>
      <description>I&amp;rsquo;ve successfully set up Jenkins on my Kubernetes Cluster, streamlining build, test, and deployment pipelines. Following a Docker image creation for Jenkins on the Raspberry Pi, I deployed it to the Kubernetes Cluster. Troubleshooting involved building a custom Docker image due to ARM architecture limitations. Additionally, I addressed a service account error by creating the necessary role and role binding. Now, I can access Jenkins and proceed to configure Jenkins Agents for Kubernetes in the next post, enhancing automation within my cluster.</description>
    </item>
    <item>
      <title>Gitea for K8s Cluster</title>
      <link>https://seehiong.github.io/posts/2020/07/gitea-for-k8s-cluster/</link>
      <pubDate>Fri, 10 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/gitea-for-k8s-cluster/</guid>
      <description>In my recent endeavor, I spent 40 minutes setting up Gitea on my Kubernetes Pi cluster, granting me absolute control over personal Git repositories. I seamlessly integrated MySQL, using Docker images and Kubernetes configurations. The meticulous setup involved creating necessary paths on an external HDD, configuring persistent volumes, and ensuring a smooth deployment. I prepared MySQL for Gitea, creating a user, database, and granting privileges. Gitea installation via Docker and subsequent exposure to external access using NodePort were executed flawlessly. A troubleshooting tip addressed a MySQL access issue. Now, my Gitea on Kubernetes Pi Cluster is fully operational for efficient repository management.</description>
    </item>
    <item>
      <title>Kubernetes Cluster on Pi</title>
      <link>https://seehiong.github.io/posts/2020/07/kubernetes-cluster-on-pi/</link>
      <pubDate>Sat, 04 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/07/kubernetes-cluster-on-pi/</guid>
      <description>I recently spent 70 minutes setting up a Kubernetes Cluster on Raspberry Pi using Ubuntu Server 20.04 LTS. After burning the OS image and configuring a headless setup, I updated the OS, changed the hostname, and enabled memory cgroup. The Docker installation involved setting up external storage and configuring Docker daemon. Installing kubeadm and creating the Kubernetes cluster took an additional 45 minutes. I verified the cluster status, installed networking addons (Calico), and added leaf nodes. Troubleshooting included resolving conntrack and socat issues. Overall, the Raspberry Pi Kubernetes Cluster provides full control over Docker container orchestration.</description>
    </item>
    <item>
      <title>Docker for MicroK8s Cluster</title>
      <link>https://seehiong.github.io/posts/2020/06/docker-for-microk8s-cluster/</link>
      <pubDate>Sun, 21 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/docker-for-microk8s-cluster/</guid>
      <description>Setting up Docker on my Raspberry Pi Cluster took just 15 minutes. After installing Docker, I added the ubuntu user to the Docker group. Configuring Docker included adjusting the daemon settings for external storage. Testing Docker with a hello-world container went smoothly. To use local images for MicroK8s, I exported and injected the image successfully. Troubleshooting involved resolving daemon start errors, addressing connection issues, and handling permission errors. Formatting the existing NTFS HDD to ext4 and adjusting boot-up settings resolved challenges, making Docker work seamlessly on my Raspberry Pi Cluster.</description>
    </item>
    <item>
      <title>External Storage</title>
      <link>https://seehiong.github.io/posts/2020/06/external-storage/</link>
      <pubDate>Fri, 19 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/external-storage/</guid>
      <description>Expanding my Raspberry Pi Cluster&amp;rsquo;s storage with an external 640GB USB hard disk took 35 minutes. After mounting the external storage and addressing troubleshooting issues, I configured MicroK8s default storage to utilize the added space. Despite encountering errors, a reset and careful configuration solved the problem. Adding leaf nodes for MicroK8s and troubleshooting service unavailability for the dashboard completed the setup. I also disabled and re-enabled addons, ensuring a smooth integration of external storage with my MicroK8s cluster. Accessing the Kubernetes dashboard and checking nodes confirmed a successful expansion.</description>
    </item>
    <item>
      <title>MicroK8s on Pi 4 8GB (II)</title>
      <link>https://seehiong.github.io/posts/2020/06/microk8s-on-pi-4-8gb-ii/</link>
      <pubDate>Tue, 09 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/microk8s-on-pi-4-8gb-ii/</guid>
      <description>In the second part of my MicroK8s adventure on Raspberry Pi 4 Model B 8GB, I spent 45 minutes adding low-cost Raspberry Pi nodes to enhance cluster performance. Utilizing two older Pi 3B devices with Ubuntu Server (64-bit), I updated the OS, installed MicroK8s, and adjusted configurations. The master node initiated new node creation with &amp;ldquo;sudo microk8s add-node,&amp;rdquo; copying the output to each node. Successful integration was confirmed with &amp;ldquo;microk8s kubectl get node.&amp;rdquo; Excited to explore Kubernetes possibilities and gradually shift CI/CD pipelines to this lightweight cluster. Stay tuned for more on its diverse use cases!</description>
    </item>
    <item>
      <title>MicroK8s on Pi 4 8GB (I)</title>
      <link>https://seehiong.github.io/posts/2020/06/microk8s-on-pi-4-8gb-i/</link>
      <pubDate>Sat, 06 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2020/06/microk8s-on-pi-4-8gb-i/</guid>
      <description>I recently spent 40 minutes setting up MicroK8s on my new Raspberry Pi 4 Model B 8GB. Opting for a headless install due to a lack of a microHDMI cable, I used Ubuntu Server (64-bit) for the 64-bit requirements of MicroK8s. After initial setup, including changing the hostname and enabling memory cgroup, I installed MicroK8s, ensuring compatibility by adding my user to the MicroK8s group. Verification and usage of MicroK8s followed, with additional steps for enabling services like the dashboard. Troubleshooting involved switching to a 64-bit OS and finding the Pi&amp;rsquo;s IP using nmap. Excited to explore MicroK8s on my Raspberry Pi!</description>
    </item>
  </channel>
</rss>
