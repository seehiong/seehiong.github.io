<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MLflow on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/tags/mlflow/</link>
    <description>Recent content in MLflow on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 13 Apr 2025 10:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/tags/mlflow/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Feature Impact on HDB predictions</title>
      <link>https://seehiong.github.io/2025/feature-impact-on-hdb-predictions/</link>
      <pubDate>Sun, 13 Apr 2025 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2025/feature-impact-on-hdb-predictions/</guid>
      <description>In this post, I explore the impact of different feature sets on XGBoost model performance for HDB resale price prediction. By combining numerical, categorical, and engineered features, I conducted a series of experiments and tracked their performance using MLflow. The results reveal how thoughtful feature engineering and selection can significantly influence metrics like RMSE, MAE, and R²—offering valuable insights into building more accurate predictive models.</description>
    </item>
    <item>
      <title>GPT-2 Training Guide</title>
      <link>https://seehiong.github.io/archives/2024/gpt-2-training-guide/</link>
      <pubDate>Thu, 31 Oct 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2024/gpt-2-training-guide/</guid>
      <description>This post documents my journey training GPT-2 on the Tiny Shakespeare dataset, inspired by Andrej Karpathy&amp;rsquo;s instructional video and nanoGPT repository. Following each step, I detail the setup process, from encoding data and optimizing the model with AdamW, to improving training stability with mixed precision and flash attention. The post includes practical insights on using pretrained weights, weight sharing, and efficient data handling, concluding with sample outputs from training and sampling a “baby” GPT model.</description>
    </item>
    <item>
      <title>Integrating MLflow and Kubeflow on Talos</title>
      <link>https://seehiong.github.io/archives/2024/integrating-mlflow-and-kubeflow-on-talos/</link>
      <pubDate>Sun, 20 Oct 2024 08:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2024/integrating-mlflow-and-kubeflow-on-talos/</guid>
      <description>This post details the installation of MLflow and Kubeflow on a Talos HomeLab cluster. It covers the setup process, including Talos configuration, local-path and NFS provisioning, and Metallb installation. Step-by-step instructions are provided for deploying Kubeflow, followed by the installation of MLflow for managing the machine learning lifecycle. Finally, the post illustrates how to log experiments and models in MLflow and perform inference, demonstrating a seamless integration of these tools for enhanced machine learning operations.</description>
    </item>
  </channel>
</rss>
