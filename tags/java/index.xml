<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Java on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/tags/java/</link>
    <description>Recent content in Java on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 02 Feb 2025 20:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/tags/java/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>JMC: Java Performance Profiling Simplified</title>
      <link>https://seehiong.github.io/posts/2025/02/jmc-java-performance-profiling-simplified/</link>
      <pubDate>Sun, 02 Feb 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/02/jmc-java-performance-profiling-simplified/</guid>
      <description>JDK Mission Control (JMC) is a powerful tool for low-overhead Java application profiling and performance analysis. In this post, I explore JMC’s capabilities while optimizing inference performance for Micronaut-Llama3 with DeepSeek-R1. I walk through setup, profiling with Flight Recorder, and identifying bottlenecks using flame graphs. Key optimizations, such as refining ByteVector operations, significantly enhance performance. A comparison with VisualVM highlights JMC’s advantages, making it the go-to tool for in-depth Java profiling. If you&amp;rsquo;re looking to fine-tune your Java applications, JMC provides essential insights for optimization.</description>
    </item>
    <item>
      <title>Building a Flexible Optimizer Framework with Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/12/building-a-flexible-optimizer-framework-with-micronaut/</link>
      <pubDate>Sun, 29 Dec 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/12/building-a-flexible-optimizer-framework-with-micronaut/</guid>
      <description>This post outlines the design and implementation of the Micronaut Optimizer framework, which solves combinatorial optimization problems like TSP and FLP. It details the architecture, key components, and the use of Flux and PublishSubject for real-time updates. The post also highlights planned enhancements, including additional solver integration, performance optimizations, visualization improvements, and architecture extensions. The complete implementation is available on GitHub, and contributions are welcome.</description>
    </item>
    <item>
      <title>Porting Llama3.java to Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/12/porting-llama3.java-to-micronaut/</link>
      <pubDate>Sun, 15 Dec 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/12/porting-llama3.java-to-micronaut/</guid>
      <description>This project ports the original single-file llama3.java by Alfonso² Peterssen into a modular Micronaut application, transforming it from a console app to a stream-based, production-ready API. The internals and performance of the original GGUF-format LLM remain unchanged. Updates focus on restructuring the codebase into logical packages and adapting it to Micronaut’s ecosystem, enabling easier integration with Java microservices. This streamlined design retains the original’s simplicity while enhancing scalability and usability for modern AI applications.</description>
    </item>
    <item>
      <title>Porting Llama2.java to Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/12/porting-llama2.java-to-micronaut/</link>
      <pubDate>Sat, 07 Dec 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/12/porting-llama2.java-to-micronaut/</guid>
      <description>This post explores porting the single-file llama2.java into a robust Micronaut application, demonstrating both JDK and GraalVM native mode performance. While GraalVM offers faster startup (56ms), its serving throughput is slower (210 tokens/sec). For high-performance inference, JDK mode is preferred, but GraalVM shines for lightweight, startup-critical scenarios. The journey highlights Micronaut&amp;rsquo;s ease of integration for AI applications.</description>
    </item>
    <item>
      <title>From Routing Models to MIP: Solving Capacitated Vehicle Routing Problem</title>
      <link>https://seehiong.github.io/posts/2024/06/from-routing-models-to-mip-solving-capacitated-vehicle-routing-problem/</link>
      <pubDate>Sat, 01 Jun 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/06/from-routing-models-to-mip-solving-capacitated-vehicle-routing-problem/</guid>
      <description>In this post, we delve into solving the Capacitated Vehicle Routing Problem (CVRP) by transitioning from traditional routing models to the advanced Mixed Integer Programming (MIP) approach. We&amp;rsquo;ll start with the basics of creating a routing model using Google OR-Tools and then explore how to formulate and solve the CVRP using MIP for more optimized solutions. Whether you&amp;rsquo;re new to vehicle routing or looking to enhance your optimization techniques, this comprehensive guide provides the insights and code examples you need.</description>
    </item>
    <item>
      <title>Solving Facility Location Problem with OR-Tools and Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/05/solving-facility-location-problem-with-or-tools-and-micronaut/</link>
      <pubDate>Mon, 27 May 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/05/solving-facility-location-problem-with-or-tools-and-micronaut/</guid>
      <description>This post demonstrates solving the Facility Location Problem (FLP) using OR-Tools and Micronaut. It covers defining the solver, variables, constraints, and objective function in Java. The implementation includes creating a Micronaut service and controller to handle file uploads, process the data, and compute the optimal solution. The example input file format and expected outputs are also illustrated, providing a complete guide to implementing and testing the FLP solution.</description>
    </item>
    <item>
      <title>Optimizing TSP with Genetic Algorithms in Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/05/optimizing-tsp-with-genetic-algorithms-in-micronaut/</link>
      <pubDate>Thu, 23 May 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/05/optimizing-tsp-with-genetic-algorithms-in-micronaut/</guid>
      <description>In this post, I explore solving a Traveling Salesman Problem (TSP) involving 200 cities using genetic algorithms within a Micronaut framework. Leveraging techniques like inversion, insertion, and swap mutations, I illustrate how to maintain genetic diversity and improve solution quality over generations. The implementation showcases significant performance improvements compared to previous solvers. This approach combines simulated annealing, genetic algorithms, and local search to tackle complex optimization challenges effectively.</description>
    </item>
    <item>
      <title>Efficient TSP Solver API with Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/04/efficient-tsp-solver-api-with-micronaut/</link>
      <pubDate>Sat, 27 Apr 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/04/efficient-tsp-solver-api-with-micronaut/</guid>
      <description>Solve the Travelling Salesman Problem using Choco-solver and convert it into a powerful API with Micronaut. Explore the efficient solution and its integration for optimal city tours.</description>
    </item>
    <item>
      <title>Java Integration with Jupyter Notebooks</title>
      <link>https://seehiong.github.io/posts/2024/01/java-integration-with-jupyter-notebooks/</link>
      <pubDate>Sun, 21 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/java-integration-with-jupyter-notebooks/</guid>
      <description>Embark on a seamless integration of Java into Jupyter notebooks with this comprehensive guide. Beginning with the selection of a relevant Jupyter Docker Stack, the post details setup steps and deployment in HomeLab, showcasing application results for verification. The integration of Java Kernel through JBang and testing with &amp;ldquo;Hello World&amp;rdquo; and Apache Commons library exemplifies the versatility. Further exploration involves experimenting with Java in a Python kernel using JBang. Concluding with a call to joyful coding, this journey promises a harmonious blend of Java&amp;rsquo;s robustness and Jupyter&amp;rsquo;s interactive nature. Discover the joy of coding in this enriched Java-in-Jupyter experience. Happy coding!</description>
    </item>
    <item>
      <title>Deploying LLMs with WasmEdge in HomeLab</title>
      <link>https://seehiong.github.io/posts/2024/01/deploying-llms-with-wasmedge-in-homelab/</link>
      <pubDate>Sat, 13 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/deploying-llms-with-wasmedge-in-homelab/</guid>
      <description>In this post, we explored deploying Lightweight Language Models (LLMs) using WasmEdge, a high-performance WebAssembly runtime, within a HomeLab environment. The process involved preparing an OpenAI-compatible API server, configuring the Wasi-NN plugin, and deploying the setup to HomeLab using Kubernetes (K3s). The post also detailed the steps for testing the API server and integrating it into a Java application. Overall, the guide provides a comprehensive walkthrough of hosting and utilizing LLMs with WasmEdge in a local environment.</description>
    </item>
    <item>
      <title>AI Integration: LocalAI, Chroma, and Langchain4j</title>
      <link>https://seehiong.github.io/posts/2023/12/ai-integration-localai-chroma-and-langchain4j/</link>
      <pubDate>Fri, 29 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/ai-integration-localai-chroma-and-langchain4j/</guid>
      <description>Explore AI integration in a home lab with LocalAI, Chroma, and Langchain4j. Begin by creating a custom LocalAI image, deploying it alongside Chroma, and configuring the Kubernetes environment. The post details deploying and exposing services, ensuring seamless communication between applications. Learn to modify endpoints in the Langchain4j application for smooth integration with the Home Lab setup. With a focus on simplicity, this guide empowers users to harness the capabilities of these AI tools within a controlled home environment, fostering experimentation and development.</description>
    </item>
    <item>
      <title>Unveiling Agent AutoBuild in Autogen</title>
      <link>https://seehiong.github.io/posts/2023/12/unveiling-agent-autobuild-in-autogen/</link>
      <pubDate>Sun, 17 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/unveiling-agent-autobuild-in-autogen/</guid>
      <description>In this blog, I explored Autogen&amp;rsquo;s Agent AutoBuild and experimented with the Mixtral 8x7B model. I configured Autogen, envisioning a software academy project for coding novices. Through code snippets, I showcased AutoBuild&amp;rsquo;s multi-agent system creation and tailored a task that wrote a General Paper article on art and courage. The Mixtral 8x7B model in LM Studio brought excitement but posed challenges with duplicate content. Check out the blog for a firsthand look at the dynamic interplay between Autogen and cutting-edge AI, complete with code snippets and images.</description>
    </item>
    <item>
      <title>Empowering Autogen: Enabling Seamless Java Code Execution</title>
      <link>https://seehiong.github.io/posts/2023/12/empowering-autogen-enabling-seamless-java-code-execution/</link>
      <pubDate>Sun, 10 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/empowering-autogen-enabling-seamless-java-code-execution/</guid>
      <description>In this post, I explored enhancing Autogen&amp;rsquo;s capabilities by enabling seamless Java code execution. Drawing inspiration from 0xlws&amp;rsquo; fork supporting JavaScript, I embarked on modifying Autogen to robustly support Java. I detailed the setup process, including installing Java on Windows Subsystem for Linux (WSL) and modifying key files. The post includes code snippets showcasing the changes, recompilation steps, and instructions for generating Java code. I extended functionality to additional test cases, seamlessly switching between Java and Python code execution. Docker integration for Java code execution was also optimized, showcasing Autogen&amp;rsquo;s versatility and robust development experience.</description>
    </item>
    <item>
      <title>RAG over Java code with Langchain4j</title>
      <link>https://seehiong.github.io/posts/2023/11/rag-over-java-code-with-langchain4j/</link>
      <pubDate>Sat, 11 Nov 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/11/rag-over-java-code-with-langchain4j/</guid>
      <description>In my latest post, I delve into seamlessly integrating Retrieval-Augmented Generation (RAG) with Java code using Langchain4j. Drawing inspiration from RAG over code, I explore Java Parser&amp;rsquo;s potential for robust codebase analysis. The pivotal JavaParsingService and EmbeddingStoreService orchestrate this integration, enabling users to effortlessly load Java projects and glean profound insights. The enhanced controller boasts user-friendly endpoints, fostering dynamic interactions. Witness Retrieval-Augmented Generation breathe life into Java code, from codebase ingestion to insightful querying with models like gpt4all-j, WizardLM, and OpenAI. This narrative unveils the nuanced capabilities of RAG in querying Java codebases.</description>
    </item>
    <item>
      <title>Building an AI Application with Langchain4j</title>
      <link>https://seehiong.github.io/posts/2023/11/building-an-ai-application-with-langchain4j/</link>
      <pubDate>Tue, 07 Nov 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/11/building-an-ai-application-with-langchain4j/</guid>
      <description>I embarked on a journey to harness the capabilities of Langchain4j, crafting a powerful AI application in Java using the local language model. Utilizing Spring Boot, Postman, and various Langchain4j components, I explored setting up, implementing a chat service, integrating custom tools, embedding functionality with Chroma, translation, persistence, retrieval, and streaming services. The blog post serves as a comprehensive guide for building personalized AI applications, showcasing the versatility and potential of Langchain4j in Java development.</description>
    </item>
  </channel>
</rss>
