<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Llama2 on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/tags/llama2/</link>
    <description>Recent content in Llama2 on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sat, 07 Dec 2024 20:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/tags/llama2/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Porting Llama2.java to Micronaut</title>
      <link>https://seehiong.github.io/posts/2024/12/porting-llama2.java-to-micronaut/</link>
      <pubDate>Sat, 07 Dec 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/12/porting-llama2.java-to-micronaut/</guid>
      <description>This post explores porting the single-file llama2.java into a robust Micronaut application, demonstrating both JDK and GraalVM native mode performance. While GraalVM offers faster startup (56ms), its serving throughput is slower (210 tokens/sec). For high-performance inference, JDK mode is preferred, but GraalVM shines for lightweight, startup-critical scenarios. The journey highlights Micronaut&amp;rsquo;s ease of integration for AI applications.</description>
    </item>
    <item>
      <title>Unleashing Text Generation with NVIDIA Jetson Orin NX</title>
      <link>https://seehiong.github.io/posts/2024/08/unleashing-text-generation-with-nvidia-jetson-orin-nx/</link>
      <pubDate>Sat, 17 Aug 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/08/unleashing-text-generation-with-nvidia-jetson-orin-nx/</guid>
      <description>This post explores the powerful capabilities of NVIDIA Jetson Orin NX for text generation tasks. It covers the setup and use of models like Llama 2 and Llama 3, including installation steps, performance benchmarks, and examples of interactive AI sessions. Additionally, it provides insights into using the Jetson platform for deploying AI models efficiently, with practical tips on getting started and maximizing performance. Whether you&amp;rsquo;re a developer or AI enthusiast, this guide offers a hands-on look at harnessing NVIDIA Jetson&amp;rsquo;s potential for advanced AI applications.</description>
    </item>
    <item>
      <title>Unlocking the Power of Machine Learning with MLC LLM</title>
      <link>https://seehiong.github.io/posts/2023/09/unlocking-the-power-of-machine-learning-with-mlc-llm/</link>
      <pubDate>Sat, 02 Sep 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/09/unlocking-the-power-of-machine-learning-with-mlc-llm/</guid>
      <description>I delve into the transformative realm of MLC LLM, an advanced universal deployment solution for extensive language models. My post guides you personally through the setup, emphasizing critical components like TVM and Conda. I demonstrate the process, including TVM installation via pip, Conda setup on WSL, and Vulkan SDK installation for optimal performance. Navigating the MLC Chat exploration, I detail creating a Conda environment and running MLC LLM&amp;rsquo;s CLI version, offering a glimpse into its potential through a sample question. With MLC LLM and MLC Chat at your fingertips, the world of machine learning and language understanding unfolds boundless possibilities. ðŸš€ðŸ§ </description>
    </item>
  </channel>
</rss>
