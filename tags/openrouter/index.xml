<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>OpenRouter on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/tags/openrouter/</link>
    <description>Recent content in OpenRouter on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 21 Sep 2025 20:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/tags/openrouter/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI-Driven 3D Workflows with n8n</title>
      <link>https://seehiong.github.io/posts/2025/09/ai-driven-3d-workflows-with-n8n/</link>
      <pubDate>Sun, 21 Sep 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/09/ai-driven-3d-workflows-with-n8n/</guid>
      <description>This post explores how to integrate n8n, OpenRouter, and Blender MCP to create AI-driven 3D modeling workflows. Starting with an AI agent chat in n8n, I bridge prompts to Blender using a custom server, generating a condominium prototype complete with materials, landscaping, and cinematic lighting. Along the way, I highlight practical challenges—like material tuning and lighting setup—and show how automation and AI make complex 3D tasks conversational and modular. The result is a workflow that moves closer to a no-code, AI-powered approach to 3D design.</description>
    </item>
    <item>
      <title>Blender Meets MCP</title>
      <link>https://seehiong.github.io/posts/2025/09/blender-meets-mcp/</link>
      <pubDate>Sat, 13 Sep 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/09/blender-meets-mcp/</guid>
      <description>A step-by-step guide to integrating the Model Context Protocol (MCP) with Blender. From setup and server connections to building a datacenter model, discover how AI-driven workflows enhance 3D design and creativity.</description>
    </item>
    <item>
      <title>Run gpt-oss Locally on Ryzen AI</title>
      <link>https://seehiong.github.io/posts/2025/08/run-gpt-oss-locally-on-ryzen-ai/</link>
      <pubDate>Tue, 19 Aug 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/08/run-gpt-oss-locally-on-ryzen-ai/</guid>
      <description>Learn how to run OpenAI’s new gpt-oss model locally on a Ryzen AI Max+ 395 mini PC. This guide covers setting up Ollama, Cursor with Kilo Code, and OpenRouter to build a multi-model chat app that queries GPT-3.5, Claude, Mistral, LLaMA, Gemini, and more in parallel. Responses are consolidated into one clean interface—no more juggling multiple tabs. While local gpt-oss runs slower than cloud-hosted models, this experiment shows how anyone can explore AI development locally with modern tools.</description>
    </item>
    <item>
      <title>Running Bolt.diy with OpenRouter</title>
      <link>https://seehiong.github.io/posts/2025/07/running-bolt.diy-with-openrouter/</link>
      <pubDate>Sun, 06 Jul 2025 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2025/07/running-bolt.diy-with-openrouter/</guid>
      <description>This post explores running the open-source bolt.diy locally and integrating it with OpenRouter to experiment with various LLMs. I document the development of TextForge—a multi-tool text manipulation app—using one-shot prompts and compare outputs from models like Claude 3 and DeepSeek Chat. The post shares setup steps, performance benchmarks, cost breakdowns, and lessons learned from building a locally hosted, LLM-driven developer tool.</description>
    </item>
  </channel>
</rss>
