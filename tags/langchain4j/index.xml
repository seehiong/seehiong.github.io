<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Langchain4j on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/tags/langchain4j/</link>
    <description>Recent content in Langchain4j on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sat, 13 Jan 2024 20:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/tags/langchain4j/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deploying LLMs with WasmEdge in HomeLab</title>
      <link>https://seehiong.github.io/posts/2024/01/deploying-llms-with-wasmedge-in-homelab/</link>
      <pubDate>Sat, 13 Jan 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/deploying-llms-with-wasmedge-in-homelab/</guid>
      <description>In this post, we explored deploying Lightweight Language Models (LLMs) using WasmEdge, a high-performance WebAssembly runtime, within a HomeLab environment. The process involved preparing an OpenAI-compatible API server, configuring the Wasi-NN plugin, and deploying the setup to HomeLab using Kubernetes (K3s). The post also detailed the steps for testing the API server and integrating it into a Java application. Overall, the guide provides a comprehensive walkthrough of hosting and utilizing LLMs with WasmEdge in a local environment.</description>
    </item>
    <item>
      <title>Integration of Kong into AI Workflow</title>
      <link>https://seehiong.github.io/posts/2024/01/integration-of-kong-into-ai-workflow/</link>
      <pubDate>Sat, 06 Jan 2024 10:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2024/01/integration-of-kong-into-ai-workflow/</guid>
      <description>This comprehensive guide navigates through configuring Kong OSS and Kong Ingress Controller (KIC), seamlessly integrating Kong into an AI workflow. Starting with Kong OSS configuration, the tutorial covers updating environment variables and service ports. The Langchain4j application is then adapted to leverage Kong API, allowing for flexible path-based APIs. Additionally, potential timeout issues are addressed. The guide concludes with a demonstration of Kong Ingress Controller configuration, emphasizing optimal settings for specific use cases. Whether through Kong OSS or KIC, readers gain insights into enhancing API management and integration within their AI workflows.</description>
    </item>
    <item>
      <title>AI Integration: LocalAI, Chroma, and Langchain4j</title>
      <link>https://seehiong.github.io/posts/2023/12/ai-integration-localai-chroma-and-langchain4j/</link>
      <pubDate>Fri, 29 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/12/ai-integration-localai-chroma-and-langchain4j/</guid>
      <description>Explore AI integration in a home lab with LocalAI, Chroma, and Langchain4j. Begin by creating a custom LocalAI image, deploying it alongside Chroma, and configuring the Kubernetes environment. The post details deploying and exposing services, ensuring seamless communication between applications. Learn to modify endpoints in the Langchain4j application for smooth integration with the Home Lab setup. With a focus on simplicity, this guide empowers users to harness the capabilities of these AI tools within a controlled home environment, fostering experimentation and development.</description>
    </item>
    <item>
      <title>RAG over Java code with Langchain4j</title>
      <link>https://seehiong.github.io/posts/2023/11/rag-over-java-code-with-langchain4j/</link>
      <pubDate>Sat, 11 Nov 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/11/rag-over-java-code-with-langchain4j/</guid>
      <description>In my latest post, I delve into seamlessly integrating Retrieval-Augmented Generation (RAG) with Java code using Langchain4j. Drawing inspiration from RAG over code, I explore Java Parser&amp;rsquo;s potential for robust codebase analysis. The pivotal JavaParsingService and EmbeddingStoreService orchestrate this integration, enabling users to effortlessly load Java projects and glean profound insights. The enhanced controller boasts user-friendly endpoints, fostering dynamic interactions. Witness Retrieval-Augmented Generation breathe life into Java code, from codebase ingestion to insightful querying with models like gpt4all-j, WizardLM, and OpenAI. This narrative unveils the nuanced capabilities of RAG in querying Java codebases.</description>
    </item>
    <item>
      <title>Building an AI Application with Langchain4j</title>
      <link>https://seehiong.github.io/posts/2023/11/building-an-ai-application-with-langchain4j/</link>
      <pubDate>Tue, 07 Nov 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/posts/2023/11/building-an-ai-application-with-langchain4j/</guid>
      <description>I embarked on a journey to harness the capabilities of Langchain4j, crafting a powerful AI application in Java using the local language model. Utilizing Spring Boot, Postman, and various Langchain4j components, I explored setting up, implementing a chat service, integrating custom tools, embedding functionality with Chroma, translation, persistence, retrieval, and streaming services. The blog post serves as a comprehensive guide for building personalized AI applications, showcasing the versatility and potential of Langchain4j in Java development.</description>
    </item>
  </channel>
</rss>
