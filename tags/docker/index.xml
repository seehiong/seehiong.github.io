<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/tags/docker/</link>
    <description>Recent content in Docker on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 Jun 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://seehiong.github.io/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Log Management with Graylog</title>
      <link>https://seehiong.github.io/2024/log-management-with-graylog/</link>
      <pubDate>Fri, 19 Apr 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/log-management-with-graylog/</guid>
      <description>&lt;p&gt;In this blog post, I&amp;rsquo;ll guide you through the setup of &lt;a href=&#34;https://graylog.org/&#34; target=&#34;_blank&#34;&gt;Graylog&lt;/a&gt;, an open-source log management platform, within a HomeLab environment, providing a comprehensive solution for log analysis and monitoring.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setting-up-graylog-with-docker&#34;&gt;Setting up Graylog with Docker&lt;/h2&gt;&#xA;&lt;p&gt;To initiate our exploration of Graylog, we&amp;rsquo;ll opt for a &lt;a href=&#34;https://go2docs.graylog.org/5-2/downloading_and_installing_graylog/docker_installation.htm&#34; target=&#34;_blank&#34;&gt;Docker Installation&lt;/a&gt;, which ensures simplicity and ease of deployment. Follow the steps outlined in the official documentation to set up Graylog via Docker. Upon successful installation, access the Graylog interface by navigating to &lt;em&gt;http://localhost:9000/&lt;/em&gt;, and use the default credentials: &lt;strong&gt;admin/admin&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Integration: LocalAI, Chroma, and Langchain4j</title>
      <link>https://seehiong.github.io/archives/2023/ai-integration-localai-chroma-langchain4j/</link>
      <pubDate>Fri, 29 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2023/ai-integration-localai-chroma-langchain4j/</guid>
      <description>&lt;p&gt;Referring to the &lt;a href=&#34;https://seehiong.github.io/archives/2023/building-an-ai-application-with-langchain4j/&#34; target=&#34;_blank&#34;&gt;Building an AI application with Langchaing4j&lt;/a&gt; guide, the deployment of necessary Docker images, LocalAI, and Chroma to our Home Lab is outlined.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;creating-custom-localai-image&#34;&gt;Creating custom LocalAI image&lt;/h2&gt;&#xA;&lt;p&gt;Begin with pulling the latest image using the &lt;a href=&#34;https://localai.io/howtos/easy-setup-docker/&#34; target=&#34;_blank&#34;&gt;easy docker setup&lt;/a&gt; guide:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker pull quay.io/go-skynet/local-ai:v2.2.0&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now, run LocalAI from the &lt;em&gt;~/localai&lt;/em&gt; folder and download a model:&lt;/p&gt;</description>
    </item>
    <item>
      <title>GitLab Setup: Installation, Migration, and CI/CD Simplified</title>
      <link>https://seehiong.github.io/archives/2023/gitlab-setup-installation-migration-and-ci-cd-simplified/</link>
      <pubDate>Sun, 24 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2023/gitlab-setup-installation-migration-and-ci-cd-simplified/</guid>
      <description>&lt;p&gt;In this guide, I&amp;rsquo;ll walk you through the process of installing &lt;a href=&#34;https://docs.gitlab.com/omnibus/installation/&#34; target=&#34;_blank&#34;&gt;GitLab&lt;/a&gt;, a comprehensive suite of tools for version control, continuous integration, continuous delivery, and more, in my Home Lab collection.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;After obtaining the latest &lt;a href=&#34;https://ubuntu.com/download/server&#34; target=&#34;_blank&#34;&gt;Ubuntu Server&lt;/a&gt;, I utilized &lt;a href=&#34;https://rufus.ie/en/&#34; target=&#34;_blank&#34;&gt;Rufus&lt;/a&gt;, a utility for formatting and creating bootable USB flash drives.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;&#xA;&lt;p&gt;Following the &lt;a href=&#34;https://packages.gitlab.com/gitlab/gitlab-ce/install&#34; target=&#34;_blank&#34;&gt;installation instructions&lt;/a&gt;, initiate a quick installation using the following command:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deploying OpenAI-Compatible LLAMA CPP Server with K3S</title>
      <link>https://seehiong.github.io/archives/2023/deploying-openai-compatible-llama-cpp-server-with-k3s/</link>
      <pubDate>Fri, 22 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2023/deploying-openai-compatible-llama-cpp-server-with-k3s/</guid>
      <description>&lt;p&gt;Commencing my week-long Christmas break, I extend the concepts from my &lt;a href=&#34;https://seehiong.github.io/archives/2023/running-llama-server-in-local-machine/&#34; target=&#34;_blank&#34;&gt;previous post&lt;/a&gt; to establish an OpenAI-compatible server in my &lt;a href=&#34;https://seehiong.github.io/archives/2023/setting-up-k3s/&#34; target=&#34;_blank&#34;&gt;Home Lab&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;technical-setup&#34;&gt;Technical Setup&lt;/h2&gt;&#xA;&lt;p&gt;After fine-tuning a sample &lt;a href=&#34;https://github.com/abetlen/llama-cpp-python/blob/main/docker/openblas_simple/Dockerfile&#34; target=&#34;_blank&#34;&gt;Dockerfile&lt;/a&gt;, I reinstalled my Ubuntu server, incorporating necessary adjustments. The subsequent setup commands, reflecting my Home Lab&amp;rsquo;s new IP address (192.168.68.115), include:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt update &amp;amp; sudo apt upgrade -y&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Install docker&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install docker.io&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo usermod -aG docker pi&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Install Anaconda&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl -O https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chmod +x Anaconda3-2023.09-0-Linux-x86_64.sh&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;./Anaconda3-2023.09-0-Linux-x86_64.sh&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Init conda&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;source /home/pi/anaconda3/bin/activate&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda init&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda create -n docker-llama python&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;conda activate docker-llama &#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Empowering Autogen: Enabling Seamless Java Code Execution</title>
      <link>https://seehiong.github.io/archives/2023/empowering-autogen-enabling-seamless-java-code-execution/</link>
      <pubDate>Sun, 10 Dec 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2023/empowering-autogen-enabling-seamless-java-code-execution/</guid>
      <description>&lt;p&gt;In the pursuit of enhancing Autogen&amp;rsquo;s capabilities, I drew inspiration from &lt;a href=&#34;https://github.com/0xlws/autogen&#34; target=&#34;_blank&#34;&gt;0xlws&amp;rsquo; fork&lt;/a&gt; supporting JavaScript. This led me to embark on a journey to modify Autogen, enabling robust support for Java code execution.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;setting-up&#34;&gt;Setting up&lt;/h2&gt;&#xA;&lt;p&gt;Begin by ensuring that Java is installed on your Windows Subsystem for Linux (WSL) using the following command:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install openjdk-17-jdk-headless&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Utilizing vLLM for Efficient Language Model Serving</title>
      <link>https://seehiong.github.io/archives/2023/utilizing-vllm-for-efficient-language-model-serving/</link>
      <pubDate>Sun, 20 Aug 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2023/utilizing-vllm-for-efficient-language-model-serving/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://vllm.ai/&#34; target=&#34;_blank&#34;&gt;vLLM&lt;/a&gt; is an open-source library designed for rapid LLM (Large Language Model) inference and deployment. It leverages their novel algorithm called &lt;strong&gt;PagedAttention&lt;/strong&gt;, which optimizes the management of attention keys and values.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;In this blog post, I will share my experience of utilizing vLLM on a WSL (Windows Subsystem for Linux) instance running Ubuntu 22.04. Let&amp;rsquo;s start by setting up the environment:&lt;/p&gt;&#xA;&lt;h3 id=&#34;installing-wsl-and-configuring-ubuntu&#34;&gt;Installing WSL and Configuring Ubuntu&lt;/h3&gt;&#xA;&lt;p&gt;Begin by installing WSL and configuring it to use Ubuntu as the default distribution:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Setting up K3s</title>
      <link>https://seehiong.github.io/archives/2023/setting-up-k3s/</link>
      <pubDate>Sun, 30 Jul 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2023/setting-up-k3s/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://docs.k3s.io/&#34; target=&#34;_blank&#34;&gt;K3S&lt;/a&gt; is a lightweight and easy-to-install Kubernetes distribution, making it an ideal choice for running a Kubernetes cluster in your home lab. In this blog post, we will walk you through the step-by-step process of setting up K3s on an Ubuntu Server 22.04.2 LTS.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-setting-up-k3s&#34;&gt;1 Setting up K3S&lt;/h2&gt;&#xA;&lt;h3 id=&#34;11-installing-ubuntu-server-22042-lts&#34;&gt;1.1 Installing Ubuntu Server 22.04.2 LTS&lt;/h3&gt;&#xA;&lt;p&gt;To start, we&amp;rsquo;ll install &lt;a href=&#34;https://ubuntu.com/download/server&#34; target=&#34;_blank&#34;&gt;Ubuntu server 22.04.2 LTS&lt;/a&gt; on our laptop. You can verify the Linux distribution using the following command:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Unleashing the Power of LLaMA Server in Docker Container</title>
      <link>https://seehiong.github.io/archives/2023/unleashing-the-power-of-llama-server-in-docker-container/</link>
      <pubDate>Sat, 15 Jul 2023 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2023/unleashing-the-power-of-llama-server-in-docker-container/</guid>
      <description>&lt;p&gt;Having recently completed the enlightening &lt;a href=&#34;https://www.coursera.org/learn/generative-ai-with-llms&#34; target=&#34;_blank&#34;&gt;Generative AI with Large Language Models&lt;/a&gt; course, where we gained invaluable knowledge and hands-on skills, we are now excited to share an exhilarating experience of running the LLaMA model in a Dockerized container.&lt;/p&gt;&#xA;&lt;p&gt;In this guide, we&amp;rsquo;ll walk you through the setup and demonstrate how to unleash the full potential of running LLaMA Server within a Docker container.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;the-setup&#34;&gt;The Setup&lt;/h2&gt;&#xA;&lt;p&gt;Before we delve into the magic of LLaMA, let&amp;rsquo;s set up our application structure. To ensure smooth execution, we&amp;rsquo;ve structured our project as follows:&lt;/p&gt;</description>
    </item>
    <item>
      <title>HA K8s Pi Cluster (II)</title>
      <link>https://seehiong.github.io/archives/2020/highly-available-kubernetes-pi-cluster-part-2/</link>
      <pubDate>Mon, 17 Aug 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2020/highly-available-kubernetes-pi-cluster-part-2/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://seehiong.github.io/images/ha-k8s2/highly-available-kubernetes-pi-cluster.png&#34; alt=&#34;highly-available-kubernetes-pi-cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;By having a Highly Available Kubernetes Pi Cluster, you will have full control over your production grade environment on-premise&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;ha-kubernetes-pi-cluster-part-ii&#34;&gt;HA Kubernetes Pi Cluster (Part II)&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 20 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;In this follow up guide, I will configure the HA Kubernetes Cluster onto the previous &lt;a href=&#34;https://seehiong.github.io/archives/2020/highly-available-kubernetes-pi-cluster-part-1/&#34; target=&#34;_blank&#34;&gt;external etcd setup&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;installing-docker&#34;&gt;Installing Docker&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(5 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Firstly, installs docker &lt;a href=&#34;https://kubernetes.io/docs/setup/production-environment/container-runtimes/&#34; target=&#34;_blank&#34;&gt;container runtimes&lt;/a&gt; to all master nodes:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gitea for K8s Cluster</title>
      <link>https://seehiong.github.io/archives/2020/gitea-on-kubernetes-pi-cluster/</link>
      <pubDate>Fri, 10 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2020/gitea-on-kubernetes-pi-cluster/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://seehiong.github.io/images/gitea-k8s/gitea-on-raspberry-pi-cluster.png&#34; alt=&#34;gitea-on-kubernetes-pi-cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Having Gitea on Kubernetes Pi cluster, you will have full control over your personal Git repositories&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;gitea-for-kubernetes-cluster-on-pi&#34;&gt;Gitea for Kubernetes Cluster on Pi&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 40 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Similar to the previous post on &lt;a href=&#34;https://seehiong.github.io/archives/2020/gitea-for-raspberry-pi-cluster/&#34; target=&#34;_blank&#34;&gt;Gitea for MicroK8s Cluster&lt;/a&gt;, I will be setting up Git in the newly created &lt;a href=&#34;https://seehiong.github.io/archives/2020/kubernetes-cluster-on-raspberry-pi/&#34; target=&#34;_blank&#34;&gt;Kubernetes Cluster&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;setup-mysql&#34;&gt;Setup MySQL&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(15 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;First, I download the &lt;a href=&#34;https://dev.mysql.com/doc/mysql-installation-excerpt/8.0/en/docker-mysql-getting-started.html&#34; target=&#34;_blank&#34;&gt;mysql-server docker&lt;/a&gt; image:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Kubernetes Cluster on Pi</title>
      <link>https://seehiong.github.io/archives/2020/kubernetes-cluster-on-raspberry-pi/</link>
      <pubDate>Sat, 04 Jul 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2020/kubernetes-cluster-on-raspberry-pi/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://seehiong.github.io/images/kubernetes/kubernetes-cluster-on-raspberry-pi.png&#34; alt=&#34;kubernetes-cluster-on-raspberry-pi&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;With Kubernetes Cluster on Raspberry Pi, you may orchestrate and manage your Docker containers with full control&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;kubernetes-cluster&#34;&gt;Kubernetes Cluster&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 70 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Similar to the previous &lt;a href=&#34;https://seehiong.github.io/archives/2020/microk8s-cluster-on-raspberry-pi-8gb-part-1/&#34; target=&#34;_blank&#34;&gt;MicroK8s cluster&lt;/a&gt; setup, I am using &lt;a href=&#34;https://ubuntu.com/download/raspberry-pi&#34; target=&#34;_blank&#34;&gt;Ubuntu Server 20.04 LTS (64-bit)&lt;/a&gt; as my OS. Having a Kubernetes Cluster on Raspberry Pi, you will have more control over how the cluster configured.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gitea for MicroK8s Cluster</title>
      <link>https://seehiong.github.io/archives/2020/gitea-for-raspberry-pi-cluster/</link>
      <pubDate>Mon, 29 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2020/gitea-for-raspberry-pi-cluster/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://seehiong.github.io/images/gitea/gitea-on-raspberry-pi-cluster.png&#34; alt=&#34;gitea-for-raspberry-pi-cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;With Gitea for Raspberry Pi cluster, you can have your own self-hosted Git Service&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;gitea-for-raspberry-pi&#34;&gt;Gitea for Raspberry Pi&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 45 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://gitea.io/en-us/&#34; target=&#34;_blank&#34;&gt;Gitea&lt;/a&gt; is a painless self-hosted Git service. By hosting Gitea locally, our team is able to save cost and you also have more control over your server.&lt;/p&gt;&#xA;&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;(5 min)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;If you are following my &lt;a href=&#34;https://seehiong.github.io/archives/2020/microk8s-cluster-on-raspberry-pi-8gb-part-1/&#34; target=&#34;_blank&#34;&gt;MicroK8s cluster&lt;/a&gt; setup, for each kubectl command, you need to append with microk8s. With this section, you can simply use &lt;em&gt;kubectl&lt;/em&gt;. First, install kubectl:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Docker for MicroK8s Cluster</title>
      <link>https://seehiong.github.io/archives/2020/docker-on-raspberry-pi-cluster/</link>
      <pubDate>Sun, 21 Jun 2020 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/archives/2020/docker-on-raspberry-pi-cluster/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://seehiong.github.io/images/docker/docker-on-pi-cluster.png&#34; alt=&#34;docker-for-raspberry-pi&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;With Docker on Raspberry Pi cluster, you can run any containerized applications on your Pi Cluster&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h1 id=&#34;docker-on-raspberry&#34;&gt;Docker on Raspberry&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;(Total Setup Time: 15 mins)&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;To install &lt;a href=&#34;https://microk8s.io/docs/registry-images&#34; target=&#34;_blank&#34;&gt;Docker&lt;/a&gt; for Raspberry Pi Cluster, add &lt;strong&gt;ubuntu&lt;/strong&gt; user to the docker group:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt install docker.io&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo usermod -aG docker ubuntu&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;su - ubuntu &lt;span style=&#34;color:#75715e&#34;&gt;# open a new shell with updated membership for the user&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pr</description>
    </item>
  </channel>
</rss>
