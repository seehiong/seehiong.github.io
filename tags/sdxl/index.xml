<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SDXL on See Hiong&#39;s Blog</title>
    <link>https://seehiong.github.io/tags/sdxl/</link>
    <description>Recent content in SDXL on See Hiong&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 10 Feb 2024 20:00:00 +0800</lastBuildDate>
    <atom:link href="https://seehiong.github.io/tags/sdxl/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Text-to-Image with StableDiffusionPipeline</title>
      <link>https://seehiong.github.io/2024/text-to-image-with-stablediffusionpipeline/</link>
      <pubDate>Sat, 10 Feb 2024 20:00:00 +0800</pubDate>
      <guid>https://seehiong.github.io/2024/text-to-image-with-stablediffusionpipeline/</guid>
      <description>In this post, we explore the capabilities of StableDiffusionPipeline for generating photorealistic images from textual inputs. We start with setting up the environment and installing necessary libraries. Then, we dive into Textual Inversion, demonstrating how the model learns new concepts from images. Image-to-Image transformations are also explored, showcasing the pipeline&amp;rsquo;s versatility. Additionally, we introduce Animagine XL 2.0, a model for high-resolution anime image creation, and provide sample code for its implementation. Lastly, we highlight Stable Diffusion XL, a powerful text-to-image model, and share a festive image generated using it.</description>
    </item>
  </channel>
</rss>
